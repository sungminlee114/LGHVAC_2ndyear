{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:datasets:PyTorch version 2.7.1+cu128 available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory of src to the path\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src.db.manager import DBManager\n",
    "from src.input_to_instructions.load_and_execute import *\n",
    "from src.input_to_instructions.types import *\n",
    "from src.operation.execute import *\n",
    "from src.response_generation.load_and_execute import *\n",
    "from src.dateutils import normalize_sql_dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "import json\n",
    "import itertools\n",
    "\n",
    "# from db.manager import DBManager\n",
    "from operation.execute import OperationExecutor\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import datetime\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"../\"\n",
    "def read_json(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        result = json.loads(f.read())\n",
    "    \n",
    "    # result = [{\"Input\": d[\"Input\"], \"Response\": json.dumps(d[\"Response\"], ensure_ascii=False)} for d in result]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn_implementation: flash_attention_2, torch_dtype: torch.bfloat16\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.get_device_capability()[0] >= 8:\n",
    "    attn_implementation = \"flash_attention_2\"\n",
    "    torch_dtype = torch.bfloat16\n",
    "else:\n",
    "    attn_implementation = \"eager\"\n",
    "    torch_dtype = torch.float16\n",
    "print(f\"attn_implementation: {attn_implementation}, torch_dtype: {torch_dtype}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: WARNING `trust_remote_code` is True.\n",
      "Are you certain you want to do remote code execution?\n",
      "==((====))==  Unsloth 2025.8.1: Fast Llama patching. Transformers: 4.55.0.\n",
      "   \\\\   /|    NVIDIA H100 80GB HBM3. Num GPUs = 1. Max memory: 79.19 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.1+cu128. CUDA: 9.0. CUDA Toolkit: 12.8. Triton: 3.3.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = True]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da5c05be67f647828cfd848d981b29d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sh2orc/Llama-3.1-Korean-8B-Instruct does not have a padding token! Will use pad_token = <|finetune_right_pad_id|>.\n",
      "PreTrainedTokenizerFast(name_or_path='sh2orc/Llama-3.1-Korean-8B-Instruct', vocab_size=128000, model_max_length=131072, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<|begin_of_text|>', 'eos_token': '<|eot_id|>', 'pad_token': '<|finetune_right_pad_id|>'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
      "\t128000: AddedToken(\"<|begin_of_text|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128001: AddedToken(\"<|end_of_text|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128002: AddedToken(\"<|reserved_special_token_0|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128003: AddedToken(\"<|reserved_special_token_1|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128004: AddedToken(\"<|finetune_right_pad_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128005: AddedToken(\"<|reserved_special_token_2|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128006: AddedToken(\"<|start_header_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128007: AddedToken(\"<|end_header_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128008: AddedToken(\"<|eom_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128009: AddedToken(\"<|eot_id|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128010: AddedToken(\"<|python_tag|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128011: AddedToken(\"<|reserved_special_token_3|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128012: AddedToken(\"<|reserved_special_token_4|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128013: AddedToken(\"<|reserved_special_token_5|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128014: AddedToken(\"<|reserved_special_token_6|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128015: AddedToken(\"<|reserved_special_token_7|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128016: AddedToken(\"<|reserved_special_token_8|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128017: AddedToken(\"<|reserved_special_token_9|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128018: AddedToken(\"<|reserved_special_token_10|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128019: AddedToken(\"<|reserved_special_token_11|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128020: AddedToken(\"<|reserved_special_token_12|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128021: AddedToken(\"<|reserved_special_token_13|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128022: AddedToken(\"<|reserved_special_token_14|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128023: AddedToken(\"<|reserved_special_token_15|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128024: AddedToken(\"<|reserved_special_token_16|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128025: AddedToken(\"<|reserved_special_token_17|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128026: AddedToken(\"<|reserved_special_token_18|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128027: AddedToken(\"<|reserved_special_token_19|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128028: AddedToken(\"<|reserved_special_token_20|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128029: AddedToken(\"<|reserved_special_token_21|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128030: AddedToken(\"<|reserved_special_token_22|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128031: AddedToken(\"<|reserved_special_token_23|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128032: AddedToken(\"<|reserved_special_token_24|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128033: AddedToken(\"<|reserved_special_token_25|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128034: AddedToken(\"<|reserved_special_token_26|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128035: AddedToken(\"<|reserved_special_token_27|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128036: AddedToken(\"<|reserved_special_token_28|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128037: AddedToken(\"<|reserved_special_token_29|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128038: AddedToken(\"<|reserved_special_token_30|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128039: AddedToken(\"<|reserved_special_token_31|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128040: AddedToken(\"<|reserved_special_token_32|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128041: AddedToken(\"<|reserved_special_token_33|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128042: AddedToken(\"<|reserved_special_token_34|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128043: AddedToken(\"<|reserved_special_token_35|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128044: AddedToken(\"<|reserved_special_token_36|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128045: AddedToken(\"<|reserved_special_token_37|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128046: AddedToken(\"<|reserved_special_token_38|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128047: AddedToken(\"<|reserved_special_token_39|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128048: AddedToken(\"<|reserved_special_token_40|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128049: AddedToken(\"<|reserved_special_token_41|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128050: AddedToken(\"<|reserved_special_token_42|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128051: AddedToken(\"<|reserved_special_token_43|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128052: AddedToken(\"<|reserved_special_token_44|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128053: AddedToken(\"<|reserved_special_token_45|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128054: AddedToken(\"<|reserved_special_token_46|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128055: AddedToken(\"<|reserved_special_token_47|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128056: AddedToken(\"<|reserved_special_token_48|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128057: AddedToken(\"<|reserved_special_token_49|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128058: AddedToken(\"<|reserved_special_token_50|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128059: AddedToken(\"<|reserved_special_token_51|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128060: AddedToken(\"<|reserved_special_token_52|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128061: AddedToken(\"<|reserved_special_token_53|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128062: AddedToken(\"<|reserved_special_token_54|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128063: AddedToken(\"<|reserved_special_token_55|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128064: AddedToken(\"<|reserved_special_token_56|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128065: AddedToken(\"<|reserved_special_token_57|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128066: AddedToken(\"<|reserved_special_token_58|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128067: AddedToken(\"<|reserved_special_token_59|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128068: AddedToken(\"<|reserved_special_token_60|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128069: AddedToken(\"<|reserved_special_token_61|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128070: AddedToken(\"<|reserved_special_token_62|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128071: AddedToken(\"<|reserved_special_token_63|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128072: AddedToken(\"<|reserved_special_token_64|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128073: AddedToken(\"<|reserved_special_token_65|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128074: AddedToken(\"<|reserved_special_token_66|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128075: AddedToken(\"<|reserved_special_token_67|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128076: AddedToken(\"<|reserved_special_token_68|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128077: AddedToken(\"<|reserved_special_token_69|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128078: AddedToken(\"<|reserved_special_token_70|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128079: AddedToken(\"<|reserved_special_token_71|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128080: AddedToken(\"<|reserved_special_token_72|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128081: AddedToken(\"<|reserved_special_token_73|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128082: AddedToken(\"<|reserved_special_token_74|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128083: AddedToken(\"<|reserved_special_token_75|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128084: AddedToken(\"<|reserved_special_token_76|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128085: AddedToken(\"<|reserved_special_token_77|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128086: AddedToken(\"<|reserved_special_token_78|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128087: AddedToken(\"<|reserved_special_token_79|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128088: AddedToken(\"<|reserved_special_token_80|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128089: AddedToken(\"<|reserved_special_token_81|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128090: AddedToken(\"<|reserved_special_token_82|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128091: AddedToken(\"<|reserved_special_token_83|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128092: AddedToken(\"<|reserved_special_token_84|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128093: AddedToken(\"<|reserved_special_token_85|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128094: AddedToken(\"<|reserved_special_token_86|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128095: AddedToken(\"<|reserved_special_token_87|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128096: AddedToken(\"<|reserved_special_token_88|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128097: AddedToken(\"<|reserved_special_token_89|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128098: AddedToken(\"<|reserved_special_token_90|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128099: AddedToken(\"<|reserved_special_token_91|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128100: AddedToken(\"<|reserved_special_token_92|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128101: AddedToken(\"<|reserved_special_token_93|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128102: AddedToken(\"<|reserved_special_token_94|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128103: AddedToken(\"<|reserved_special_token_95|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128104: AddedToken(\"<|reserved_special_token_96|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128105: AddedToken(\"<|reserved_special_token_97|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128106: AddedToken(\"<|reserved_special_token_98|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128107: AddedToken(\"<|reserved_special_token_99|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128108: AddedToken(\"<|reserved_special_token_100|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128109: AddedToken(\"<|reserved_special_token_101|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128110: AddedToken(\"<|reserved_special_token_102|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128111: AddedToken(\"<|reserved_special_token_103|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128112: AddedToken(\"<|reserved_special_token_104|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128113: AddedToken(\"<|reserved_special_token_105|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128114: AddedToken(\"<|reserved_special_token_106|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128115: AddedToken(\"<|reserved_special_token_107|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128116: AddedToken(\"<|reserved_special_token_108|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128117: AddedToken(\"<|reserved_special_token_109|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128118: AddedToken(\"<|reserved_special_token_110|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128119: AddedToken(\"<|reserved_special_token_111|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128120: AddedToken(\"<|reserved_special_token_112|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128121: AddedToken(\"<|reserved_special_token_113|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128122: AddedToken(\"<|reserved_special_token_114|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128123: AddedToken(\"<|reserved_special_token_115|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128124: AddedToken(\"<|reserved_special_token_116|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128125: AddedToken(\"<|reserved_special_token_117|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128126: AddedToken(\"<|reserved_special_token_118|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128127: AddedToken(\"<|reserved_special_token_119|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128128: AddedToken(\"<|reserved_special_token_120|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128129: AddedToken(\"<|reserved_special_token_121|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128130: AddedToken(\"<|reserved_special_token_122|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128131: AddedToken(\"<|reserved_special_token_123|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128132: AddedToken(\"<|reserved_special_token_124|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128133: AddedToken(\"<|reserved_special_token_125|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128134: AddedToken(\"<|reserved_special_token_126|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128135: AddedToken(\"<|reserved_special_token_127|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128136: AddedToken(\"<|reserved_special_token_128|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128137: AddedToken(\"<|reserved_special_token_129|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128138: AddedToken(\"<|reserved_special_token_130|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128139: AddedToken(\"<|reserved_special_token_131|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128140: AddedToken(\"<|reserved_special_token_132|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128141: AddedToken(\"<|reserved_special_token_133|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128142: AddedToken(\"<|reserved_special_token_134|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128143: AddedToken(\"<|reserved_special_token_135|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128144: AddedToken(\"<|reserved_special_token_136|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128145: AddedToken(\"<|reserved_special_token_137|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128146: AddedToken(\"<|reserved_special_token_138|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128147: AddedToken(\"<|reserved_special_token_139|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128148: AddedToken(\"<|reserved_special_token_140|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128149: AddedToken(\"<|reserved_special_token_141|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128150: AddedToken(\"<|reserved_special_token_142|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128151: AddedToken(\"<|reserved_special_token_143|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128152: AddedToken(\"<|reserved_special_token_144|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128153: AddedToken(\"<|reserved_special_token_145|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128154: AddedToken(\"<|reserved_special_token_146|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128155: AddedToken(\"<|reserved_special_token_147|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128156: AddedToken(\"<|reserved_special_token_148|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128157: AddedToken(\"<|reserved_special_token_149|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128158: AddedToken(\"<|reserved_special_token_150|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128159: AddedToken(\"<|reserved_special_token_151|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128160: AddedToken(\"<|reserved_special_token_152|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128161: AddedToken(\"<|reserved_special_token_153|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128162: AddedToken(\"<|reserved_special_token_154|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128163: AddedToken(\"<|reserved_special_token_155|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128164: AddedToken(\"<|reserved_special_token_156|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128165: AddedToken(\"<|reserved_special_token_157|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128166: AddedToken(\"<|reserved_special_token_158|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128167: AddedToken(\"<|reserved_special_token_159|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128168: AddedToken(\"<|reserved_special_token_160|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128169: AddedToken(\"<|reserved_special_token_161|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128170: AddedToken(\"<|reserved_special_token_162|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128171: AddedToken(\"<|reserved_special_token_163|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128172: AddedToken(\"<|reserved_special_token_164|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128173: AddedToken(\"<|reserved_special_token_165|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128174: AddedToken(\"<|reserved_special_token_166|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128175: AddedToken(\"<|reserved_special_token_167|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128176: AddedToken(\"<|reserved_special_token_168|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128177: AddedToken(\"<|reserved_special_token_169|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128178: AddedToken(\"<|reserved_special_token_170|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128179: AddedToken(\"<|reserved_special_token_171|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128180: AddedToken(\"<|reserved_special_token_172|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128181: AddedToken(\"<|reserved_special_token_173|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128182: AddedToken(\"<|reserved_special_token_174|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128183: AddedToken(\"<|reserved_special_token_175|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128184: AddedToken(\"<|reserved_special_token_176|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128185: AddedToken(\"<|reserved_special_token_177|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128186: AddedToken(\"<|reserved_special_token_178|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128187: AddedToken(\"<|reserved_special_token_179|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128188: AddedToken(\"<|reserved_special_token_180|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128189: AddedToken(\"<|reserved_special_token_181|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128190: AddedToken(\"<|reserved_special_token_182|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128191: AddedToken(\"<|reserved_special_token_183|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128192: AddedToken(\"<|reserved_special_token_184|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128193: AddedToken(\"<|reserved_special_token_185|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128194: AddedToken(\"<|reserved_special_token_186|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128195: AddedToken(\"<|reserved_special_token_187|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128196: AddedToken(\"<|reserved_special_token_188|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128197: AddedToken(\"<|reserved_special_token_189|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128198: AddedToken(\"<|reserved_special_token_190|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128199: AddedToken(\"<|reserved_special_token_191|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128200: AddedToken(\"<|reserved_special_token_192|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128201: AddedToken(\"<|reserved_special_token_193|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128202: AddedToken(\"<|reserved_special_token_194|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128203: AddedToken(\"<|reserved_special_token_195|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128204: AddedToken(\"<|reserved_special_token_196|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128205: AddedToken(\"<|reserved_special_token_197|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128206: AddedToken(\"<|reserved_special_token_198|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128207: AddedToken(\"<|reserved_special_token_199|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128208: AddedToken(\"<|reserved_special_token_200|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128209: AddedToken(\"<|reserved_special_token_201|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128210: AddedToken(\"<|reserved_special_token_202|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128211: AddedToken(\"<|reserved_special_token_203|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128212: AddedToken(\"<|reserved_special_token_204|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128213: AddedToken(\"<|reserved_special_token_205|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128214: AddedToken(\"<|reserved_special_token_206|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128215: AddedToken(\"<|reserved_special_token_207|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128216: AddedToken(\"<|reserved_special_token_208|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128217: AddedToken(\"<|reserved_special_token_209|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128218: AddedToken(\"<|reserved_special_token_210|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128219: AddedToken(\"<|reserved_special_token_211|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128220: AddedToken(\"<|reserved_special_token_212|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128221: AddedToken(\"<|reserved_special_token_213|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128222: AddedToken(\"<|reserved_special_token_214|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128223: AddedToken(\"<|reserved_special_token_215|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128224: AddedToken(\"<|reserved_special_token_216|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128225: AddedToken(\"<|reserved_special_token_217|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128226: AddedToken(\"<|reserved_special_token_218|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128227: AddedToken(\"<|reserved_special_token_219|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128228: AddedToken(\"<|reserved_special_token_220|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128229: AddedToken(\"<|reserved_special_token_221|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128230: AddedToken(\"<|reserved_special_token_222|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128231: AddedToken(\"<|reserved_special_token_223|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128232: AddedToken(\"<|reserved_special_token_224|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128233: AddedToken(\"<|reserved_special_token_225|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128234: AddedToken(\"<|reserved_special_token_226|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128235: AddedToken(\"<|reserved_special_token_227|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128236: AddedToken(\"<|reserved_special_token_228|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128237: AddedToken(\"<|reserved_special_token_229|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128238: AddedToken(\"<|reserved_special_token_230|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128239: AddedToken(\"<|reserved_special_token_231|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128240: AddedToken(\"<|reserved_special_token_232|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128241: AddedToken(\"<|reserved_special_token_233|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128242: AddedToken(\"<|reserved_special_token_234|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128243: AddedToken(\"<|reserved_special_token_235|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128244: AddedToken(\"<|reserved_special_token_236|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128245: AddedToken(\"<|reserved_special_token_237|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128246: AddedToken(\"<|reserved_special_token_238|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128247: AddedToken(\"<|reserved_special_token_239|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128248: AddedToken(\"<|reserved_special_token_240|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128249: AddedToken(\"<|reserved_special_token_241|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128250: AddedToken(\"<|reserved_special_token_242|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128251: AddedToken(\"<|reserved_special_token_243|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128252: AddedToken(\"<|reserved_special_token_244|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128253: AddedToken(\"<|reserved_special_token_245|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128254: AddedToken(\"<|reserved_special_token_246|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128255: AddedToken(\"<|reserved_special_token_247|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# ResponseGeneration.update_prompt()\n",
    "\n",
    "ResponseGeneration.initialize(\n",
    "    log_output=False,\n",
    "    instance_type=\"unsloth\"\n",
    ")\n",
    "tokenizer = ResponseGeneration.tokenizer\n",
    "print(tokenizer)\n",
    "\n",
    "def measure_token_count(input: str) -> int:\n",
    "    return len(tokenizer.encode(str(input)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from src.input_to_instructions.types import InstructionQ_raw\n",
    "def get_time(df, fmt=\"datetime\"):\n",
    "    # from df get 'timestamp' column and return them in format\n",
    "    if fmt == \"date\":\n",
    "        fmt = '%Y-%m-%d'\n",
    "    elif fmt == \"month\":\n",
    "        fmt = '%Y-%m'\n",
    "    elif fmt == \"year\":\n",
    "        fmt = '%Y'\n",
    "    else:\n",
    "        fmt = '%Y-%m-%d %H:%M:%S'\n",
    "    print(f\"get_time, col: {df.columns}, fmt: {fmt}\")\n",
    "    if isinstance(df['timestamp'], pd.Timestamp):\n",
    "        result = df['timestamp'].strftime(fmt)\n",
    "    else:\n",
    "        result = df['timestamp'].apply(lambda x: x.strftime(fmt))\n",
    "    return sorted(list(set(result)))\n",
    "\n",
    "def get_spatials(df):\n",
    "    return pd.unique(df['idu_name'])\n",
    "\n",
    "def get_tv(df, col:str|list[str], fmt=\"datetime\"):\n",
    "    if isinstance(col, str):\n",
    "        col = [col]\n",
    "    \n",
    "    timestamps = get_time(df, fmt)\n",
    "    return_tuple = tuple([timestamps] + [df[c] for c in col])\n",
    "    return return_tuple\n",
    "\n",
    "def data_(metadata, mapping, query_results, t=str|list[str], s=str|list[str], m=str|list[str]):\n",
    "    if isinstance(t, str):\n",
    "        t = [t]\n",
    "    if isinstance(s, str):\n",
    "        s = [s]\n",
    "    if isinstance(m, str):\n",
    "        m = [m]\n",
    "\n",
    "    t_raw = [mapping.temporal[t_highlevel] for t_highlevel in t]\n",
    "    s_raw = [mapping.spatials[s_highlevel] for s_highlevel in s]\n",
    "    m_raw = [mapping.modalities[m_highlevel] for m_highlevel in m]\n",
    "    \n",
    "    # flatten s_raw into a list of strings\n",
    "    # flattened = [item for sublist in data for item in (sublist if isinstance(sublist, list) else [sublist])]\n",
    "    s_raw = [item for sublist in s_raw for item in (sublist if isinstance(sublist, list) else [sublist])]\n",
    "    # print(s_raw)\n",
    "    result_df = DBManager.structured_query_data_t_v2(metadata, m_raw, t_raw, s_raw, get_rowids=True)\n",
    "    \n",
    "    cols = list(result_df.columns)\n",
    "    print(f\"cols: {cols}\")\n",
    "    cols.remove(\"id\")\n",
    "    cols.remove(\"idu_name\")\n",
    "    cols.remove(\"timestamp\")\n",
    "    rows = list(result_df[\"id\"])\n",
    "    query_results.append({\n",
    "        \"result_columns\": cols,\n",
    "        \"result_indices\": rows,\n",
    "    })\n",
    "    # print(cols, rows)\n",
    "\n",
    "    # For demo, drop rows where any value is -1\n",
    "    result_df = result_df.loc[(result_df != -1).all(axis=1)]\n",
    "\n",
    "    # drop \"id\" from result_df\n",
    "    result_df = result_df.drop(columns=['id'])\n",
    "\n",
    "    # change column names to high level\n",
    "    inverse_mapping = {v: k for k, v in mapping.modalities.items()}\n",
    "    result_df.columns = [inverse_mapping[col] if col in inverse_mapping else col for col in result_df.columns]\n",
    "\n",
    "    # change idu_name raw values to high level\n",
    "    inverse_mapping = {}\n",
    "    for k, v in mapping.spatials.items():\n",
    "        if isinstance(v, list):\n",
    "            for v_ in v:\n",
    "                inverse_mapping[v_] = k\n",
    "        else:\n",
    "            inverse_mapping[v] = k\n",
    "\n",
    "    result_df[\"idu_name\"] = result_df[\"idu_name\"].map(inverse_mapping)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "\n",
    "def run_query_v2(user_input, metadata, mapping, expectations, required_variables, scripts, exp_tag=None):\n",
    "    query_results = []\n",
    "    variables = {}\n",
    "    # print(f\"exp_tag: {exp_tag}\")\n",
    "    if scripts is not None:\n",
    "\n",
    "        # search data(t=~~, ...,)\n",
    "        globals()['metadata'] = metadata\n",
    "        globals()['mapping'] = mapping\n",
    "        globals()['query_results'] = query_results\n",
    "        for name in list(globals()):\n",
    "            if name.startswith(\"v_\"):\n",
    "                del globals()[name]\n",
    "        try:\n",
    "            query_time = 0\n",
    "            process_time = 0\n",
    "            \n",
    "            for script in scripts:\n",
    "                try:\n",
    "                    start_time = time.time()\n",
    "                    if \"data\" in script:\n",
    "                        script = script.replace(\"data(\", \"data_(metadata, mapping, query_results, \")\n",
    "                    \n",
    "                    if \"SELECT\" in script:\n",
    "                        # split only at the first '=' to avoid issues with '=' in SQL\n",
    "                        variable, sql = script.split(\"=\", 1)\n",
    "                        variable = variable.strip()\n",
    "                        sql = sql.strip()\n",
    "                        # get all between \\\" and \\\"\n",
    "                        sql = re.findall(r'\"(.*)\"', sql)\n",
    "                        sql = sql[0]\n",
    "                        # \"SELECT\"ÎùºÎäî Ï≤´ Î≤àÏß∏ Îì±Ïû•Îßå \"SELECT id \"Î°ú ÎåÄÏ≤¥Ìï©ÎãàÎã§.\n",
    "                        sql = sql.replace(\"SELECT\", \"SELECT id, \", 1)\n",
    "                        df = DBManager.execute_structured_query_string(sql)\n",
    "                        cols = list(df.columns)\n",
    "                        cols.remove(\"id\")\n",
    "                        cols.remove(\"idu_name\")\n",
    "                        cols.remove(\"timestamp\")\n",
    "                        rows = list(df[\"id\"])\n",
    "                        query_results.append({\n",
    "                            \"result_columns\": cols,\n",
    "                            \"result_indices\": rows,\n",
    "                        })\n",
    "                        df = df.drop(columns=['id'])\n",
    "                        globals()[variable] = df\n",
    "                    else:\n",
    "                        exec(script, globals())\n",
    "                    \n",
    "                    end_time = time.time()\n",
    "                    if \"data\" in script:\n",
    "                        query_time += end_time - start_time\n",
    "                    else:\n",
    "                        process_time += end_time - start_time\n",
    "                except Exception as e:\n",
    "                    print(f\"Error in executing script: {script}\")\n",
    "                    print(e)\n",
    "                    raise e\n",
    "\n",
    "            start_time = time.time()\n",
    "            variables = {name:globals()[name] for name in globals() if name.startswith(\"v_\")}\n",
    "            response, required_variables = ResponseGeneration.execute_v2(expectations, required_variables, variables, user_input, exp_tag=exp_tag)\n",
    "            rg_last_input_token_length = measure_token_count(ResponseGeneration.last_input_str)\n",
    "            rg_last_output_token_length = measure_token_count(response)\n",
    "            print(\"rg_last_input_token_length,\", rg_last_input_token_length, \",rg_last_output_token_length,\", rg_last_output_token_length)\n",
    "            \n",
    "            response_generation_time = time.time() - start_time\n",
    "\n",
    "            # print(f\"ÏßàÎ¨∏: {user_input}, ÏøºÎ¶¨ Ïã§Ìñâ ÏãúÍ∞Ñ: {query_time:.4f}Ï¥à, ÌîÑÎ°úÏÑ∏Ïä§ Ïã§Ìñâ ÏãúÍ∞Ñ: {process_time:.4f}Ï¥à, ÏùëÎãµ ÏÉùÏÑ± ÏãúÍ∞Ñ: {response_generation_time:.4f}Ï¥à\")\n",
    "            return response, variables, required_variables, query_results\n",
    "        except Exception as e:\n",
    "            print(f\"Error in running query_v2: {e}\")\n",
    "            return \"Ïã§ÌñâÏ§ë ÏóêÎü¨Í∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§.\", variables, None, query_results\n",
    "    else:\n",
    "        if exp_tag in [\"woQM\", \"woQM+Script\"]:\n",
    "            response, required_variables = ResponseGeneration.execute_v2(expectations, required_variables, variables, user_input, exp_tag=exp_tag)\n",
    "            return response, variables, required_variables, query_results\n",
    "        else:\n",
    "            variables = {}\n",
    "            unknown_spatials = [k for k, v in mapping.spatials.items() if v == \"Unknown\"]\n",
    "            unknown_modalities = [k for k, v in mapping.modalities.items() if v == \"Unknown\"]\n",
    "            \n",
    "            response_unknown = f\"Ï£ÑÏÜ°Ìï©ÎãàÎã§, {unknown_spatials + unknown_modalities}Îäî Ï°¥Ïû¨ÌïòÏßÄ ÏïäÎäî Í≥µÍ∞ÑÏù¥ÎÇò Î™®Îã¨Î¶¨Ìã∞ ÏûÖÎãàÎã§.\"\n",
    "            return response_unknown, variables, [], query_results\n",
    "\n",
    "\n",
    "def run_query(user_input, metadata, instructions, exp_tag=None):\n",
    "    variables = {\n",
    "        \"Metadata\": metadata,\n",
    "    }\n",
    "    query_results = []\n",
    "        \n",
    "    \n",
    "    for instruction in instructions:\n",
    "        # logger.debug(f\"Executing instruction: {instruction.__class__.__name__}\")\n",
    "        # print(f\"Executing instruction: {instruction.__class__.__name__}\")\n",
    "        \n",
    "        if type(instruction) == InstructionQ:\n",
    "            # Execute query\n",
    "            result_df = DBManager.structured_query_data_t(metadata, instruction.args, get_rowids=True)\n",
    "            # if result_df is None:\n",
    "                # print(\"Ï£ÑÏÜ°Ìï©ÎãàÎã§, Í¥ÄÎ†® Îç∞Ïù¥ÌÑ∞Î•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.\", \"response\")\n",
    "                # return\n",
    "\n",
    "            cols = list(result_df.columns)\n",
    "            cols.remove(\"id\")\n",
    "            cols.remove(\"idu\")\n",
    "            rows = list(result_df[\"id\"])\n",
    "\n",
    "            query_results.append({\n",
    "                \"result_columns\": cols,\n",
    "                \"result_indices\": rows,\n",
    "            })\n",
    "\n",
    "            # For demo, drop rows where any value is -1\n",
    "            result_df = result_df.loc[(result_df != -1).all(axis=1)]\n",
    "\n",
    "            # drop \"id\" from result_df\n",
    "            result_df = result_df.drop(columns=['id'])\n",
    "           \n",
    "            #pd.set_option('display.max_rows', 10000)        \n",
    "            #pd.set_option('display.max_columns', 1000)\n",
    "            #pd.set_option('display.width', 1000)\n",
    "            #pd.set_option('display.max_colwidth', 1000)\n",
    "            #print(f\"QueryResult: {result_df}\")\n",
    "\n",
    "            variables[instruction.result_name] = result_df\n",
    "        elif type(instruction) == InstructionQ_raw:\n",
    "            instruction.query = instruction.query.replace(\" FROM \\\"data_t\\\"\", \", \\\"id\\\" FROM \\\"data_t\\\"\")\n",
    "            result_df = DBManager.execute_structured_query_string(\n",
    "                instruction.query\n",
    "            )\n",
    "            # rename idu_name to idu\n",
    "            result_df = result_df.rename(columns={'idu_name': 'idu'})\n",
    "            \n",
    "            cols = list(result_df.columns)\n",
    "            cols.remove(\"id\")\n",
    "            cols.remove(\"idu\")\n",
    "            rows = list(result_df[\"id\"])\n",
    "\n",
    "            query_results.append({\n",
    "                \"result_columns\": cols,\n",
    "                \"result_indices\": rows,\n",
    "            })\n",
    "\n",
    "            # drop \"id\" from result_df\n",
    "            result_df = result_df.drop(columns=['id'])\n",
    "            \n",
    "            variables[instruction.result_name] = result_df\n",
    "            # print(result_df, flush=True)\n",
    "\n",
    "        elif type(instruction) == InstructionO:\n",
    "            # Execute operation\n",
    "            # variables_to_report = {k: v for k, v in variables.items() if k not in [\"Metadata\"]}\n",
    "            # print(variables_to_report)\n",
    "            result_dict = OperationExecutor.execute(variables, instruction.scripts)\n",
    "            # print(instruction.scripts, instruction.returns, result_dict)\n",
    "            variables.update(result_dict)\n",
    "            pass\n",
    "            # print(fig, \"graph\")\n",
    "        elif type(instruction) == InstructionR:\n",
    "            # Execute response generation\n",
    "            variables_to_report = {k: v for k, v in variables.items() if k not in [\"Metadata\"]}\n",
    "            # print(variables_to_report)\n",
    "            # variables_to_report = ResponseGeneration.stringify_variables(variables_to_report)\n",
    "            # variables_to_report = summarize_variables_to_report(variables_to_report)\n",
    "\n",
    "            # print(f\"Variables: {variables_to_report}\")\n",
    "\n",
    "            keys_to_leave = [\"modality_mapping\", \"idu_mapping\"]\n",
    "            metadata_ = {}\n",
    "            for key in metadata.keys():\n",
    "                if key in keys_to_leave:\n",
    "                    metadata_[key] = metadata[key]\n",
    "\n",
    "            response, required_variables = ResponseGeneration.execute(instruction, variables, user_input, metadata_, exp_tag=exp_tag)\n",
    "            # print(f\"Required variables: {required_variables}\")\n",
    "            \n",
    "            # response = instruction.expectations[0] # \"{{var}}...\"\n",
    "            # for var_name, var_value in required_variables.items():\n",
    "            #     placeholder = f\"{{{{{var_name}}}}}\"\n",
    "            #     if placeholder in response:\n",
    "            #         response = response.replace(placeholder, str(var_value))\n",
    "\n",
    "            \n",
    "            return response, variables_to_report, required_variables, query_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import Any  # Any ÌÉÄÏûÖ import ÌïÑÏöî\n",
    "from copy import deepcopy\n",
    "class EM:\n",
    "    json_structure = \"JsonStructureCorrectness\"\n",
    "    true_positive = \"QueryTruePositive\"\n",
    "    false_positive = \"QueryFalsePositive\"\n",
    "    false_negative = \"QueryFalseNegative\"\n",
    "    \n",
    "def eval_query(cand_response_filename, db_gt_filename=\"./gts.json\"):\n",
    "    db_gts = read_json(db_gt_filename)\n",
    "    cand_responses = read_json(cand_response_filename)\n",
    "    # metadata_ = read_json(f\"{BASE_DIR}/finetuning/dataset/v7-250309-reduceinputanddatefunctioncall/scenario1/metadata.json\")\n",
    "    evaluation_reports = []\n",
    "    response_reports = []\n",
    "    time_reports = []\n",
    "    with tqdm(total=len(cand_responses)) as pbar:\n",
    "        for cand_response in cand_responses:\n",
    "            # pbar.set_description(f\"Processing {cand_response['Input']}\")\n",
    "            input = cand_response[\"Input\"]\n",
    "            scenario = cand_response[\"Scenario\"]\n",
    "\n",
    "            # if \"ÏòÜÎ∞ò ÏäµÎèÑ ÏïåÎ†§Ï§ò\" not in input:\n",
    "            #     continue\n",
    "\n",
    "            if \"Metadata\" in cand_response:\n",
    "                metadata = cand_response[\"Metadata\"]\n",
    "            else:\n",
    "                # metadata = metadata_\n",
    "                metadata = None\n",
    "            # Í¥ÄÍ≥Ñ ÏóÜÎäî ÏßàÎ¨∏Îì§ÏùÄ Í±¥ÎÑàÎõ∞Ïûê\n",
    "            gt_report = [d for d in db_gts if d[\"Input\"] == input and d[\"Scenario\"] == scenario]\n",
    "            assert len(gt_report) <= 1\n",
    "            if len(gt_report) == 0:\n",
    "                print(f\"No ground truth found for {input}\")\n",
    "                pbar.update(1)\n",
    "                continue\n",
    "\n",
    "            gt_report = gt_report[0]\n",
    "            tags = gt_report[\"Tags\"]\n",
    "            # assert gt_report[\"QueryResults\"] != []\n",
    "            # if gt_report[\"Result\"] == []:\n",
    "            #     pbar.update(1)\n",
    "            #     continue\n",
    "            \n",
    "            \n",
    "            gt_results = [d for d in gt_report[\"QueryResults\"]]\n",
    "            gt_query_results = defaultdict(list)\n",
    "            for gt_result in gt_results:\n",
    "                for col in gt_result[\"result_columns\"]:\n",
    "                    gt_query_results[col].extend(gt_result[\"result_indices\"])\n",
    "\n",
    "            gt_total_combinations = sum(len(v) for v in gt_query_results.values())\n",
    "\n",
    "            gt_response = gt_report[\"Response\"]\n",
    "            # gt_required_variables = gt_report[\"RequiredVariables\"]\n",
    "            # gt_variables_to_report = gt_report[\"VariablesToReport\"]\n",
    "            user_input = gt_report[\"Input\"]\n",
    "            # print(user_input)\n",
    "            exp_tag = cand_response_filename.split(\"/\")[-1].split(\"_\")[3]\n",
    "            print(cand_response_filename, exp_tag)\n",
    "            response_report = {\n",
    "                \"Input\": user_input,\n",
    "                \"Metadata\": metadata,\n",
    "                \"GT_Response\": gt_response,\n",
    "                # \"GT_RequiredVariables\": gt_required_variables,\n",
    "                # \"GT_VariablesToReport\": gt_variables_to_report,\n",
    "            }\n",
    "            # evaluation_report ÎîïÏÖîÎÑàÎ¶¨ ÏÉùÏÑ± (defaultdict ÏÇ¨Ïö©, Í∏∞Î≥∏Í∞í None)\n",
    "\n",
    "            evaluation_report: dict[str, Any] = defaultdict(lambda: None)\n",
    "            evaluation_report[\"Input\"] = input\n",
    "            evaluation_report[\"Metadata\"] = metadata\n",
    "            evaluation_report[\"Tags\"] = tags\n",
    "\n",
    "            \n",
    "            \n",
    "            if isinstance(cand_response[\"Candidate\"], dict):\n",
    "                requirements = [\"Thinking\", \"Expectations\", \"Mapping\"]\n",
    "                if exp_tag in [\"WoThinking\", \"WoMetadata+Thinking\"]:\n",
    "                    requirements.remove(\"Thinking\")\n",
    "                elif exp_tag in [\"woExp\"]:\n",
    "                    requirements.remove(\"Expectations\")\n",
    "                elif exp_tag in [\"woQM\", \"woQM+Script\"]:\n",
    "                    requirements.remove(\"Mapping\")\n",
    "                for requirement in requirements:\n",
    "                    if requirement not in cand_response[\"Candidate\"]:\n",
    "                        evaluation_report[EM.json_structure] = False\n",
    "                        break\n",
    "                else:\n",
    "                    evaluation_report[EM.json_structure] = True\n",
    "            else:\n",
    "                evaluation_report[EM.json_structure] = False\n",
    "            \n",
    "            if not evaluation_report[EM.json_structure]:\n",
    "                evaluation_report[EM.true_positive] = 0\n",
    "                evaluation_report[EM.false_positive] = 0\n",
    "                evaluation_report[EM.false_negative] = gt_total_combinations\n",
    "\n",
    "                print(\"Failed to parse input: \", input, cand_response[\"Candidate\"])\n",
    "                evaluation_reports.append(evaluation_report)\n",
    "                pbar.update(1)\n",
    "                response_reports.append(response_report)\n",
    "                continue\n",
    "            \n",
    "            start_time = time.time()\n",
    "            expertLLM_output_token_length = measure_token_count(cand_response[\"Candidate\"])\n",
    "            print(\"Input,\", cand_response[\"Input\"], \",expertLLM_output_tlen,\",  expertLLM_output_token_length)\n",
    "\n",
    "            if exp_tag in [\"woExp\"]:\n",
    "                cand_response[\"Candidate\"][\"Expectations\"] = []\n",
    "            if exp_tag in [\"woQM\", \"woQM+Script\"]:\n",
    "                pass\n",
    "            # exp_tag = \\\n",
    "            #     \"woCoTExp\" if \"woCoTExp\" in str(cand_response_filename) else \\\n",
    "            #     \"woOp\" if \"woOp\" in str(cand_response_filename) else \\\n",
    "            #     \"woQM\" if \"woQM\" in str(cand_response_filename) else \\\n",
    "            #     None\n",
    "            try:\n",
    "                mapping, expectations, required_variables, script = InputToInstruction.postprocess_v2(\n",
    "                    deepcopy(cand_response[\"Candidate\"]), \n",
    "                    exp_tag=exp_tag\n",
    "                )\n",
    "            except:\n",
    "                evaluation_report[EM.true_positive] = 0\n",
    "                evaluation_report[EM.false_positive] = 0\n",
    "                evaluation_report[EM.false_negative] = gt_total_combinations\n",
    "                            \n",
    "                evaluation_reports.append(evaluation_report)\n",
    "                pbar.update(1)\n",
    "                response_reports.append(response_report)\n",
    "                continue\n",
    "            \n",
    "\n",
    "            \n",
    "            response, variables_to_report, required_variables, _cand_query_results = run_query_v2(user_input, metadata, mapping, expectations, required_variables, script, exp_tag=exp_tag)\n",
    "            # print(response)\n",
    "            response_report[\"PD_Response\"] = response\n",
    "            # try:\n",
    "            #     # response, variables_to_report, required_variables, _cand_query_results = run_query_v2(user_input, metadata, instructions, exp_tag=exp_tag)\n",
    "            # except Exception as e:\n",
    "            #     print(f\"Error: {e}\")\n",
    "            #     # evaluation_report[EM.true_positive] = 0\n",
    "            #     # evaluation_report[EM.false_positive] = 0\n",
    "            #     # evaluation_report[EM.false_negative] = gt_total_combinations\n",
    "                            \n",
    "            #     # evaluation_reports.append(evaluation_report)\n",
    "\n",
    "            #     # response_reports.append(response_report)\n",
    "                            \n",
    "            #     # pbar.update(1)\n",
    "            #     # continue\n",
    "            time_reports.append(time.time() - start_time)\n",
    "            response_reports.append(response_report)\n",
    "            \n",
    "            # required_variables = summarize_variables_to_report(required_variables)\n",
    "            # print(required_variables)\n",
    "            # required_variables = ResponseGeneration.stringify_variables(required_variables)\n",
    "            \n",
    "            # response_report[\"PD_RequiredVariables\"] = required_variables\n",
    "            # response_report[\"PD_VariablesToReport\"] = variables_to_report\n",
    "\n",
    "            if len(_cand_query_results) == 0:\n",
    "                evaluation_report[EM.true_positive] = 0\n",
    "                evaluation_report[EM.false_positive] = 0\n",
    "                evaluation_report[EM.false_negative] = gt_total_combinations\n",
    "                            \n",
    "                evaluation_reports.append(evaluation_report)\n",
    "                pbar.update(1)\n",
    "                continue\n",
    "            \n",
    "            cand_query_results = defaultdict(list)\n",
    "            for cand_query_result in _cand_query_results:\n",
    "                for col in cand_query_result[\"result_columns\"]:\n",
    "                    cand_query_results[col].extend(cand_query_result[\"result_indices\"])\n",
    "\n",
    "            cand_total_combinations = sum(len(v) for v in gt_query_results.values())\n",
    "\n",
    "            if len(gt_results) == 0:\n",
    "                evaluation_report[EM.true_positive] = 0\n",
    "                evaluation_report[EM.false_positive] = cand_total_combinations\n",
    "                evaluation_report[EM.false_negative] = 0\n",
    "\n",
    "                evaluation_reports.append(evaluation_report)\n",
    "                pbar.update(1)\n",
    "\n",
    "                continue\n",
    "            \n",
    "            # print(gt_total_combinations, cand_total_combinations)\n",
    "            # True Positive: Í≥µÌÜµÎêú Ïª¨ÎüºÍ≥º Î°úÏö∞Ïùò Î™®Îì† Ï°∞Ìï©\n",
    "            true_positive = 0\n",
    "            false_negative = 0\n",
    "            false_positive = 0\n",
    "            for col in set(gt_query_results.keys())&set(cand_query_results.keys()):\n",
    "                s_gt_query_result = set(gt_query_results[col])\n",
    "                s_cand_query_result = set(cand_query_results[col])\n",
    "                true_positive += len(s_gt_query_result & s_cand_query_result)\n",
    "                false_negative += len(s_gt_query_result - s_cand_query_result)\n",
    "                false_positive += len(s_cand_query_result - s_gt_query_result)\n",
    "\n",
    "                # print(true_positive, false_negative, false_positive, len(s_gt_query_result), len(s_cand_query_result))\n",
    "            # assert true_positive + false_positive + false_negative == gt_total_combinations\n",
    "            \n",
    "\n",
    "            evaluation_report[EM.true_positive] = true_positive\n",
    "            evaluation_report[EM.false_positive] = false_positive\n",
    "            evaluation_report[EM.false_negative] = false_negative\n",
    "\n",
    "            evaluation_reports.append(evaluation_report)\n",
    "            # print(evaluation_report)\n",
    "            \n",
    "            pbar.update(1)\n",
    "\n",
    "    with open(f\"{cand_response_filename.replace('.json', '_response.json')}\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(response_reports, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(f\"Time: {time_reports}, {sum(time_reports) / len(time_reports)}\")\n",
    "\n",
    "    eval_df = pd.DataFrame(evaluation_reports)\n",
    "    # print(eval_df)\n",
    "\n",
    "    eval_df['ExactMatch'] = eval_df.apply(lambda x: x[EM.false_positive] == 0 and x[EM.false_negative] == 0, axis=1).astype(int)\n",
    "    # eval_df['TruePositive'] = eval_df['TruePositive'].astype(int)\n",
    "    # eval_df['FalsePositive'] = eval_df['FalsePositive'].astype(int)\n",
    "    # eval_df['FalseNegative'] = eval_df['FalseNegative'].astype(int)\n",
    "\n",
    "    final_result = {}\n",
    "\n",
    "    for col in [\"JsonStructureCorrectness\", \"ExactMatch\"]:\n",
    "        # print(f\"{col}: {eval_df[col].mean()}\")\n",
    "        final_result[col] = eval_df[col].mean()\n",
    "    \n",
    "    # normalize per query\n",
    "    eval_df[\"Total\"] = eval_df[EM.true_positive] + eval_df[EM.false_positive] + eval_df[EM.false_negative]\n",
    "    eval_print = eval_df.drop(columns=[\"Metadata\", \"Tags\"])\n",
    "    print(eval_print)\n",
    "    eval_df[EM.true_positive] = eval_df[EM.true_positive] / eval_df[\"Total\"]\n",
    "    eval_df[EM.false_positive] = eval_df[EM.false_positive] / eval_df[\"Total\"]\n",
    "    eval_df[EM.false_negative] = eval_df[EM.false_negative] / eval_df[\"Total\"]\n",
    "\n",
    "    # # replace nan with 0\n",
    "    # eval_df.fillna(0, inplace=True)\n",
    "\n",
    "    # # F1 score except nans.\n",
    "    truepos_sum, falsepos_sum, falseneg_sum = eval_df[EM.true_positive].sum(), eval_df[EM.false_positive].sum(), eval_df[EM.false_negative].sum()\n",
    "    precision = truepos_sum / (truepos_sum + falsepos_sum)\n",
    "    recall = truepos_sum / (truepos_sum + falseneg_sum)\n",
    "    print(truepos_sum, falsepos_sum, falseneg_sum)\n",
    "    print(precision, recall)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    # print(f\"F1: {f1}\")\n",
    "    final_result[\"F1\"] = f1\n",
    "    final_result[\"Recall\"] = recall\n",
    "\n",
    "    for col in final_result:\n",
    "        print(f\"{col}: {final_result[col]:.2f}\")\n",
    "    \n",
    "    return eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../experiments/result_3rdyear/r-3rdyear_r211_a422_sh2orc-Llama-3.1-Korean-8B-Instruct_tr27_4bit-step-41.json sh2orc-Llama-3.1-Korean-8B-Instruct\n",
      "Input, Ïù¥Î≤àÏ£º Ïö∞Î¶¨Î∞òÍ≥º ÏïûÎ∞òÏùò ÌèâÍ∑† Ïò®ÎèÑ ÏïåÎ†§Ï§ò ,expertLLM_output_tlen, 456\n",
      "cols: ['roomtemp', 'idu_name', 'id', 'timestamp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cols: ['roomtemp', 'idu_name', 'id', 'timestamp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|‚ñä         | 1/12 [00:02<00:29,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rg_last_input_token_length, 221 ,rg_last_output_token_length, 57\n",
      "../experiments/result_3rdyear/r-3rdyear_r211_a422_sh2orc-Llama-3.1-Korean-8B-Instruct_tr27_4bit-step-41.json sh2orc-Llama-3.1-Korean-8B-Instruct\n",
      "Input, ÌòÑÏû¨ ÏÑ§Ï†ïÏò®ÎèÑÎûë Ïã§ÎÇ¥Ïò®ÎèÑ Ï∞®Ïù¥ ÏïåÎ†§Ï§ò. ,expertLLM_output_tlen, 333\n",
      "cols: ['roomtemp', 'idu_name', 'settemp', 'id', 'timestamp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|‚ñà‚ñã        | 2/12 [00:03<00:14,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rg_last_input_token_length, 149 ,rg_last_output_token_length, 35\n",
      "../experiments/result_3rdyear/r-3rdyear_r211_a422_sh2orc-Llama-3.1-Korean-8B-Instruct_tr27_4bit-step-41.json sh2orc-Llama-3.1-Korean-8B-Instruct\n",
      "Input, ÏßÄÎÇúÎã¨Ïóê ÏÑ§Ï†ïÏò®ÎèÑÏôÄ Ïã§ÎÇ¥Ïò®ÎèÑ Ï∞®Ïù¥Í∞Ä Í∞ÄÏû• ÎßéÏù¥ ÎÇ¨Îçò ÎÇ†ÏùÄ? ,expertLLM_output_tlen, 746\n",
      "cols: ['idu_name', 'settemp', 'id', 'timestamp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|‚ñà‚ñà‚ñå       | 3/12 [00:05<00:16,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cols: ['roomtemp', 'idu_name', 'id', 'timestamp']\n",
      "get_time, col: Index(['ÏÑ§Ï†ïÏò®ÎèÑ_Ïã§ÎÇ¥Ïò®ÎèÑ_Ï∞®Ïù¥'], dtype='object'), fmt: %Y-%m-%d\n",
      "Error in executing script: v_ÏßÄÎÇúÎã¨_ÏÑ§Ï†ïÏò®ÎèÑ_Ïã§ÎÇ¥Ïò®ÎèÑ_Ï∞®Ïù¥_ÏµúÍ≥†_ÎÇ†Ïßú = get_time(v_ÏßÄÎÇúÎã¨_ÏÑ§Ï†ïÏò®ÎèÑ_Ïã§ÎÇ¥Ïò®ÎèÑ_Ï∞®Ïù¥_ÏµúÍ≥†_df, fmt='date')\n",
      "'timestamp'\n",
      "Error in running query_v2: 'timestamp'\n",
      "../experiments/result_3rdyear/r-3rdyear_r211_a422_sh2orc-Llama-3.1-Korean-8B-Instruct_tr27_4bit-step-41.json sh2orc-Llama-3.1-Korean-8B-Instruct\n",
      "Input, Ïù¥Î≤àÏ£º Ïö∞Î¶¨Î∞òÍ≥º ÏòÜÎ∞òÏùò ÌèâÍ∑† Ïã§ÎÇ¥Ïò®ÎèÑ Ï∞®Ïù¥ ÏïåÎ†§Ï§ò ,expertLLM_output_tlen, 444\n",
      "cols: ['roomtemp', 'idu_name', 'id', 'timestamp']\n",
      "cols: ['roomtemp', 'idu_name', 'id', 'timestamp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 4/12 [00:08<00:17,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rg_last_input_token_length, 213 ,rg_last_output_token_length, 45\n",
      "../experiments/result_3rdyear/r-3rdyear_r211_a422_sh2orc-Llama-3.1-Korean-8B-Instruct_tr27_4bit-step-41.json sh2orc-Llama-3.1-Korean-8B-Instruct\n",
      "Input, 2Ï£ºÏ†Ñ Í∞ÄÏû• ÎçîÏõ†Îçò ÎÇ† ÏïåÎ†§Ï§ò ,expertLLM_output_tlen, 363\n",
      "cols: ['roomtemp', 'idu_name', 'id', 'timestamp']\n",
      "get_time, col: Index(['Ïã§ÎÇ¥Ïò®ÎèÑ', 'idu_name', 'timestamp'], dtype='object'), fmt: %Y-%m-%d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 5/12 [00:09<00:12,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rg_last_input_token_length, 142 ,rg_last_output_token_length, 29\n",
      "../experiments/result_3rdyear/r-3rdyear_r211_a422_sh2orc-Llama-3.1-Korean-8B-Instruct_tr27_4bit-step-41.json sh2orc-Llama-3.1-Korean-8B-Instruct\n",
      "Input, ÌôîÏÑ±Ïùò ÏÑ§Ï†ïÏò®ÎèÑ ÌôïÏù∏Ìï¥Ï§ò ,expertLLM_output_tlen, 105\n",
      "../experiments/result_3rdyear/r-3rdyear_r211_a422_sh2orc-Llama-3.1-Korean-8B-Instruct_tr27_4bit-step-41.json sh2orc-Llama-3.1-Korean-8B-Instruct\n",
      "Input, ÏòÜÎ∞ò ÏäµÎèÑ ÏïåÎ†§Ï§ò ,expertLLM_output_tlen, 109\n",
      "../experiments/result_3rdyear/r-3rdyear_r211_a422_sh2orc-Llama-3.1-Korean-8B-Instruct_tr27_4bit-step-41.json sh2orc-Llama-3.1-Korean-8B-Instruct\n",
      "Input, ÏßÄÎÇú 3Ïùº ÎèôÏïà Ïö∞Î¶¨Î∞ò Ïã§ÎÇ¥ Ïò®ÎèÑ ÌèâÍ∑† Í∞í ÏïåÎ†§Ï§ò. ,expertLLM_output_tlen, 245\n",
      "cols: ['roomtemp', 'idu_name', 'id', 'timestamp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 8/12 [00:09<00:03,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rg_last_input_token_length, 98 ,rg_last_output_token_length, 23\n",
      "../experiments/result_3rdyear/r-3rdyear_r211_a422_sh2orc-Llama-3.1-Korean-8B-Instruct_tr27_4bit-step-41.json sh2orc-Llama-3.1-Korean-8B-Instruct\n",
      "Input, Ïò§Îäò Ïò§ÌõÑ 5ÏãúÏóê ÏòÜÎ∞òÏùò ÏÑ§Ï†ïÏò®ÎèÑÎäî Ïñ¥Îï†Ïñ¥? ,expertLLM_output_tlen, 248\n",
      "cols: ['idu_name', 'settemp', 'id', 'timestamp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 9/12 [00:10<00:02,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rg_last_input_token_length, 97 ,rg_last_output_token_length, 22\n",
      "../experiments/result_3rdyear/r-3rdyear_r211_a422_sh2orc-Llama-3.1-Korean-8B-Instruct_tr27_4bit-step-41.json sh2orc-Llama-3.1-Korean-8B-Instruct\n",
      "Input, Ïò¨Ìï¥ Ïó¨Î¶Ñ Ïö∞Î¶¨Î∞ò Ïã§ÎÇ¥Ïò®ÎèÑ ÏµúÎåÄÍ∞íÍ≥º ÏµúÏÜåÍ∞í ÏïåÎ†§Ï§ò ,expertLLM_output_tlen, 318\n",
      "cols: ['roomtemp', 'idu_name', 'id', 'timestamp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 10/12 [00:12<00:02,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rg_last_input_token_length, 149 ,rg_last_output_token_length, 33\n",
      "../experiments/result_3rdyear/r-3rdyear_r211_a422_sh2orc-Llama-3.1-Korean-8B-Instruct_tr27_4bit-step-41.json sh2orc-Llama-3.1-Korean-8B-Instruct\n",
      "Failed to parse input:  Ïö∞Î¶¨Î∞òÍ≥º ÏïûÎ∞ò Ï§ë Í∞ÄÏû• ÎçîÏö¥ Î∞©ÏùÄ? {\"Thinking\": \"ÏÇ¨Ïö©ÏûêÎäî ÌòÑÏû¨ Ïö∞Î¶¨Î∞òÍ≥º ÏïûÎ∞ò Ï§ë Ïã§ÎÇ¥Ïò®ÎèÑÍ∞Ä Îçî ÎÜíÏùÄ Í≥≥ÏùÑ ÏïåÍ≥†Ïã∂Ïñ¥Ìï®. ÌòÑÏû¨ Ïö∞Î¶¨Î∞òÍ≥º ÏïûÎ∞òÏùò Ïã§ÎÇ¥Ïò®ÎèÑÎ•º ÏøºÎ¶¨Ìïú ÌõÑ Îçî ÎÜíÏùÄ Ïã§ÎÇ¥Ïò®ÎèÑÎ•º Í∞ÄÏßÑ Î∞©Í≥º Í∑∏ Ïò®ÎèÑÎ•º Î∞òÌôòÌïòÎ©¥ Îê®.\", \"Expectations\": [\"{{ÌòÑÏû¨_Ïã§ÎÇ¥Ïò®ÎèÑ_ÏµúÍ≥†_Í≥µÍ∞Ñ}}({{ÌòÑÏû¨_Ïã§ÎÇ¥Ïò®ÎèÑ_ÏµúÍ≥†_Í≥µÍ∞Ñ_Ïã§ÎÇ¥Ïò®ÎèÑ}}‚ÑÉ)Ïù¥ {{ÌòÑÏû¨_Ïã§ÎÇ¥Ïò®ÎèÑ_ÏµúÍ≥†_Í≥µÍ∞ÑÎ≥Ñ_Í≥µÍ∞Ñ}}Î≥¥Îã§ {{ÌòÑÏû¨_Ïã§ÎÇ¥Ïò®ÎèÑ_ÏµúÍ≥†_Í≥µÍ∞ÑÎ≥Ñ_Í≥µÍ∞Ñ_Ï∞®Ïù¥}}‚ÑÉ Îçî ÎÜíÏäµÎãàÎã§.\"], \"Mapping\": {\"temporal\": {\"ÌòÑÏû¨\": \"LAST_RECORD\"}, \"spatials\": {\"Ïö∞Î¶¨Î∞ò\": \"02_I81\", \"ÏïûÎ∞ò\": \"01_IB7\"}, \"modalities\": {\"Ïã§ÎÇ¥Ïò®ÎèÑ\": \"roomtemp\"}}, \"Script\": [\"v_ÌòÑÏû¨_Ïö∞Î¶¨Î∞ò_Ïã§ÎÇ¥Ïò®ÎèÑ_df = data(t='ÌòÑÏû¨',s='Ïö∞Î¶¨Î∞ò',m='Ïã§ÎÇ¥Ïò®ÎèÑ')\", \"v_ÌòÑÏû¨_ÏïûÎ∞ò_Ïã§ÎÇ¥Ïò®ÎèÑ_df = data(t='ÌòÑÏû¨',s='ÏïûÎ∞ò',m='Ïã§ÎÇ¥Ïò®ÎèÑ')\", \"v_ÌòÑÏû¨_Ïã§ÎÇ¥Ïò®ÎèÑ = {'Ïö∞Î¶¨Î∞ò': v_ÌòÑÏû¨_Ïö∞Î¶¨Î∞ò_Ïã§ÎÇ¥Ïò®ÎèÑ_df['Ïã§ÎÇ¥Ïò®ÎèÑ'].max(), 'ÏïûÎ∞ò': v_ÌòÑÏû¨_ÏïûÎ∞ò_Ïã§ÎÇ¥Ïò®ÎèÑ_df['Ïã§ÎÇ¥Ïò®ÎèÑ'].max()}\", \"v_ÌòÑÏû¨_Ïã§ÎÇ¥Ïò®ÎèÑ_ÏµúÍ≥†_Í≥µÍ∞Ñ, v_ÌòÑÏû¨_Ïã§ÎÇ¥Ïò®ÎèÑ_ÏµúÍ≥†_Í≥µÍ∞Ñ_Ïã§ÎÇ¥Ïò®ÎèÑ = max(v_ÌòÑÏû¨_Ïã§ÎÇ¥Ïò®ÎèÑ.items(), key=lambda x:x[1])\n",
      "]}\n",
      "../experiments/result_3rdyear/r-3rdyear_r211_a422_sh2orc-Llama-3.1-Korean-8B-Instruct_tr27_4bit-step-41.json sh2orc-Llama-3.1-Korean-8B-Instruct\n",
      "Input, ÏßÄÍ∏à 4Ï∏µ ÌèâÍ∑† Ïã§ÎÇ¥Ïò®ÎèÑ ÏïåÎ†§Ï§ò ,expertLLM_output_tlen, 245\n",
      "cols: ['roomtemp', 'idu_name', 'id', 'timestamp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:12<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rg_last_input_token_length, 82 ,rg_last_output_token_length, 19\n",
      "Time: [2.6505610942840576, 0.6098086833953857, 2.1940596103668213, 2.70094895362854, 0.9671032428741455, 0.00032258033752441406, 0.0001811981201171875, 0.6127476692199707, 0.4335818290710449, 2.0798933506011963, 0.405653715133667], 1.1504419933665881\n",
      "                               Input  JsonStructureCorrectness  \\\n",
      "0             Ïù¥Î≤àÏ£º Ïö∞Î¶¨Î∞òÍ≥º ÏïûÎ∞òÏùò ÌèâÍ∑† Ïò®ÎèÑ ÏïåÎ†§Ï§ò                      True   \n",
      "1              ÌòÑÏû¨ ÏÑ§Ï†ïÏò®ÎèÑÎûë Ïã§ÎÇ¥Ïò®ÎèÑ Ï∞®Ïù¥ ÏïåÎ†§Ï§ò.                      True   \n",
      "2   ÏßÄÎÇúÎã¨Ïóê ÏÑ§Ï†ïÏò®ÎèÑÏôÄ Ïã§ÎÇ¥Ïò®ÎèÑ Ï∞®Ïù¥Í∞Ä Í∞ÄÏû• ÎßéÏù¥ ÎÇ¨Îçò ÎÇ†ÏùÄ?                      True   \n",
      "3        Ïù¥Î≤àÏ£º Ïö∞Î¶¨Î∞òÍ≥º ÏòÜÎ∞òÏùò ÌèâÍ∑† Ïã§ÎÇ¥Ïò®ÎèÑ Ï∞®Ïù¥ ÏïåÎ†§Ï§ò                      True   \n",
      "4                   2Ï£ºÏ†Ñ Í∞ÄÏû• ÎçîÏõ†Îçò ÎÇ† ÏïåÎ†§Ï§ò                      True   \n",
      "5                      ÌôîÏÑ±Ïùò ÏÑ§Ï†ïÏò®ÎèÑ ÌôïÏù∏Ìï¥Ï§ò                      True   \n",
      "6                          ÏòÜÎ∞ò ÏäµÎèÑ ÏïåÎ†§Ï§ò                      True   \n",
      "7       ÏßÄÎÇú 3Ïùº ÎèôÏïà Ïö∞Î¶¨Î∞ò Ïã§ÎÇ¥ Ïò®ÎèÑ ÌèâÍ∑† Í∞í ÏïåÎ†§Ï§ò.                      True   \n",
      "8           Ïò§Îäò Ïò§ÌõÑ 5ÏãúÏóê ÏòÜÎ∞òÏùò ÏÑ§Ï†ïÏò®ÎèÑÎäî Ïñ¥Îï†Ïñ¥?                      True   \n",
      "9        Ïò¨Ìï¥ Ïó¨Î¶Ñ Ïö∞Î¶¨Î∞ò Ïã§ÎÇ¥Ïò®ÎèÑ ÏµúÎåÄÍ∞íÍ≥º ÏµúÏÜåÍ∞í ÏïåÎ†§Ï§ò                      True   \n",
      "10               Ïö∞Î¶¨Î∞òÍ≥º ÏïûÎ∞ò Ï§ë Í∞ÄÏû• ÎçîÏö¥ Î∞©ÏùÄ?                     False   \n",
      "11                 ÏßÄÍ∏à 4Ï∏µ ÌèâÍ∑† Ïã§ÎÇ¥Ïò®ÎèÑ ÏïåÎ†§Ï§ò                      True   \n",
      "\n",
      "    QueryTruePositive  QueryFalsePositive  QueryFalseNegative  ExactMatch  \\\n",
      "0               14214                   0                   0           1   \n",
      "1                   2                   0                   0           1   \n",
      "2               88160                   0                   0           1   \n",
      "3               14201                   0                   0           1   \n",
      "4                9935                   0                   0           1   \n",
      "5                   0                   0                   0           1   \n",
      "6                   0                   0                   0           1   \n",
      "7                4268                   0                   0           1   \n",
      "8                   1                   0                   0           1   \n",
      "9               44080                   0                   0           1   \n",
      "10                  0                   0                   2           0   \n",
      "11                  3                   0                   0           1   \n",
      "\n",
      "    Total  \n",
      "0   14214  \n",
      "1       2  \n",
      "2   88160  \n",
      "3   14201  \n",
      "4    9935  \n",
      "5       0  \n",
      "6       0  \n",
      "7    4268  \n",
      "8       1  \n",
      "9   44080  \n",
      "10      2  \n",
      "11      3  \n",
      "9.0 0.0 1.0\n",
      "1.0 0.9\n",
      "JsonStructureCorrectness: 0.92\n",
      "ExactMatch: 0.92\n",
      "F1: 0.95\n",
      "Recall: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../experiments/result_3rdyear/r-3rdyear_r211_a422_sh2orc-Llama-3.1-Korean-8B-Instruct_tr27_8bit-step-41.json sh2orc-Llama-3.1-Korean-8B-Instruct\n",
      "Input, Ïù¥Î≤àÏ£º Ïö∞Î¶¨Î∞òÍ≥º ÏïûÎ∞òÏùò ÌèâÍ∑† Ïò®ÎèÑ ÏïåÎ†§Ï§ò ,expertLLM_output_tlen, 362\n",
      "cols: ['roomtemp', 'idu_name', 'id', 'timestamp']\n",
      "cols: ['roomtemp', 'idu_name', 'id', 'timestamp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|‚ñä         | 1/12 [00:01<00:13,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rg_last_input_token_length, 153 ,rg_last_output_token_length, 36\n",
      "../experiments/result_3rdyear/r-3rdyear_r211_a422_sh2orc-Llama-3.1-Korean-8B-Instruct_tr27_8bit-step-41.json sh2orc-Llama-3.1-Korean-8B-Instruct\n",
      "Input, ÌòÑÏû¨ ÏÑ§Ï†ïÏò®ÎèÑÎûë Ïã§ÎÇ¥Ïò®ÎèÑ Ï∞®Ïù¥ ÏïåÎ†§Ï§ò. ,expertLLM_output_tlen, 379\n",
      "cols: ['idu_name', 'settemp', 'id', 'timestamp']\n",
      "cols: ['roomtemp', 'idu_name', 'id', 'timestamp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|‚ñà‚ñã        | 2/12 [00:01<00:09,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rg_last_input_token_length, 150 ,rg_last_output_token_length, 36\n",
      "../experiments/result_3rdyear/r-3rdyear_r211_a422_sh2orc-Llama-3.1-Korean-8B-Instruct_tr27_8bit-step-41.json sh2orc-Llama-3.1-Korean-8B-Instruct\n",
      "Input, ÏßÄÎÇúÎã¨Ïóê ÏÑ§Ï†ïÏò®ÎèÑÏôÄ Ïã§ÎÇ¥Ïò®ÎèÑ Ï∞®Ïù¥Í∞Ä Í∞ÄÏû• ÎßéÏù¥ ÎÇ¨Îçò ÎÇ†ÏùÄ? ,expertLLM_output_tlen, 782\n",
      "Error in executing script: v_ÏßÄÎÇúÎã¨_ÏÑ§Ï†ïÏò®ÎèÑ_df = data_(metadata, mapping, query_results, t='ÏßÄÎÇúÎã¨',s='Ïö∞Î¶¨Î∞ò,ÏïûÎ∞ò,ÏòÜÎ∞ò',m='ÏÑ§Ï†ïÏò®ÎèÑ')\n",
      "'Ïö∞Î¶¨Î∞ò,ÏïûÎ∞ò,ÏòÜÎ∞ò'\n",
      "Error in running query_v2: 'Ïö∞Î¶¨Î∞ò,ÏïûÎ∞ò,ÏòÜÎ∞ò'\n",
      "../experiments/result_3rdyear/r-3rdyear_r211_a422_sh2orc-Llama-3.1-Korean-8B-Instruct_tr27_8bit-step-41.json sh2orc-Llama-3.1-Korean-8B-Instruct\n",
      "Input, Ïù¥Î≤àÏ£º Ïö∞Î¶¨Î∞òÍ≥º ÏòÜÎ∞òÏùò ÌèâÍ∑† Ïã§ÎÇ¥Ïò®ÎèÑ Ï∞®Ïù¥ ÏïåÎ†§Ï§ò ,expertLLM_output_tlen, 443\n",
      "cols: ['roomtemp', 'idu_name', 'id', 'timestamp']\n",
      "cols: ['roomtemp', 'idu_name', 'id', 'timestamp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 4/12 [00:03<00:06,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rg_last_input_token_length, 221 ,rg_last_output_token_length, 53\n",
      "../experiments/result_3rdyear/r-3rdyear_r211_a422_sh2orc-Llama-3.1-Korean-8B-Instruct_tr27_8bit-step-41.json sh2orc-Llama-3.1-Korean-8B-Instruct\n",
      "Input, 2Ï£ºÏ†Ñ Í∞ÄÏû• ÎçîÏõ†Îçò ÎÇ† ÏïåÎ†§Ï§ò ,expertLLM_output_tlen, 421\n",
      "cols: ['roomtemp', 'idu_name', 'id', 'timestamp']\n",
      "get_time, col: Index(['Ïã§ÎÇ¥Ïò®ÎèÑ', 'idu_name', 'timestamp'], dtype='object'), fmt: %Y-%m-%d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 5/12 [00:04<00:06,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rg_last_input_token_length, 58 ,rg_last_output_token_length, 17\n",
      "../experiments/result_3rdyear/r-3rdyear_r211_a422_sh2orc-Llama-3.1-Korean-8B-Instruct_tr27_8bit-step-41.json sh2orc-Llama-3.1-Korean-8B-Instruct\n",
      "Input, ÌôîÏÑ±Ïùò ÏÑ§Ï†ïÏò®ÎèÑ ÌôïÏù∏Ìï¥Ï§ò ,expertLLM_output_tlen, 182\n",
      "cols: ['idu_name', 'settemp', 'id', 'timestamp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 6/12 [00:05<00:04,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rg_last_input_token_length, 71 ,rg_last_output_token_length, 16\n",
      "../experiments/result_3rdyear/r-3rdyear_r211_a422_sh2orc-Llama-3.1-Korean-8B-Instruct_tr27_8bit-step-41.json sh2orc-Llama-3.1-Korean-8B-Instruct\n",
      "Input, ÏòÜÎ∞ò ÏäµÎèÑ ÏïåÎ†§Ï§ò ,expertLLM_output_tlen, 109\n",
      "../experiments/result_3rdyear/r-3rdyear_r211_a422_sh2orc-Llama-3.1-Korean-8B-Instruct_tr27_8bit-step-41.json sh2orc-Llama-3.1-Korean-8B-Instruct\n",
      "Input, ÏßÄÎÇú 3Ïùº ÎèôÏïà Ïö∞Î¶¨Î∞ò Ïã§ÎÇ¥ Ïò®ÎèÑ ÌèâÍ∑† Í∞í ÏïåÎ†§Ï§ò. ,expertLLM_output_tlen, 248\n",
      "cols: ['roomtemp', 'idu_name', 'id', 'timestamp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 8/12 [00:05<00:02,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rg_last_input_token_length, 98 ,rg_last_output_token_length, 23\n",
      "../experiments/result_3rdyear/r-3rdyear_r211_a422_sh2orc-Llama-3.1-Korean-8B-Instruct_tr27_8bit-step-41.json sh2orc-Llama-3.1-Korean-8B-Instruct\n",
      "Input, Ïò§Îäò Ïò§ÌõÑ 5ÏãúÏóê ÏòÜÎ∞òÏùò ÏÑ§Ï†ïÏò®ÎèÑÎäî Ïñ¥Îï†Ïñ¥? ,expertLLM_output_tlen, 247\n",
      "cols: ['idu_name', 'settemp', 'id', 'timestamp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 9/12 [00:06<00:01,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rg_last_input_token_length, 97 ,rg_last_output_token_length, 22\n",
      "../experiments/result_3rdyear/r-3rdyear_r211_a422_sh2orc-Llama-3.1-Korean-8B-Instruct_tr27_8bit-step-41.json sh2orc-Llama-3.1-Korean-8B-Instruct\n",
      "Input, Ïò¨Ìï¥ Ïó¨Î¶Ñ Ïö∞Î¶¨Î∞ò Ïã§ÎÇ¥Ïò®ÎèÑ ÏµúÎåÄÍ∞íÍ≥º ÏµúÏÜåÍ∞í ÏïåÎ†§Ï§ò ,expertLLM_output_tlen, 320\n",
      "cols: ['roomtemp', 'idu_name', 'id', 'timestamp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 10/12 [00:08<00:01,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rg_last_input_token_length, 149 ,rg_last_output_token_length, 33\n",
      "../experiments/result_3rdyear/r-3rdyear_r211_a422_sh2orc-Llama-3.1-Korean-8B-Instruct_tr27_8bit-step-41.json sh2orc-Llama-3.1-Korean-8B-Instruct\n",
      "Input, Ïö∞Î¶¨Î∞òÍ≥º ÏïûÎ∞ò Ï§ë Í∞ÄÏû• ÎçîÏö¥ Î∞©ÏùÄ? ,expertLLM_output_tlen, 444\n",
      "cols: ['roomtemp', 'idu_name', 'id', 'timestamp']\n",
      "cols: ['roomtemp', 'idu_name', 'id', 'timestamp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 11/12 [00:09<00:00,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rg_last_input_token_length, 129 ,rg_last_output_token_length, 23\n",
      "../experiments/result_3rdyear/r-3rdyear_r211_a422_sh2orc-Llama-3.1-Korean-8B-Instruct_tr27_8bit-step-41.json sh2orc-Llama-3.1-Korean-8B-Instruct\n",
      "Input, ÏßÄÍ∏à 4Ï∏µ ÌèâÍ∑† Ïã§ÎÇ¥Ïò®ÎèÑ ÏïåÎ†§Ï§ò ,expertLLM_output_tlen, 216\n",
      "cols: ['roomtemp', 'idu_name', 'id', 'timestamp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:09<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rg_last_input_token_length, 82 ,rg_last_output_token_length, 19\n",
      "Time: [1.2384097576141357, 0.7592594623565674, 0.0006930828094482422, 1.4721522331237793, 1.378847360610962, 0.36470890045166016, 0.0002384185791015625, 0.7318768501281738, 0.433943510055542, 2.073249340057373, 0.5949814319610596, 0.4005870819091797], 0.7874122858047485\n",
      "                               Input  JsonStructureCorrectness  \\\n",
      "0             Ïù¥Î≤àÏ£º Ïö∞Î¶¨Î∞òÍ≥º ÏïûÎ∞òÏùò ÌèâÍ∑† Ïò®ÎèÑ ÏïåÎ†§Ï§ò                      True   \n",
      "1              ÌòÑÏû¨ ÏÑ§Ï†ïÏò®ÎèÑÎûë Ïã§ÎÇ¥Ïò®ÎèÑ Ï∞®Ïù¥ ÏïåÎ†§Ï§ò.                      True   \n",
      "2   ÏßÄÎÇúÎã¨Ïóê ÏÑ§Ï†ïÏò®ÎèÑÏôÄ Ïã§ÎÇ¥Ïò®ÎèÑ Ï∞®Ïù¥Í∞Ä Í∞ÄÏû• ÎßéÏù¥ ÎÇ¨Îçò ÎÇ†ÏùÄ?                      True   \n",
      "3        Ïù¥Î≤àÏ£º Ïö∞Î¶¨Î∞òÍ≥º ÏòÜÎ∞òÏùò ÌèâÍ∑† Ïã§ÎÇ¥Ïò®ÎèÑ Ï∞®Ïù¥ ÏïåÎ†§Ï§ò                      True   \n",
      "4                   2Ï£ºÏ†Ñ Í∞ÄÏû• ÎçîÏõ†Îçò ÎÇ† ÏïåÎ†§Ï§ò                      True   \n",
      "5                      ÌôîÏÑ±Ïùò ÏÑ§Ï†ïÏò®ÎèÑ ÌôïÏù∏Ìï¥Ï§ò                      True   \n",
      "6                          ÏòÜÎ∞ò ÏäµÎèÑ ÏïåÎ†§Ï§ò                      True   \n",
      "7       ÏßÄÎÇú 3Ïùº ÎèôÏïà Ïö∞Î¶¨Î∞ò Ïã§ÎÇ¥ Ïò®ÎèÑ ÌèâÍ∑† Í∞í ÏïåÎ†§Ï§ò.                      True   \n",
      "8           Ïò§Îäò Ïò§ÌõÑ 5ÏãúÏóê ÏòÜÎ∞òÏùò ÏÑ§Ï†ïÏò®ÎèÑÎäî Ïñ¥Îï†Ïñ¥?                      True   \n",
      "9        Ïò¨Ìï¥ Ïó¨Î¶Ñ Ïö∞Î¶¨Î∞ò Ïã§ÎÇ¥Ïò®ÎèÑ ÏµúÎåÄÍ∞íÍ≥º ÏµúÏÜåÍ∞í ÏïåÎ†§Ï§ò                      True   \n",
      "10               Ïö∞Î¶¨Î∞òÍ≥º ÏïûÎ∞ò Ï§ë Í∞ÄÏû• ÎçîÏö¥ Î∞©ÏùÄ?                      True   \n",
      "11                 ÏßÄÍ∏à 4Ï∏µ ÌèâÍ∑† Ïã§ÎÇ¥Ïò®ÎèÑ ÏïåÎ†§Ï§ò                      True   \n",
      "\n",
      "    QueryTruePositive  QueryFalsePositive  QueryFalseNegative  ExactMatch  \\\n",
      "0               14214                   0                   0           1   \n",
      "1                   2                   0                   0           1   \n",
      "2                   0                   0               88160           0   \n",
      "3               14201                   0                   0           1   \n",
      "4                9935               19870                   0           0   \n",
      "5                   0                   0                   0           1   \n",
      "6                   0                   0                   0           1   \n",
      "7                4268                   0                   0           1   \n",
      "8                   1                   0                   0           1   \n",
      "9               44080                   0                   0           1   \n",
      "10                  2                   0                   0           1   \n",
      "11                  3                   0                   0           1   \n",
      "\n",
      "    Total  \n",
      "0   14214  \n",
      "1       2  \n",
      "2   88160  \n",
      "3   14201  \n",
      "4   29805  \n",
      "5       0  \n",
      "6       0  \n",
      "7    4268  \n",
      "8       1  \n",
      "9   44080  \n",
      "10      2  \n",
      "11      3  \n",
      "8.333333333333332 0.6666666666666666 1.0\n",
      "0.9259259259259259 0.8928571428571428\n",
      "JsonStructureCorrectness: 1.00\n",
      "ExactMatch: 0.83\n",
      "F1: 0.91\n",
      "Recall: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../experiments/result_3rdyear/r-3rdyear_r211_a422_sh2orc-Llama-3.1-Korean-8B-Instruct_tr27_16bit-step-41.json sh2orc-Llama-3.1-Korean-8B-Instruct\n",
      "Input, Ïù¥Î≤àÏ£º Ïö∞Î¶¨Î∞òÍ≥º ÏïûÎ∞òÏùò ÌèâÍ∑† Ïò®ÎèÑ ÏïåÎ†§Ï§ò ,expertLLM_output_tlen, 446\n",
      "cols: ['roomtemp', 'idu_name', 'id', 'timestamp']\n",
      "cols: ['roomtemp', 'idu_name', 'id', 'timestamp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|‚ñà‚ñã        | 2/12 [00:01<00:07,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rg_last_input_token_length, 209 ,rg_last_output_token_length, 45\n",
      "../experiments/result_3rdyear/r-3rdyear_r211_a422_sh2orc-Llama-3.1-Korean-8B-Instruct_tr27_16bit-step-41.json sh2orc-Llama-3.1-Korean-8B-Instruct\n",
      "Input, ÌòÑÏû¨ ÏÑ§Ï†ïÏò®ÎèÑÎûë Ïã§ÎÇ¥Ïò®ÎèÑ Ï∞®Ïù¥ ÏïåÎ†§Ï§ò. ,expertLLM_output_tlen, 338\n",
      "cols: ['roomtemp', 'idu_name', 'settemp', 'id', 'timestamp']\n",
      "Error in executing script: v_ÌòÑÏû¨_Ïö∞Î¶¨Î∞ò_ÏÑ§Ï†ïÏò®ÎèÑ-ÌòÑÏû¨_Ïö∞Î¶¨Î∞ò_Ïã§ÎÇ¥Ïò®ÎèÑ = v_ÌòÑÏû¨_Ïö∞Î¶¨Î∞ò_ÏÑ§Ï†ïÏò®ÎèÑ - v_ÌòÑÏû¨_Ïö∞Î¶¨Î∞ò_Ïã§ÎÇ¥Ïò®ÎèÑ\n",
      "cannot assign to expression here. Maybe you meant '==' instead of '='? (<string>, line 1)\n",
      "Error in running query_v2: cannot assign to expression here. Maybe you meant '==' instead of '='? (<string>, line 1)\n",
      "../experiments/result_3rdyear/r-3rdyear_r211_a422_sh2orc-Llama-3.1-Korean-8B-Instruct_tr27_16bit-step-41.json sh2orc-Llama-3.1-Korean-8B-Instruct\n",
      "Input, ÏßÄÎÇúÎã¨Ïóê ÏÑ§Ï†ïÏò®ÎèÑÏôÄ Ïã§ÎÇ¥Ïò®ÎèÑ Ï∞®Ïù¥Í∞Ä Í∞ÄÏû• ÎßéÏù¥ ÎÇ¨Îçò ÎÇ†ÏùÄ? ,expertLLM_output_tlen, 763\n",
      "cols: ['idu_name', 'settemp', 'id', 'timestamp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|‚ñà‚ñà‚ñå       | 3/12 [00:08<00:33,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cols: ['roomtemp', 'idu_name', 'id', 'timestamp']\n",
      "Error in executing script: v_ÏßÄÎÇúÎã¨_ÏÑ§Ï†ïÏò®ÎèÑ_Ïã§ÎÇ¥Ïò®ÎèÑ_df = pd.merge(v_ÏßÄÎÇúÎã¨_ÏÑ§Ï†ïÏò®ÎèÑ_df, v_ÏßÄÎÇúÎã¨_Ïã§ÎÇ¥Ïò®ÎèÑ_df, how='inner', on=['date','spatial'])\n",
      "'date'\n",
      "Error in running query_v2: 'date'\n",
      "../experiments/result_3rdyear/r-3rdyear_r211_a422_sh2orc-Llama-3.1-Korean-8B-Instruct_tr27_16bit-step-41.json sh2orc-Llama-3.1-Korean-8B-Instruct\n",
      "Input, Ïù¥Î≤àÏ£º Ïö∞Î¶¨Î∞òÍ≥º ÏòÜÎ∞òÏùò ÌèâÍ∑† Ïã§ÎÇ¥Ïò®ÎèÑ Ï∞®Ïù¥ ÏïåÎ†§Ï§ò ,expertLLM_output_tlen, 443\n",
      "cols: ['roomtemp', 'idu_name', 'id', 'timestamp']\n",
      "cols: ['roomtemp', 'idu_name', 'id', 'timestamp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 4/12 [00:10<00:21,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rg_last_input_token_length, 212 ,rg_last_output_token_length, 42\n",
      "../experiments/result_3rdyear/r-3rdyear_r211_a422_sh2orc-Llama-3.1-Korean-8B-Instruct_tr27_16bit-step-41.json sh2orc-Llama-3.1-Korean-8B-Instruct\n",
      "Input, 2Ï£ºÏ†Ñ Í∞ÄÏû• ÎçîÏõ†Îçò ÎÇ† ÏïåÎ†§Ï§ò ,expertLLM_output_tlen, 390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 5/12 [00:11<00:15,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cols: ['roomtemp', 'idu_name', 'id', 'timestamp']\n",
      "rg_last_input_token_length, 56 ,rg_last_output_token_length, 14\n",
      "../experiments/result_3rdyear/r-3rdyear_r211_a422_sh2orc-Llama-3.1-Korean-8B-Instruct_tr27_16bit-step-41.json sh2orc-Llama-3.1-Korean-8B-Instruct\n",
      "Input, ÌôîÏÑ±Ïùò ÏÑ§Ï†ïÏò®ÎèÑ ÌôïÏù∏Ìï¥Ï§ò ,expertLLM_output_tlen, 182\n",
      "cols: ['idu_name', 'settemp', 'id', 'timestamp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 6/12 [00:11<00:09,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rg_last_input_token_length, 71 ,rg_last_output_token_length, 16\n",
      "../experiments/result_3rdyear/r-3rdyear_r211_a422_sh2orc-Llama-3.1-Korean-8B-Instruct_tr27_16bit-step-41.json sh2orc-Llama-3.1-Korean-8B-Instruct\n",
      "Input, ÏòÜÎ∞ò ÏäµÎèÑ ÏïåÎ†§Ï§ò ,expertLLM_output_tlen, 109\n",
      "../experiments/result_3rdyear/r-3rdyear_r211_a422_sh2orc-Llama-3.1-Korean-8B-Instruct_tr27_16bit-step-41.json sh2orc-Llama-3.1-Korean-8B-Instruct\n",
      "Input, ÏßÄÎÇú 3Ïùº ÎèôÏïà Ïö∞Î¶¨Î∞ò Ïã§ÎÇ¥ Ïò®ÎèÑ ÌèâÍ∑† Í∞í ÏïåÎ†§Ï§ò. ,expertLLM_output_tlen, 248\n",
      "cols: ['roomtemp', 'idu_name', 'id', 'timestamp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 8/12 [00:12<00:03,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rg_last_input_token_length, 98 ,rg_last_output_token_length, 23\n",
      "../experiments/result_3rdyear/r-3rdyear_r211_a422_sh2orc-Llama-3.1-Korean-8B-Instruct_tr27_16bit-step-41.json sh2orc-Llama-3.1-Korean-8B-Instruct\n",
      "Input, Ïò§Îäò Ïò§ÌõÑ 5ÏãúÏóê ÏòÜÎ∞òÏùò ÏÑ§Ï†ïÏò®ÎèÑÎäî Ïñ¥Îï†Ïñ¥? ,expertLLM_output_tlen, 244\n",
      "cols: ['idu_name', 'settemp', 'id', 'timestamp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 9/12 [00:13<00:02,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rg_last_input_token_length, 107 ,rg_last_output_token_length, 22\n",
      "../experiments/result_3rdyear/r-3rdyear_r211_a422_sh2orc-Llama-3.1-Korean-8B-Instruct_tr27_16bit-step-41.json sh2orc-Llama-3.1-Korean-8B-Instruct\n",
      "Input, Ïò¨Ìï¥ Ïó¨Î¶Ñ Ïö∞Î¶¨Î∞ò Ïã§ÎÇ¥Ïò®ÎèÑ ÏµúÎåÄÍ∞íÍ≥º ÏµúÏÜåÍ∞í ÏïåÎ†§Ï§ò ,expertLLM_output_tlen, 340\n",
      "cols: ['roomtemp', 'idu_name', 'id', 'timestamp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 10/12 [00:15<00:02,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rg_last_input_token_length, 157 ,rg_last_output_token_length, 41\n",
      "../experiments/result_3rdyear/r-3rdyear_r211_a422_sh2orc-Llama-3.1-Korean-8B-Instruct_tr27_16bit-step-41.json sh2orc-Llama-3.1-Korean-8B-Instruct\n",
      "Input, Ïö∞Î¶¨Î∞òÍ≥º ÏïûÎ∞ò Ï§ë Í∞ÄÏû• ÎçîÏö¥ Î∞©ÏùÄ? ,expertLLM_output_tlen, 678\n",
      "cols: ['roomtemp', 'idu_name', 'id', 'timestamp']\n",
      "cols: ['roomtemp', 'idu_name', 'id', 'timestamp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 11/12 [00:15<00:01,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rg_last_input_token_length, 248 ,rg_last_output_token_length, 29\n",
      "../experiments/result_3rdyear/r-3rdyear_r211_a422_sh2orc-Llama-3.1-Korean-8B-Instruct_tr27_16bit-step-41.json sh2orc-Llama-3.1-Korean-8B-Instruct\n",
      "Input, ÏßÄÍ∏à 4Ï∏µ ÌèâÍ∑† Ïã§ÎÇ¥Ïò®ÎèÑ ÏïåÎ†§Ï§ò ,expertLLM_output_tlen, 219\n",
      "cols: ['roomtemp', 'idu_name', 'id', 'timestamp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:16<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rg_last_input_token_length, 82 ,rg_last_output_token_length, 19\n",
      "Time: [1.5104033946990967, 0.13995862007141113, 7.2114198207855225, 1.3096137046813965, 1.3305034637451172, 0.3611128330230713, 0.00021505355834960938, 0.7338883876800537, 0.4345383644104004, 2.0604357719421387, 0.6744613647460938, 0.39554452896118164], 1.346841275691986\n",
      "                               Input  JsonStructureCorrectness  \\\n",
      "0             Ïù¥Î≤àÏ£º Ïö∞Î¶¨Î∞òÍ≥º ÏïûÎ∞òÏùò ÌèâÍ∑† Ïò®ÎèÑ ÏïåÎ†§Ï§ò                      True   \n",
      "1              ÌòÑÏû¨ ÏÑ§Ï†ïÏò®ÎèÑÎûë Ïã§ÎÇ¥Ïò®ÎèÑ Ï∞®Ïù¥ ÏïåÎ†§Ï§ò.                      True   \n",
      "2   ÏßÄÎÇúÎã¨Ïóê ÏÑ§Ï†ïÏò®ÎèÑÏôÄ Ïã§ÎÇ¥Ïò®ÎèÑ Ï∞®Ïù¥Í∞Ä Í∞ÄÏû• ÎßéÏù¥ ÎÇ¨Îçò ÎÇ†ÏùÄ?                      True   \n",
      "3        Ïù¥Î≤àÏ£º Ïö∞Î¶¨Î∞òÍ≥º ÏòÜÎ∞òÏùò ÌèâÍ∑† Ïã§ÎÇ¥Ïò®ÎèÑ Ï∞®Ïù¥ ÏïåÎ†§Ï§ò                      True   \n",
      "4                   2Ï£ºÏ†Ñ Í∞ÄÏû• ÎçîÏõ†Îçò ÎÇ† ÏïåÎ†§Ï§ò                      True   \n",
      "5                      ÌôîÏÑ±Ïùò ÏÑ§Ï†ïÏò®ÎèÑ ÌôïÏù∏Ìï¥Ï§ò                      True   \n",
      "6                          ÏòÜÎ∞ò ÏäµÎèÑ ÏïåÎ†§Ï§ò                      True   \n",
      "7       ÏßÄÎÇú 3Ïùº ÎèôÏïà Ïö∞Î¶¨Î∞ò Ïã§ÎÇ¥ Ïò®ÎèÑ ÌèâÍ∑† Í∞í ÏïåÎ†§Ï§ò.                      True   \n",
      "8           Ïò§Îäò Ïò§ÌõÑ 5ÏãúÏóê ÏòÜÎ∞òÏùò ÏÑ§Ï†ïÏò®ÎèÑÎäî Ïñ¥Îï†Ïñ¥?                      True   \n",
      "9        Ïò¨Ìï¥ Ïó¨Î¶Ñ Ïö∞Î¶¨Î∞ò Ïã§ÎÇ¥Ïò®ÎèÑ ÏµúÎåÄÍ∞íÍ≥º ÏµúÏÜåÍ∞í ÏïåÎ†§Ï§ò                      True   \n",
      "10               Ïö∞Î¶¨Î∞òÍ≥º ÏïûÎ∞ò Ï§ë Í∞ÄÏû• ÎçîÏö¥ Î∞©ÏùÄ?                      True   \n",
      "11                 ÏßÄÍ∏à 4Ï∏µ ÌèâÍ∑† Ïã§ÎÇ¥Ïò®ÎèÑ ÏïåÎ†§Ï§ò                      True   \n",
      "\n",
      "    QueryTruePositive  QueryFalsePositive  QueryFalseNegative  ExactMatch  \\\n",
      "0               14214                   0                   0           1   \n",
      "1                   2                   0                   0           1   \n",
      "2               88160              176256                   0           0   \n",
      "3               14201                   0                   0           1   \n",
      "4                9935               19870                   0           0   \n",
      "5                   0                   0                   0           1   \n",
      "6                   0                   0                   0           1   \n",
      "7                4268                   0                   0           1   \n",
      "8                   1                   0                   0           1   \n",
      "9               44080                   0                   0           1   \n",
      "10                  2                   0                   0           1   \n",
      "11                  3                   0                   0           1   \n",
      "\n",
      "     Total  \n",
      "0    14214  \n",
      "1        2  \n",
      "2   264416  \n",
      "3    14201  \n",
      "4    29805  \n",
      "5        0  \n",
      "6        0  \n",
      "7     4268  \n",
      "8        1  \n",
      "9    44080  \n",
      "10       2  \n",
      "11       3  \n",
      "8.66674734761386 1.333252652386139 0.0\n",
      "0.866674734761386 1.0\n",
      "JsonStructureCorrectness: 1.00\n",
      "ExactMatch: 0.83\n",
      "F1: 0.93\n",
      "Recall: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../experiments/result_3rdyear/r-3rdyear_r450_a900_Bllossom-llama-3.2-Korean-Bllossom-3B_tr27_16bit-step-70.json Bllossom-llama-3.2-Korean-Bllossom-3B\n",
      "Input, Ïù¥Î≤àÏ£º Ïö∞Î¶¨Î∞òÍ≥º ÏïûÎ∞òÏùò ÌèâÍ∑† Ïò®ÎèÑ ÏïåÎ†§Ï§ò ,expertLLM_output_tlen, 362\n",
      "cols: ['roomtemp', 'idu_name', 'id', 'timestamp']\n",
      "cols: ['roomtemp', 'idu_name', 'id', 'timestamp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|‚ñä         | 1/12 [00:01<00:16,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rg_last_input_token_length, 153 ,rg_last_output_token_length, 36\n",
      "../experiments/result_3rdyear/r-3rdyear_r450_a900_Bllossom-llama-3.2-Korean-Bllossom-3B_tr27_16bit-step-70.json Bllossom-llama-3.2-Korean-Bllossom-3B\n",
      "Input, ÌòÑÏû¨ ÏÑ§Ï†ïÏò®ÎèÑÎûë Ïã§ÎÇ¥Ïò®ÎèÑ Ï∞®Ïù¥ ÏïåÎ†§Ï§ò. ,expertLLM_output_tlen, 262\n",
      "cols: ['idu_name', 'settemp', 'id', 'timestamp']\n",
      "cols: ['roomtemp', 'idu_name', 'id', 'timestamp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|‚ñà‚ñã        | 2/12 [00:02<00:10,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rg_last_input_token_length, 97 ,rg_last_output_token_length, 32\n",
      "../experiments/result_3rdyear/r-3rdyear_r450_a900_Bllossom-llama-3.2-Korean-Bllossom-3B_tr27_16bit-step-70.json Bllossom-llama-3.2-Korean-Bllossom-3B\n",
      "Input, ÏßÄÎÇúÎã¨Ïóê ÏÑ§Ï†ïÏò®ÎèÑÏôÄ Ïã§ÎÇ¥Ïò®ÎèÑ Ï∞®Ïù¥Í∞Ä Í∞ÄÏû• ÎßéÏù¥ ÎÇ¨Îçò ÎÇ†ÏùÄ? ,expertLLM_output_tlen, 569\n",
      "cols: ['roomtemp', 'idu_name', 'settemp', 'id', 'timestamp']\n",
      "get_time, col: Index(['Ïã§ÎÇ¥Ïò®ÎèÑ', 'idu_name', 'ÏÑ§Ï†ïÏò®ÎèÑ', 'timestamp', 'Ïò®ÎèÑÏ∞®Ïù¥'], dtype='object'), fmt: %Y-%m-%d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|‚ñà‚ñà‚ñå       | 3/12 [00:05<00:17,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rg_last_input_token_length, 368 ,rg_last_output_token_length, 99\n",
      "../experiments/result_3rdyear/r-3rdyear_r450_a900_Bllossom-llama-3.2-Korean-Bllossom-3B_tr27_16bit-step-70.json Bllossom-llama-3.2-Korean-Bllossom-3B\n",
      "Input, Ïù¥Î≤àÏ£º Ïö∞Î¶¨Î∞òÍ≥º ÏòÜÎ∞òÏùò ÌèâÍ∑† Ïã§ÎÇ¥Ïò®ÎèÑ Ï∞®Ïù¥ ÏïåÎ†§Ï§ò ,expertLLM_output_tlen, 447\n",
      "cols: ['roomtemp', 'idu_name', 'id', 'timestamp']\n",
      "cols: ['roomtemp', 'idu_name', 'id', 'timestamp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 4/12 [00:06<00:14,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rg_last_input_token_length, 212 ,rg_last_output_token_length, 42\n",
      "../experiments/result_3rdyear/r-3rdyear_r450_a900_Bllossom-llama-3.2-Korean-Bllossom-3B_tr27_16bit-step-70.json Bllossom-llama-3.2-Korean-Bllossom-3B\n",
      "Input, 2Ï£ºÏ†Ñ Í∞ÄÏû• ÎçîÏõ†Îçò ÎÇ† ÏïåÎ†§Ï§ò ,expertLLM_output_tlen, 379\n",
      "cols: ['roomtemp', 'idu_name', 'id', 'timestamp']\n",
      "get_time, col: Index(['Ïã§ÎÇ¥Ïò®ÎèÑ', 'idu_name', 'timestamp'], dtype='object'), fmt: %Y-%m-%d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 6/12 [00:08<00:06,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rg_last_input_token_length, 166 ,rg_last_output_token_length, 59\n",
      "../experiments/result_3rdyear/r-3rdyear_r450_a900_Bllossom-llama-3.2-Korean-Bllossom-3B_tr27_16bit-step-70.json Bllossom-llama-3.2-Korean-Bllossom-3B\n",
      "Input, ÌôîÏÑ±Ïùò ÏÑ§Ï†ïÏò®ÎèÑ ÌôïÏù∏Ìï¥Ï§ò ,expertLLM_output_tlen, 184\n",
      "cols: ['idu_name', 'settemp', 'id', 'timestamp']\n",
      "Error in executing script: v_ÌòÑÏû¨_ÌôîÏÑ±_ÏÑ§Ï†ïÏò®ÎèÑ = v_ÌòÑÏû¨_ÌôîÏÑ±_ÏÑ§Ï†ïÏò®ÎèÑ_df['ÏÑ§Ï†ïÏò®ÎèÑ'].values[0]\n",
      "index 0 is out of bounds for axis 0 with size 0\n",
      "Error in running query_v2: index 0 is out of bounds for axis 0 with size 0\n",
      "../experiments/result_3rdyear/r-3rdyear_r450_a900_Bllossom-llama-3.2-Korean-Bllossom-3B_tr27_16bit-step-70.json Bllossom-llama-3.2-Korean-Bllossom-3B\n",
      "Input, ÏòÜÎ∞ò ÏäµÎèÑ ÏïåÎ†§Ï§ò ,expertLLM_output_tlen, 108\n",
      "../experiments/result_3rdyear/r-3rdyear_r450_a900_Bllossom-llama-3.2-Korean-Bllossom-3B_tr27_16bit-step-70.json Bllossom-llama-3.2-Korean-Bllossom-3B\n",
      "Input, ÏßÄÎÇú 3Ïùº ÎèôÏïà Ïö∞Î¶¨Î∞ò Ïã§ÎÇ¥ Ïò®ÎèÑ ÌèâÍ∑† Í∞í ÏïåÎ†§Ï§ò. ,expertLLM_output_tlen, 254\n",
      "cols: ['roomtemp', 'idu_name', 'id', 'timestamp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 8/12 [00:08<00:02,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rg_last_input_token_length, 99 ,rg_last_output_token_length, 24\n",
      "../experiments/result_3rdyear/r-3rdyear_r450_a900_Bllossom-llama-3.2-Korean-Bllossom-3B_tr27_16bit-step-70.json Bllossom-llama-3.2-Korean-Bllossom-3B\n",
      "Input, Ïò§Îäò Ïò§ÌõÑ 5ÏãúÏóê ÏòÜÎ∞òÏùò ÏÑ§Ï†ïÏò®ÎèÑÎäî Ïñ¥Îï†Ïñ¥? ,expertLLM_output_tlen, 240\n",
      "cols: ['idu_name', 'settemp', 'id', 'timestamp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 9/12 [00:09<00:01,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rg_last_input_token_length, 93 ,rg_last_output_token_length, 22\n",
      "../experiments/result_3rdyear/r-3rdyear_r450_a900_Bllossom-llama-3.2-Korean-Bllossom-3B_tr27_16bit-step-70.json Bllossom-llama-3.2-Korean-Bllossom-3B\n",
      "Input, Ïò¨Ìï¥ Ïó¨Î¶Ñ Ïö∞Î¶¨Î∞ò Ïã§ÎÇ¥Ïò®ÎèÑ ÏµúÎåÄÍ∞íÍ≥º ÏµúÏÜåÍ∞í ÏïåÎ†§Ï§ò ,expertLLM_output_tlen, 552\n",
      "cols: ['roomtemp', 'idu_name', 'id', 'timestamp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 10/12 [00:11<00:02,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rg_last_input_token_length, 229 ,rg_last_output_token_length, 79\n",
      "../experiments/result_3rdyear/r-3rdyear_r450_a900_Bllossom-llama-3.2-Korean-Bllossom-3B_tr27_16bit-step-70.json Bllossom-llama-3.2-Korean-Bllossom-3B\n",
      "Failed to parse input:  Ïö∞Î¶¨Î∞òÍ≥º ÏïûÎ∞ò Ï§ë Í∞ÄÏû• ÎçîÏö¥ Î∞©ÏùÄ? {\"Thinking\": \"ÏÇ¨Ïö©ÏûêÎäî ÌòÑÏû¨ Ïö∞Î¶¨Î∞òÍ≥º ÏïûÎ∞ò Ï§ë Ïã§ÎÇ¥Ïò®ÎèÑÍ∞Ä Îçî ÎÜíÏùÄ Î∞©ÏùÑ ÏïåÍ≥†Ïã∂Ïñ¥Ìï®. ÌòÑÏû¨ Ïö∞Î¶¨Î∞òÍ≥º ÏïûÎ∞òÏùò Ïã§ÎÇ¥Ïò®ÎèÑÎ•º ÏøºÎ¶¨Ìïú ÌõÑ Îçî ÎÜíÏùÄ Ïã§ÎÇ¥Ïò®ÎèÑÎ•º Í∞ÄÏßÑ Î∞©Í≥º Í∑∏ Ïò®ÎèÑÎ•º Î∞òÌôòÌïòÎ©¥ Îê®.\", \"Expectations\": [\"{{ÌòÑÏû¨_Ïã§ÎÇ¥Ïò®ÎèÑ_Îçî¬†jealous}}Ïù¥({{ÌòÑÏû¨_Ïã§ÎÇ¥Ïò®ÎèÑ_Îçî¬†jealous}}‚ÑÉ) {{ÌòÑÏû¨_Ïã§ÎÇ¥Ïò®ÎèÑ_Îçî¬†jealous}}‚ÑÉÎ°ú {{ÌòÑÏû¨_Ïã§ÎÇ¥Ïò®ÎèÑ_Îçî¬†jealous}}‚ÑÉ Îçî ÎçîÏö¥ Î∞©ÏûÖÎãàÎã§.\"], \"Mapping\": {\"temporal\": {\"ÌòÑÏû¨\": \"LAST_RECORD\"}, \"spatials\": {\"Ïö∞Î¶¨Î∞ò\": \"01_IB5\", \"ÏïûÎ∞ò\": \"01_IB7\"}, \"modalities\": {\"Ïã§ÎÇ¥Ïò®ÎèÑ\": \"roomtemp\"}}, \"Script\": [\"v_ÌòÑÏû¨_Ïö∞Î¶¨Î∞ò_Ïã§ÎÇ¥Ïò®ÎèÑ_df = data(t='ÌòÑÏû¨',s='Ïö∞Î¶¨Î∞ò',m='Ïã§ÎÇ¥Ïò®ÎèÑ')\", \"v_ÌòÑÏû¨_ÏïûÎ∞ò_Ïã§ÎÇ¥Ïò®ÎèÑ_df = data(t='ÌòÑÏû¨',s='ÏïûÎ∞ò',m='Ïã§ÎÇ¥Ïò®ÎèÑ')\", \"v_ÌòÑÏû¨_Ïã§ÎÇ¥Ïò®ÎèÑ = {'Ïö∞Î¶¨Î∞ò': v_ÌòÑÏû¨_Ïö∞Î¶¨Î∞ò_Ïã§ÎÇ¥Ïò®ÎèÑ_df['Ïã§ÎÇ¥Ïò®ÎèÑ'].values[0], 'ÏïûÎ∞ò': v_ÌòÑÏû¨_ÏïûÎ∞ò_Ïã§ÎÇ¥Ïò®ÎèÑ_df['Ïã§ÎÇ¥Ïò®ÎèÑ'].values[0]}\", \"v_ÌòÑÏû¨_Ïã§ÎÇ¥Ïò®ÎèÑ_Îçî¬†jealous = {'Ïö∞Î¶¨Î∞ò': v_ÌòÑÏû¨_Ïã§ÎÇ¥Ïò®ÎèÑ['Ïö∞Î¶¨Î∞ò'], 'ÏïûÎ∞ò': v_ÌòÑÏû¨_Ïã§ÎÇ¥Ïò®ÎèÑ['ÏïûÎ∞ò']}\", \"v_ÌòÑÏû¨_Ïã§ÎÇ¥Ïò®ÎèÑ_Îçî¬†jealous_key = {'Ïö∞Î¶¨Î∞ò': 'Ïö∞Î¶¨Î∞ò', 'ÏïûÎ∞ò': 'ÏïûÎ∞ò'}\", \"v_ÌòÑÏû¨_Ïã§ÎÇ¥Ïò®ÎèÑ_Îçî¬†jealous_value = {'Ïö∞Î¶¨Î∞ò': v_ÌòÑÏû¨_Ïã§ÎÇ¥Ïò®ÎèÑ_Îçî¬†jealous['Ïö∞Î¶¨Î∞ò'], 'ÏïûÎ∞ò': v_ÌòÑÏû¨_Ïã§ÎÇ¥Ïò®ÎèÑ_Îçî¬†jealous['ÏïûÎ∞ò']}\", \"v_ÌòÑÏû¨_Ïã§ÎÇ¥Ïò®ÎèÑ_Îçî¬†jealous_key_value = {'Ïö∞Î¶¨Î∞ò': v_ÌòÑÏû¨_Ïã§ÎÇ¥Ïò®ÎèÑ_Îçî¬†jealous_key['Ïö∞Î¶¨Î∞ò'] == v_ÌòÑÏû¨_Ïã§ÎÇ¥Ïò®ÎèÑ_Îçî¬†jealous['Ïö∞Î¶¨Î∞ò'], 'ÏïûÎ∞ò': v_ÌòÑÏû¨_Ïã§ÎÇ¥Ïò®ÎèÑ_Îçî¬†jealous_key['ÏïûÎ∞ò'] == v_ÌòÑÏû¨_Ïã§ÎÇ¥Ïò®ÎèÑ_Îçî¬†jealous['ÏïûÎ∞ò']}\", \"v_ÌòÑÏû¨_Ïã§ÎÇ¥Ïò®ÎèÑ_Îçî¬†jealous_key_value_str = {'Ïö∞Î¶¨Î∞ò': str(v_ÌòÑÏû¨_Ïã§ÎÇ¥Ïò®ÎèÑ_Îçî¬†jealous_key['Ïö∞Î¶¨Î∞ò'] == v_ÌòÑÏû¨_Ïã§ÎÇ¥Ïò®ÎèÑ_Îçî¬†jealous['Ïö∞Î¶¨Î∞ò']) + '‚ÑÉ Îçî ÎçîÏö¥ Î∞©ÏûÖÎãàÎã§.', 'ÏïûÎ∞ò': str(v_ÌòÑÏû¨_Ïã§ÎÇ¥Ïò®ÎèÑ_Îçî¬†jealous_key['ÏïûÎ∞ò'] == v_ÌòÑÏû¨_Ïã§ÎÇ¥Ïò®ÎèÑ_Îçî¬†jealous['ÏïûÎ∞ò']) + '‚ÑÉ Îçî ÎçîÏö¥ Î∞©ÏûÖÎãàÎã§.']\"}}\n",
      "../experiments/result_3rdyear/r-3rdyear_r450_a900_Bllossom-llama-3.2-Korean-Bllossom-3B_tr27_16bit-step-70.json Bllossom-llama-3.2-Korean-Bllossom-3B\n",
      "Input, ÏßÄÍ∏à 4Ï∏µ ÌèâÍ∑† Ïã§ÎÇ¥Ïò®ÎèÑ ÏïåÎ†§Ï§ò ,expertLLM_output_tlen, 220\n",
      "cols: ['roomtemp', 'idu_name', 'id', 'timestamp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:12<00:00,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rg_last_input_token_length, 82 ,rg_last_output_token_length, 19\n",
      "Time: [1.5098509788513184, 0.7125959396362305, 2.987276792526245, 1.5716493129730225, 1.348240852355957, 0.14041733741760254, 0.00035572052001953125, 0.5936524868011475, 0.43607401847839355, 2.5615596771240234, 0.3954331874847412], 1.1142823912880637\n",
      "                               Input  JsonStructureCorrectness  \\\n",
      "0             Ïù¥Î≤àÏ£º Ïö∞Î¶¨Î∞òÍ≥º ÏïûÎ∞òÏùò ÌèâÍ∑† Ïò®ÎèÑ ÏïåÎ†§Ï§ò                      True   \n",
      "1              ÌòÑÏû¨ ÏÑ§Ï†ïÏò®ÎèÑÎûë Ïã§ÎÇ¥Ïò®ÎèÑ Ï∞®Ïù¥ ÏïåÎ†§Ï§ò.                      True   \n",
      "2   ÏßÄÎÇúÎã¨Ïóê ÏÑ§Ï†ïÏò®ÎèÑÏôÄ Ïã§ÎÇ¥Ïò®ÎèÑ Ï∞®Ïù¥Í∞Ä Í∞ÄÏû• ÎßéÏù¥ ÎÇ¨Îçò ÎÇ†ÏùÄ?                      True   \n",
      "3        Ïù¥Î≤àÏ£º Ïö∞Î¶¨Î∞òÍ≥º ÏòÜÎ∞òÏùò ÌèâÍ∑† Ïã§ÎÇ¥Ïò®ÎèÑ Ï∞®Ïù¥ ÏïåÎ†§Ï§ò                      True   \n",
      "4                   2Ï£ºÏ†Ñ Í∞ÄÏû• ÎçîÏõ†Îçò ÎÇ† ÏïåÎ†§Ï§ò                      True   \n",
      "5                      ÌôîÏÑ±Ïùò ÏÑ§Ï†ïÏò®ÎèÑ ÌôïÏù∏Ìï¥Ï§ò                      True   \n",
      "6                          ÏòÜÎ∞ò ÏäµÎèÑ ÏïåÎ†§Ï§ò                      True   \n",
      "7       ÏßÄÎÇú 3Ïùº ÎèôÏïà Ïö∞Î¶¨Î∞ò Ïã§ÎÇ¥ Ïò®ÎèÑ ÌèâÍ∑† Í∞í ÏïåÎ†§Ï§ò.                      True   \n",
      "8           Ïò§Îäò Ïò§ÌõÑ 5ÏãúÏóê ÏòÜÎ∞òÏùò ÏÑ§Ï†ïÏò®ÎèÑÎäî Ïñ¥Îï†Ïñ¥?                      True   \n",
      "9        Ïò¨Ìï¥ Ïó¨Î¶Ñ Ïö∞Î¶¨Î∞ò Ïã§ÎÇ¥Ïò®ÎèÑ ÏµúÎåÄÍ∞íÍ≥º ÏµúÏÜåÍ∞í ÏïåÎ†§Ï§ò                      True   \n",
      "10               Ïö∞Î¶¨Î∞òÍ≥º ÏïûÎ∞ò Ï§ë Í∞ÄÏû• ÎçîÏö¥ Î∞©ÏùÄ?                     False   \n",
      "11                 ÏßÄÍ∏à 4Ï∏µ ÌèâÍ∑† Ïã§ÎÇ¥Ïò®ÎèÑ ÏïåÎ†§Ï§ò                      True   \n",
      "\n",
      "    QueryTruePositive  QueryFalsePositive  QueryFalseNegative  ExactMatch  \\\n",
      "0               14214                   0                   0           1   \n",
      "1                   2                   0                   0           1   \n",
      "2               88160                   0                   0           1   \n",
      "3                7107                7107                7094           0   \n",
      "4                   0                9935                9935           0   \n",
      "5                   0                   0                   0           1   \n",
      "6                   0                   0                   0           1   \n",
      "7                1415                   0                2853           0   \n",
      "8                   1                   0                   0           1   \n",
      "9               44080                   0                   0           1   \n",
      "10                  0                   0                   2           0   \n",
      "11                  3                   0                   0           1   \n",
      "\n",
      "    Total  \n",
      "0   14214  \n",
      "1       2  \n",
      "2   88160  \n",
      "3   21308  \n",
      "4   19870  \n",
      "5       0  \n",
      "6       0  \n",
      "7    4268  \n",
      "8       1  \n",
      "9   44080  \n",
      "10      2  \n",
      "11      3  \n",
      "6.6650737195123995 0.8335366998310494 2.501389580656552\n",
      "0.8888411781360378 0.727115082584747\n",
      "JsonStructureCorrectness: 0.92\n",
      "ExactMatch: 0.67\n",
      "F1: 0.80\n",
      "Recall: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# name = \"r-v7_r256_a512_ours_tr6_0503-checkpoint-63\"\n",
    "# name = \"r-v7_r256_a512_ours_tr18_0503-checkpoint-52\"\n",
    "# name = \"r-v7_r256_a512_ours_tr30_0503-checkpoint-54\"\n",
    "# name = \"r-v7_r256_a512_ours_tr45_0503-checkpoint-95\"\n",
    "# name = \"r-v7_r256_a512_ours_tr60_0503-checkpoint-108\"\n",
    "\n",
    "# name = \"r-v7_r256_a512_woall_tr6_0503-checkpoint-28\"\n",
    "# name = \"r-v7_r256_a512_woall_tr18_0503-checkpoint-70\"\n",
    "# name = \"r-v7_r256_a512_woall_tr30_0503-checkpoint-57\"\n",
    "# name = \"r-v7_r256_a512_woall_tr45_0503-checkpoint-95\"\n",
    "# name = \"r-v7_r256_a512_woall_tr60_0503-checkpoint-90\"\n",
    "\n",
    "names = [\n",
    "\"r-3rdyear_r211_a422_sh2orc-Llama-3.1-Korean-8B-Instruct_tr27_4bit-step-41\",\n",
    "\"r-3rdyear_r211_a422_sh2orc-Llama-3.1-Korean-8B-Instruct_tr27_8bit-step-41\",\n",
    "\"r-3rdyear_r211_a422_sh2orc-Llama-3.1-Korean-8B-Instruct_tr27_16bit-step-41\",\n",
    "\"r-3rdyear_r450_a900_Bllossom-llama-3.2-Korean-Bllossom-3B_tr27_16bit-step-70\",\n",
    "]\n",
    "\n",
    "for name in names:\n",
    "    eval_query(\n",
    "        f\"../experiments/result_3rdyear/{name}.json\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8B_4bit\n",
      "8B_8bit\n",
      "8B_16bit\n",
      "3B_16bit\n",
      "{'Ïù¥Î≤àÏ£º Ïö∞Î¶¨Î∞òÍ≥º ÏïûÎ∞òÏùò ÌèâÍ∑† Ïò®ÎèÑ ÏïåÎ†§Ï§ò': {'8B_4bit': 'Ïù¥Î≤àÏ£º Ïö∞Î¶¨Î∞òÏùò ÌèâÍ∑† Ïã§ÎÇ¥Ïò®ÎèÑÎäî 25.98‚ÑÉÏù¥Í≥†, ÏïûÎ∞òÏùò ÌèâÍ∑† Ïã§ÎÇ¥Ïò®ÎèÑÎäî 25.11‚ÑÉÏûÖÎãàÎã§. Ïù¥Î≤àÏ£º Ïö∞Î¶¨Î∞òÎ≥¥Îã§ ÏïûÎ∞òÏùò ÌèâÍ∑† Ïã§ÎÇ¥Ïò®ÎèÑÍ∞Ä -0.87‚ÑÉ ÎÇÆÏäµÎãàÎã§.', \"('3B_16bit', '8B_8bit')\": 'Ïù¥Î≤àÏ£º Ïö∞Î¶¨Î∞òÏùò ÌèâÍ∑† Ïã§ÎÇ¥Ïò®ÎèÑÎäî 25.98‚ÑÉÏù¥Í≥†, ÏïûÎ∞òÏùò ÌèâÍ∑† Ïã§ÎÇ¥Ïò®ÎèÑÎäî 25.11‚ÑÉÏûÖÎãàÎã§.', '8B_16bit': 'Ïù¥Î≤àÏ£º Ïö∞Î¶¨Î∞òÏùò ÌèâÍ∑† Ïã§ÎÇ¥Ïò®ÎèÑÎäî 25.98‚ÑÉÏù¥Í≥†, ÏïûÎ∞òÏùò ÌèâÍ∑† Ïã§ÎÇ¥Ïò®ÎèÑÎäî 25.11‚ÑÉÏûÖÎãàÎã§. Ï∞®Ïù¥Îäî 0.87‚ÑÉÏûÖÎãàÎã§.', 'GT_Response': 'Ïù¥Î≤àÏ£º Ïö∞Î¶¨Î∞òÏùò ÌèâÍ∑† Ïã§ÎÇ¥Ïò®ÎèÑÎäî 25.98¬∞CÏù¥Í≥†, ÏïûÎ∞òÏùò ÌèâÍ∑† Ïã§ÎÇ¥Ïò®ÎèÑÎäî 25.11¬∞CÏûÖÎãàÎã§.'}, 'ÌòÑÏû¨ ÏÑ§Ï†ïÏò®ÎèÑÎûë Ïã§ÎÇ¥Ïò®ÎèÑ Ï∞®Ïù¥ ÏïåÎ†§Ï§ò.': {'8B_4bit': 'ÌòÑÏû¨ Ïö∞Î¶¨Î∞òÏùò ÏÑ§Ï†ïÏò®ÎèÑ(23.00‚ÑÉ)Îäî Ïã§ÎÇ¥Ïò®ÎèÑ(27.00‚ÑÉ)Î≥¥Îã§ 4.00‚ÑÉ ÎÜíÏäµÎãàÎã§.', '8B_8bit': 'ÌòÑÏû¨ Ïö∞Î¶¨Î∞òÏùò ÏÑ§Ï†ïÏò®ÎèÑ(23.00‚ÑÉ)ÏôÄ Ïã§ÎÇ¥Ïò®ÎèÑ(27.00‚ÑÉ)Ïùò Ï∞®Ïù¥Îäî 4.00‚ÑÉÏûÖÎãàÎã§.', '8B_16bit': 'Ïã§ÌñâÏ§ë ÏóêÎü¨Í∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§.', '3B_16bit': 'ÌòÑÏû¨ ÏÑ§Ï†ïÏò®ÎèÑ(23.00‚ÑÉ)Îûë Ïã§ÎÇ¥Ïò®ÎèÑ(27.00‚ÑÉ) Ï∞®Ïù¥Îäî -4.00‚ÑÉÏûÖÎãàÎã§.', 'GT_Response': 'ÌòÑÏû¨ ÏÑ§Ï†ïÏò®ÎèÑ(23.00¬∞C)ÏôÄ Ïã§ÎÇ¥Ïò®ÎèÑ(27.00¬∞C)Ïùò Ï∞®Ïù¥Îäî 4.00¬∞CÏûÖÎãàÎã§.'}, 'ÏßÄÎÇúÎã¨Ïóê ÏÑ§Ï†ïÏò®ÎèÑÏôÄ Ïã§ÎÇ¥Ïò®ÎèÑ Ï∞®Ïù¥Í∞Ä Í∞ÄÏû• ÎßéÏù¥ ÎÇ¨Îçò ÎÇ†ÏùÄ?': {\"('8B_16bit', '8B_4bit', '8B_8bit')\": 'Ïã§ÌñâÏ§ë ÏóêÎü¨Í∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§.', '3B_16bit': 'ÏßÄÎÇúÎã¨ 8Ïõî 2Ïùº, 4Ïùº, 5Ïùº, 7Ïùº, 8Ïùº, 10Ïùº, 13Ïùº, 16Ïùº, 18Ïùº, 21Ïùº, 24Ïùº, 26Ïùº, 27Ïùº, 29Ïùº, 30ÏùºÏóê ÏÑ§Ï†ïÏò®ÎèÑ(23.00‚ÑÉ)ÏôÄ Ïã§ÎÇ¥Ïò®ÎèÑ(22.50‚ÑÉ) Ï∞®Ïù¥Í∞Ä 0.50‚ÑÉÎ°ú Í∞ÄÏû• Ïª∏ÏäµÎãàÎã§.', 'GT_Response': 'ÏßÄÎÇúÎã¨ 8Ïõî 2Ïùº, 4Ïùº, 5Ïùº, 7Ïùº, 8Ïùº, 10Ïùº, 13Ïùº, 16Ïùº, 18Ïùº, 21Ïùº, 24Ïùº, 26Ïùº, 27Ïùº, 29Ïùº, 30ÏùºÏóê ÏÑ§Ï†ïÏò®ÎèÑ(23.00¬∞C)ÏôÄ Ïã§ÎÇ¥Ïò®ÎèÑ(22.50¬∞C) Ï∞®Ïù¥Í∞Ä 0.50¬∞CÎ°ú Í∞ÄÏû• Ïª∏ÏäµÎãàÎã§.'}, 'Ïù¥Î≤àÏ£º Ïö∞Î¶¨Î∞òÍ≥º ÏòÜÎ∞òÏùò ÌèâÍ∑† Ïã§ÎÇ¥Ïò®ÎèÑ Ï∞®Ïù¥ ÏïåÎ†§Ï§ò': {'8B_4bit': 'Ïù¥Î≤àÏ£º Ïö∞Î¶¨Î∞òÏùò ÌèâÍ∑† Ïã§ÎÇ¥Ïò®ÎèÑÎäî 25.98‚ÑÉÏù¥Í≥†, ÏòÜÎ∞òÏùò ÌèâÍ∑† Ïã§ÎÇ¥Ïò®ÎèÑÎäî 25.67‚ÑÉÏûÖÎãàÎã§. Ï∞®Ïù¥Îäî 0.31‚ÑÉÏûÖÎãàÎã§.', '8B_8bit': 'Ïù¥Î≤àÏ£º Ïö∞Î¶¨Î∞òÏùò ÌèâÍ∑† Ïã§ÎÇ¥Ïò®ÎèÑÎäî 25.98‚ÑÉÏù¥Í≥†, ÏòÜÎ∞òÏùò ÌèâÍ∑† Ïã§ÎÇ¥Ïò®ÎèÑÎäî 25.67‚ÑÉÏûÖÎãàÎã§. Îëê Î∞òÏùò ÌèâÍ∑† Ïã§ÎÇ¥Ïò®ÎèÑ Ï∞®Ïù¥Îäî 0.31‚ÑÉÏûÖÎãàÎã§.', '8B_16bit': 'Ïù¥Î≤àÏ£º Ïö∞Î¶¨Î∞òÏùò ÌèâÍ∑† Ïã§ÎÇ¥Ïò®ÎèÑ(25.98‚ÑÉ)Îäî ÏòÜÎ∞òÏùò ÌèâÍ∑† Ïã§ÎÇ¥Ïò®ÎèÑ(25.67‚ÑÉ)Î≥¥Îã§ 0.31‚ÑÉ ÎÜíÏäµÎãàÎã§.', '3B_16bit': 'Ïù¥Î≤àÏ£º Ïö∞Î¶¨Î∞òÏùò ÌèâÍ∑† Ïã§ÎÇ¥Ïò®ÎèÑ(25.98‚ÑÉ)Îäî ÏòÜÎ∞òÏùò ÌèâÍ∑† Ïã§ÎÇ¥Ïò®ÎèÑ(25.11‚ÑÉ)Î≥¥Îã§ 0.87‚ÑÉ ÎÜíÏäµÎãàÎã§.', 'GT_Response': 'Ïù¥Î≤àÏ£º Ïö∞Î¶¨Î∞ò ÌèâÍ∑† Ïã§ÎÇ¥Ïò®ÎèÑ(25.98¬∞C)ÏôÄ ÏòÜÎ∞ò ÌèâÍ∑† Ïã§ÎÇ¥Ïò®ÎèÑ(25.67¬∞C) Ï∞®Ïù¥Îäî 0.31¬∞CÏûÖÎãàÎã§.'}, '2Ï£ºÏ†Ñ Í∞ÄÏû• ÎçîÏõ†Îçò ÎÇ† ÏïåÎ†§Ï§ò': {'8B_4bit': '2Ï£ºÏ†Ñ Í∞ÄÏû• ÎçîÏõ†Îçò ÎÇ†ÏùÄ 9Ïõî 12Ïùº, 14ÏùºÎ°ú 29.00‚ÑÉÏòÄÏäµÎãàÎã§.', '8B_8bit': '2Ï£ºÏ†Ñ ÏõîÏöîÏùº Ïã§ÎÇ¥Ïò®ÎèÑ Îç∞Ïù¥ÌÑ∞Î•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.', '8B_16bit': '2Ï£ºÏ†Ñ ÏõîÏöîÏùºÎäî Îç∞Ïù¥ÌÑ∞Î•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.', '3B_16bit': '2Ï£ºÏ†Ñ Í∞ÄÏû• ÎçîÏõ†Îçò ÎÇ†ÏùÄ 2022-09-12, 13Ïùº, 14Ïùº, 15Ïùº, 16Ïùº, 17Ïùº, 18ÏùºÏóê {{v_2Ï£ºÏ†Ñ_Ïã§ÎÇ¥Ïò®ÎèÑ_ÏµúÍ≥†}}‚ÑÉÏòÄÏäµÎãàÎã§.', 'GT_Response': '2Ï£ºÏ†Ñ 9Ïõî 12ÏùºÍ≥º 9Ïõî 14ÏùºÏóê Ïã§ÎÇ¥Ïò®ÎèÑ(29.00¬∞C)Í∞Ä Í∞ÄÏû• ÎÜíÏïòÏäµÎãàÎã§.'}, 'ÌôîÏÑ±Ïùò ÏÑ§Ï†ïÏò®ÎèÑ ÌôïÏù∏Ìï¥Ï§ò': {'8B_4bit': \"Ï£ÑÏÜ°Ìï©ÎãàÎã§, ['ÌôîÏÑ±']Îäî Ï°¥Ïû¨ÌïòÏßÄ ÏïäÎäî Í≥µÍ∞ÑÏù¥ÎÇò Î™®Îã¨Î¶¨Ìã∞ ÏûÖÎãàÎã§.\", \"('8B_16bit', '8B_8bit')\": 'ÌôîÏÑ±Ïùò ÌòÑÏû¨ ÏÑ§Ï†ïÏò®ÎèÑÎäî 23.00‚ÑÉÏûÖÎãàÎã§.', '3B_16bit': 'Ïã§ÌñâÏ§ë ÏóêÎü¨Í∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§.', 'GT_Response': \"Ï£ÑÏÜ°Ìï©ÎãàÎã§, ['ÌôîÏÑ±']Îäî Ï°¥Ïû¨ÌïòÏßÄ ÏïäÎäî Í≥µÍ∞ÑÏù¥ÎÇò Î™®Îã¨Î¶¨Ìã∞ ÏûÖÎãàÎã§.\"}, 'ÏòÜÎ∞ò ÏäµÎèÑ ÏïåÎ†§Ï§ò': {\"('8B_16bit', '8B_4bit', '8B_8bit')\": \"Ï£ÑÏÜ°Ìï©ÎãàÎã§, ['ÏäµÎèÑ']Îäî Ï°¥Ïû¨ÌïòÏßÄ ÏïäÎäî Í≥µÍ∞ÑÏù¥ÎÇò Î™®Îã¨Î¶¨Ìã∞ ÏûÖÎãàÎã§.\", '3B_16bit': 'Ï£ÑÏÜ°Ìï©ÎãàÎã§, []Îäî Ï°¥Ïû¨ÌïòÏßÄ ÏïäÎäî Í≥µÍ∞ÑÏù¥ÎÇò Î™®Îã¨Î¶¨Ìã∞ ÏûÖÎãàÎã§.', 'GT_Response': \"Ï£ÑÏÜ°Ìï©ÎãàÎã§, ['ÏäµÎèÑ']Îäî Ï°¥Ïû¨ÌïòÏßÄ ÏïäÎäî Í≥µÍ∞ÑÏù¥ÎÇò Î™®Îã¨Î¶¨Ìã∞ ÏûÖÎãàÎã§.\"}, 'ÏßÄÎÇú 3Ïùº ÎèôÏïà Ïö∞Î¶¨Î∞ò Ïã§ÎÇ¥ Ïò®ÎèÑ ÌèâÍ∑† Í∞í ÏïåÎ†§Ï§ò.': {\"('8B_16bit', '8B_4bit')\": 'ÏßÄÎÇú 3Ïùº Ïö∞Î¶¨Î∞òÏùò ÌèâÍ∑† Ïã§ÎÇ¥Ïò®ÎèÑÎäî 26.52‚ÑÉÏòÄÏäµÎãàÎã§.', '8B_8bit': 'ÏßÄÎÇú 3Ïùº Ïö∞Î¶¨Î∞òÏùò Ïã§ÎÇ¥Ïò®ÎèÑ ÌèâÍ∑†ÏùÄ 26.52‚ÑÉÏòÄÏäµÎãàÎã§.', '3B_16bit': 'ÏßÄÎÇú 3Ïùº ÎèôÏïà Ïö∞Î¶¨Î∞òÏùò ÌèâÍ∑† Ïã§ÎÇ¥Ïò®ÎèÑÎäî 24.56‚ÑÉÏòÄÏäµÎãàÎã§.', 'GT_Response': 'ÏßÄÎÇú 3ÏùºÍ∞Ñ Ïö∞Î¶¨Î∞ò Ïã§ÎÇ¥Ïò®ÎèÑ ÌèâÍ∑†Í∞íÏùÄ 26.52¬∞CÏòÄÏäµÎãàÎã§.'}, 'Ïò¨Ìï¥ Ïó¨Î¶Ñ Ïö∞Î¶¨Î∞ò Ïã§ÎÇ¥Ïò®ÎèÑ ÏµúÎåÄÍ∞íÍ≥º ÏµúÏÜåÍ∞í ÏïåÎ†§Ï§ò': {'8B_4bit': 'Ïò¨Ìï¥ Ïó¨Î¶Ñ Ïö∞Î¶¨Î∞òÏùò Ïã§ÎÇ¥Ïò®ÎèÑ ÏµúÎåÄÍ∞íÏùÄ 30.50‚ÑÉÏù¥Í≥†, ÏµúÏÜåÍ∞íÏùÄ 22.50‚ÑÉÏûÖÎãàÎã§.', '8B_8bit': 'Ïò¨Ìï¥ Ïó¨Î¶Ñ Ïö∞Î¶¨Î∞òÏùò Ïã§ÎÇ¥Ïò®ÎèÑ ÏµúÎåÄÍ∞íÏùÄ 30.50‚ÑÉÎ°ú, ÏµúÏÜåÍ∞íÏùÄ 22.50‚ÑÉÏûÖÎãàÎã§.', '8B_16bit': 'Ïò¨Ìï¥ Ïó¨Î¶Ñ(6Ïõî ~ 8Ïõî) Ïö∞Î¶¨Î∞òÏùò Ïã§ÎÇ¥Ïò®ÎèÑ ÏµúÎåÄÍ∞íÏùÄ 30.50‚ÑÉÏù¥Í≥†, ÏµúÏÜåÍ∞íÏùÄ 22.50‚ÑÉÏûÖÎãàÎã§.', '3B_16bit': 'Ïò¨Ìï¥ Ïó¨Î¶Ñ(6Ïõî ~ 8Ïõî) Ïö∞Î¶¨Î∞òÏùò Ïã§ÎÇ¥Ïò®ÎèÑ ÏµúÎåÄÍ∞íÏùÄ 30.50‚ÑÉÏòÄÏäµÎãàÎã§. ÏµúÎåÄÍ∞íÏùÄ 8Ïõî 31ÏùºÏóê occuredÌñàÏäµÎãàÎã§. Ïò¨Ìï¥ Ïó¨Î¶Ñ Ïö∞Î¶¨Î∞òÏùò Ïã§ÎÇ¥Ïò®ÎèÑ ÏµúÏÜåÍ∞íÏùÄ 22.50‚ÑÉÏòÄÏäµÎãàÎã§. ÏµúÏÜåÍ∞íÏùÄ 6Ïõî 1ÏùºÏóê occuredÌñàÏäµÎãàÎã§.', 'GT_Response': 'Ïò¨Ìï¥ Ïó¨Î¶Ñ(6Ïõî ~ 8Ïõî) Ïö∞Î¶¨Î∞òÏùò Ïã§ÎÇ¥Ïò®ÎèÑ ÏµúÎåÄÍ∞íÍ≥º ÏµúÏÜåÍ∞íÏùÄ Í∞ÅÍ∞Å 30.50¬∞CÏôÄ 22.50¬∞CÏûÖÎãàÎã§.'}, 'Ïö∞Î¶¨Î∞òÍ≥º ÏïûÎ∞ò Ï§ë Í∞ÄÏû• ÎçîÏö¥ Î∞©ÏùÄ?': {\"('3B_16bit', '8B_4bit')\": 'Ïã§ÌñâÏ§ë ÏóêÎü¨ Î∞úÏÉù', '8B_8bit': 'ÌòÑÏû¨ Ïö∞Î¶¨Î∞òÍ≥º ÏïûÎ∞ò Ï§ë ÏïûÎ∞òÏù¥ 27.00‚ÑÉÎ°ú Í∞ÄÏû• ÎçîÏõåÏöî.', '8B_16bit': 'ÏïûÎ∞ò(27.00‚ÑÉ)Ïù¥ Ïö∞Î¶¨Î∞ò(27.00‚ÑÉ)Î≥¥Îã§ 0.00‚ÑÉ Îçî ÎÜíÏäµÎãàÎã§.', 'GT_Response': 'ÏïûÎ∞òÏù¥(Í∞Ä) 27.00¬∞CÎ°ú Í∞ÄÏû• ÎçîÏö¥ Î∞©Ïù¥ÏóêÏöî.'}}\n"
     ]
    }
   ],
   "source": [
    "responses = {}\n",
    "\n",
    "for name in names:\n",
    "    # Î™®Îç∏ ÌÅ¨Í∏∞ Ï∂îÏ∂ú (8B ÎòêÎäî 3B)\n",
    "    model_size_match = re.search(r'(\\d+B)', name)\n",
    "    model_size = model_size_match.group(1) if model_size_match else None\n",
    "    \n",
    "    # ÎπÑÌä∏ Ïàò Ï∂îÏ∂ú (4bit, 8bit, 16bit)\n",
    "    bit_match = re.search(r'_(\\d+bit)', name)\n",
    "    bit_size = bit_match.group(1) if bit_match else None\n",
    "    \n",
    "    # exp_tag ÏÉùÏÑ±\n",
    "    if model_size and bit_size:\n",
    "        exp_tag = f\"{model_size}_{bit_size}\"\n",
    "    print(exp_tag)\n",
    "    with open(f\"../experiments/result_3rdyear/{name}_response.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "        for item in data:\n",
    "            input = item[\"Input\"]\n",
    "            if input not in responses:\n",
    "                responses[input] = {\n",
    "                    \"GT_Response\": item[\"GT_Response\"],\n",
    "                }\n",
    "            # if \"GT_Response\" in item:\n",
    "            #     print(item[\"GT_Response\"])\n",
    "            if \"PD_Response\" in item:\n",
    "                pd_response = item[\"PD_Response\"]\n",
    "            else:\n",
    "                pd_response = \"Ïã§ÌñâÏ§ë ÏóêÎü¨ Î∞úÏÉù\"\n",
    "            \n",
    "            responses[input][f\"{exp_tag}\"] = pd_response\n",
    "\n",
    "# if the response is exactly equal, then merge them and make in to one, key is then tuple\n",
    "for input, response in responses.items():\n",
    "    if len(response) == 1:\n",
    "        continue\n",
    "    \n",
    "    # merge every matching pd_response (not only first one but every combination)\n",
    "    # create groups of responses with same values\n",
    "    from collections import defaultdict\n",
    "    \n",
    "    # group responses by their values (excluding GT_Response)\n",
    "    value_groups = defaultdict(list)\n",
    "    \n",
    "    for key, value in response.items():\n",
    "        if key != \"GT_Response\":\n",
    "            value_groups[value].append(key)\n",
    "    \n",
    "    # merge keys that have the same response values\n",
    "    merged_responses = {}\n",
    "    for value, keys in value_groups.items():\n",
    "        if len(keys) > 1:\n",
    "            # create tuple key for merged responses\n",
    "            merged_key = str(tuple(sorted(keys)))\n",
    "            merged_responses[merged_key] = value\n",
    "        else:\n",
    "            # keep single responses as is\n",
    "            merged_responses[keys[0]] = value\n",
    "    \n",
    "    # add back GT_Response\n",
    "    merged_responses[\"GT_Response\"] = response[\"GT_Response\"]\n",
    "    \n",
    "    # for key in merged_responses:\n",
    "    #     if isinstance(merged_responses[key], list):\n",
    "    #         merged_responses[key] = \" \".join(merged_responses[key])\n",
    "\n",
    "    # update responses dict\n",
    "    responses[input] = merged_responses\n",
    "\n",
    "# import pprint\n",
    "# pprint.pprint(responses)\n",
    "\n",
    "# save to json\n",
    "with open(\"responses.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(responses, f, ensure_ascii=False, indent=4)\n",
    "print(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
