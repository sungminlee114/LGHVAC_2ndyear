{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory of src to the path\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'torch' from '/venv/main/lib/python3.12/site-packages/torch/__init__.py'>\n",
      "1\n",
      "ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch)\n",
    "# print(torch.__version__)\n",
    "print(torch.cuda.device_count())\n",
    "from unsloth import FastLanguageModel, unsloth_train\n",
    "\n",
    "from transformers import TrainerCallback, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling, BitsAndBytesConfig\n",
    "from datasets import load_dataset, Dataset\n",
    "from peft import get_peft_model, LoraConfig, TaskType, PeftModel\n",
    "import pprint\n",
    "import json\n",
    "from pathlib import Path\n",
    "import transformers\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "from src.db.manager import DBManager\n",
    "from src.input_to_instructions.types import InstructionQ\n",
    "from trl import SFTTrainer\n",
    "\n",
    "# ì‹œë“œ ì„¤ì •\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    transformers.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "# ì‹œë“œê°’ ì„¤ì •\n",
    "seed = 3407\n",
    "set_seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using flash_attention_2 for attention computation.\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 0     # Unsloth auto supports RoPE Scaling internally!\n",
    "# dtype = None              # None for auto detection\n",
    "load_in_4bit = False      # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "device = f\"cuda\"\n",
    "\n",
    "\n",
    "\n",
    "if torch.cuda.get_device_capability()[0] >= 8:\n",
    "    attn_implementation = \"flash_attention_2\"\n",
    "    torch_dtype = torch.bfloat16\n",
    "else:\n",
    "    attn_implementation = \"eager\"\n",
    "    torch_dtype = torch.float16\n",
    "# attn_implementation = \"eager\"\n",
    "print(f\"Using {attn_implementation} for attention computation.\")\n",
    "# QLora?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_DATASET_DIR: ../finetuning/dataset/v7-250309-reduceinputanddatefunctioncall\n",
      "[PosixPath('../finetuning/dataset/v7-250309-reduceinputanddatefunctioncall/prompt.txt'), PosixPath('../finetuning/dataset/v7-250309-reduceinputanddatefunctioncall/refine.ipynb'), PosixPath('../finetuning/dataset/v7-250309-reduceinputanddatefunctioncall/scenario1'), PosixPath('../finetuning/dataset/v7-250309-reduceinputanddatefunctioncall/scenario2'), PosixPath('../finetuning/dataset/v7-250309-reduceinputanddatefunctioncall/summary.ipynb')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# BASE_DATASET_DIR = Path(\"../dataset/v5-250228-multimetadata\")\n",
    "# dataset_name = \"v6-250306-optimizetoken\"\n",
    "dataset_name = \"v7-250309-reduceinputanddatefunctioncall\"\n",
    "BASE_DATASET_DIR = Path(f\"../finetuning/dataset/{dataset_name}\")\n",
    "print(f\"BASE_DATASET_DIR: {BASE_DATASET_DIR}\")\n",
    "print(list(BASE_DATASET_DIR.iterdir()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë„ˆëŠ” ìœ ì €ì˜ HVAC ê´€ë ¨ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” Agentì˜ ê³„íšì„ ì„¤ê³„í•˜ëŠ” ì •í™•í•˜ê³  í›Œë£¡í•œ ì¸ê³µì§€ëŠ¥ì´ë‹¤. \n",
      "ì‚¬ìš©ìì˜ ì§ˆë¬¸(Input)ì„ ë°›ì•„ Agentì˜ Instructionsë¥¼ ì¶œë ¥í•´ ì£¼ì–´ì•¼ í•œë‹¤.\n",
      "Thinkingì—ì„œëŠ” HVAC ìƒì‹ì„ ë°”íƒ•ìœ¼ë¡œ ìœ ì €ì˜ ì˜ë„ë¥¼ ì¶”ì¸¡í•´ ë¹ ì§„ contextë¥¼ ì¶”ì¸¡í•˜ì—¬ ì§ˆë¬¸ì˜ ëª¨í˜¸í•¨ì„ ì—†ì•¤ ì™„ë²½í•œ í˜•íƒœì˜ ì§ˆë¬¸ì„ ì¶œë ¥í•˜ê³ , ì´ì— ëŒ€í•œ ë‹µë³€ ê³„íšì„ ì„¸ì›Œì•¼í•¨.\n",
      "Expectationì—ì„œëŠ” ìœ ì €ê°€ ê¸°ëŒ€í• ë§Œí•œ ë‹µë³€ì„ ì¶”ì¸¡í•´ì•¼í•¨.\n",
      "Mappingì—ì„œëŠ” ì§ˆë¬¸ì— ì‚¬ìš©ëœ high-level taxonomyë¥¼ metadataë¥¼ ë°”íƒ•ìœ¼ë¡œ low-level taxonomyë¡œì˜ mappingì„ ê³„ì‚°í•˜ì—¬ì•¼ í•¨.\n",
      "ì´ë•Œ metadataì— ì—†ëŠ” ì •ë³´ë¥¼ ê¸°ìˆ í•˜ëŠ” ë“± ê±°ì§“ëœ ì¶œë ¥ì„ í•˜ë©´ ì•ˆë˜ê³ , ëª¨ë¥´ëŠ” ì •ë³´ê°€ ìˆìœ¼ë©´ Unknownì´ë¼ ë‹µë³€í•´ì•¼í•¨.\n",
      "Scriptì—ì„œëŠ” data í•¨ìˆ˜ë¥¼ ì´ìš©í•˜ì—¬ pandas dataframe í˜•ì‹ì˜ ë°ì´í„°ë¥¼ ì¿¼ë¦¬í•˜ì—¬ ë‹µë³€ì— í•„ìš”í•œ ì—°ì‚°ì„ python ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì§œ ìˆ˜í–‰í•œë‹¤. ì´ë•Œ ì‹¤í–‰ ì—ëŸ¬ì— ì¡°ì‹¬í•œë‹¤. python\n",
      "Expectationì˜ ëª…ì‹œëœ ëª¨ë“  variableì´ scriptì—ì„œ ê³„ì‚°ë˜ì•¼ í•œë‹¤.\n",
      "jsoní˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ë©°, eval() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ê´„í˜¸ë“¤ê³¼ ë”°ì˜´í‘œë“¤ì˜ ìˆœì„œì™€ ë‹«í˜ì„ ë§¤ìš° ì‹ ê²½ì¨ì„œ ì¶œë ¥í•´ì•¼í•œë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "train_type = \"ours\"\n",
    "def sub(name, common_prompt):\n",
    "    # Remove the section between <|name|> ... <|name|> including the tags themselves\n",
    "    # Use re.DOTALL to match newlines with '.'\n",
    "    pattern = rf\"\\n?<\\|{name}\\|>[\\s\\S]*?<\\|{name}\\|>\"\n",
    "    common_prompt = re.sub(pattern, \"\", common_prompt, flags=re.DOTALL)\n",
    "    return common_prompt\n",
    "\n",
    "common_prompt = open(BASE_DATASET_DIR / f\"prompt.txt\", \"r\").read()\n",
    "\n",
    "sub_targets = []\n",
    "if train_type == \"ours\":\n",
    "    sub_targets = []\n",
    "elif train_type == \"BASE\":\n",
    "    sub_targets = [\"Thinking\", \"Expectation\", \"Mapping\", \"Script\", \"Examples\"]\n",
    "elif train_type in [\"WoThinking\"]:\n",
    "    sub_targets = [\"Thinking\"]\n",
    "elif train_type in [\"woMetadata\"]:\n",
    "    sub_targets = [\"Metadata\"]\n",
    "elif train_type in [\"WoMetadata+Thinking\"]:\n",
    "    sub_targets = [\"Metadata\", \"Thinking\"]\n",
    "elif train_type in [\"woExp\"]:\n",
    "    sub_targets = [\"Expectation\"]\n",
    "\n",
    "if train_type in [\"woQM\", \"woQM+Script\"]:\n",
    "    sub_targets = [\"QM\", \"Mapping\"]\n",
    "if train_type in [\"woScript\", \"woQM+Script\"]:\n",
    "    sub_targets = [\"Script\"]\n",
    "\n",
    "\n",
    "for sub_target in sub_targets:\n",
    "    common_prompt = sub(sub_target, common_prompt)\n",
    "# remove all <||>\n",
    "common_prompt = re.sub(r\"<\\|.*?\\|>\", \"\", common_prompt)\n",
    "print(common_prompt)\n",
    "\n",
    "# print(common_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('../finetuning/dataset/v7-250309-reduceinputanddatefunctioncall/scenario1'), PosixPath('../finetuning/dataset/v7-250309-reduceinputanddatefunctioncall/scenario2')]\n"
     ]
    }
   ],
   "source": [
    "scenario_dirs = [d for d in BASE_DATASET_DIR.iterdir() if d.is_dir() and \"scenario\" in d.name and \"metadata.json\" in [f.name for f in d.iterdir()]]\n",
    "print(scenario_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dateutils import normalize_sql_dates\n",
    "\n",
    "def read_dataset(dir, path):\n",
    "    # the file is originally json-list format\n",
    "    # we want every first-level elements to be a string itself\n",
    "    # for example, [{\"Hi\": \"a'b'\"}, {\"Hi\": \"c'd'\"}] -> [\"\"\"{\"Hi\": \"a'b'\"}\"\"\", \"\"\"{\"Hi\": \"c'd'\"}\"\"\"]\n",
    "    \n",
    "    metadata = json.load(open(dir / \"metadata.json\", \"r\"))\n",
    "\n",
    "    path = dir / path\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.loads(f.read())\n",
    "    \n",
    "    result = []\n",
    "    for d in data:\n",
    "        if train_type in [\"WoThinking\", \"WoMetadata+Thinking\"]:\n",
    "            del d[\"Response\"][\"Thinking\"]\n",
    "        elif train_type in [\"woExp\"]:\n",
    "            del d[\"Response\"][\"Expectations\"]\n",
    "        \n",
    "        if \"Script\" in d[\"Response\"]:\n",
    "            if train_type in [\"woScript\", \"woQM+Script\"]:\n",
    "                new_scripts = []\n",
    "                for i, script in enumerate(d[\"Response\"][\"Script\"]):\n",
    "                    if \"data\" in script:\n",
    "                        new_scripts.append(script)\n",
    "                d[\"Response\"][\"Script\"] = new_scripts\n",
    "\n",
    "            if train_type in [\"woQM\"]:\n",
    "                new_scripts = []\n",
    "                for i, script in enumerate(d[\"Response\"][\"Script\"]):\n",
    "                    if \"data\" in script:\n",
    "                        new_scripts.append(script)\n",
    "                    else:\n",
    "                        for m, n in [(\"ì‹¤ë‚´ì˜¨ë„\", \"roomtemp\"), (\"ì„¤ì •ì˜¨ë„\", \"settemp\")]:\n",
    "                            script = script.replace(f\"'{m}'\", f\"'{n}'\")\n",
    "                        \n",
    "                        new_scripts.append(script)\n",
    "                d[\"Response\"][\"Script\"] = new_scripts\n",
    "\n",
    "            if train_type in [\"woQM\", \"woQM+Script\"]:\n",
    "                mapping = d[\"Response\"][\"Mapping\"]\n",
    "                for i, script in enumerate(d[\"Response\"][\"Script\"]):\n",
    "                    if \"data\" not in script:\n",
    "                        continue\n",
    "\n",
    "                    t_match = re.search(r\"t=('[^']+'|\\[[^\\]]+\\])\", script)\n",
    "                    s_match = re.search(r\"s=('[^']+'|\\[[^\\]]+\\])\", script)\n",
    "                    m_match = re.search(r\"m=('[^']+'|\\[[^\\]]+\\])\", script)\n",
    "                    t = eval(t_match.group(1)) if t_match else None\n",
    "                    s = eval(s_match.group(1)) if s_match else None\n",
    "                    m = eval(m_match.group(1)) if m_match else None\n",
    "                    \n",
    "                    if isinstance(t, str):\n",
    "                        t = [t]\n",
    "                    if isinstance(s, str):\n",
    "                        s = [s]\n",
    "                    if isinstance(m, str):\n",
    "                        m = [m]\n",
    "\n",
    "                    t_raw = [mapping['temporal'][t_highlevel] for t_highlevel in t]\n",
    "                    s_raw = [mapping['spatials'][s_highlevel] for s_highlevel in s]\n",
    "                    m_raw = [mapping['modalities'][m_highlevel] for m_highlevel in m]\n",
    "                    s_raw = [item for sublist in s_raw for item in (sublist if isinstance(sublist, list) else [sublist])]\n",
    "                    sql = DBManager.get_query_strings_v2(\n",
    "                        metadata, m_raw, t_raw, s_raw\n",
    "                    )\n",
    "                    sql = normalize_sql_dates(sql)\n",
    "                    # replace data(...) with sql using regex\n",
    "                    d[\"Response\"][\"Script\"][i] = re.sub(r\"data\\(([^)]+)\\)\", lambda x: f\"\\\"{sql}\\\"\", script)\n",
    "                del d[\"Response\"][\"Mapping\"]\n",
    "            #     # raise NotImplementedError\n",
    "            # elif train_type in [\"woOp\"]:\n",
    "            #     instructions = d[\"Response\"][\"Instructions\"]\n",
    "            #     d[\"Response\"][\"Instructions\"] = [i for i in instructions if i[\"type\"] == \"q\"]\n",
    "\n",
    "        tags = d[\"Tags\"][\"Style\"]\n",
    "\n",
    "        skip_tags = [\"Reason\", \"Graph\", \"Unrelated\", \"Prediction\"]\n",
    "\n",
    "        skip = False\n",
    "        for skip_tag in skip_tags:\n",
    "            if skip_tag in tags:\n",
    "                skip = True\n",
    "                break\n",
    "        \n",
    "        if skip:\n",
    "            continue\n",
    "\n",
    "        \n",
    "        result.append({\"Metadata\": metadata, \"Input\": d[\"Input\"], \"Scenarios\": dir.name, \"Response\": json.dumps(d[\"Response\"], ensure_ascii=False)})\n",
    "    # result = [{\"Input\": d[\"Input\"], \"Response\": json.dumps(d[\"Response\"], ensure_ascii=False)} for d in data]\n",
    "    # print(f\"Read {len(result)} examples from {path}\")\n",
    "    # print(f\"Type of result: {type(result)}\")\n",
    "    # print(f\"Type of result[0]: {type(result[0])}\")\n",
    "    # print(f\"Type of result[0]['Input']: {type(result[0]['Input'])}\")\n",
    "    # print(f\"Type of result[0]['Response']: {type(result[0]['Response'])}\")\n",
    "    return result\n",
    "\n",
    "dataset_trs = []\n",
    "dataset_tss = []\n",
    "for scenario_dir in scenario_dirs:\n",
    "    dataset_trs.extend(read_dataset(scenario_dir, \"onlyq_tr.json\"))\n",
    "    dataset_tss.extend(read_dataset(scenario_dir, \"onlyq_ts.json\"))\n",
    "    # print(\"Warning!!!: Test set is not mutually exclusive with training set.\")\n",
    "\n",
    "dataset_sampling_rate = 1\n",
    "dataset_trs = np.random.choice(dataset_trs, size=int(len(dataset_trs) * dataset_sampling_rate), replace=False)\n",
    "dataset_trs = dataset_trs.tolist()\n",
    "dataset_tr_ = Dataset.from_list(dataset_trs) # ì„œë¡œ ë‹¤ë¥¸ ë©”íƒ€ë°ì´í„° í•©ì¹˜ë©´ì„œ\n",
    "dataset_ts_ = Dataset.from_list(dataset_tss) # Mutually exclusiveí•œ ì• ë“¤ì€ None ë¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_prompts_func(examples):\n",
    "    global tokenizer\n",
    "    convos = []\n",
    "    inputs = []\n",
    "    # Iterate through each item in the batch (examples are structured as lists of values)\n",
    "    print(examples)\n",
    "    for metadata, input, response in zip(examples['Metadata'], examples['Input'], examples['Response']):\n",
    "        # global max_seq_length\n",
    "        response.replace(\"    \", \"\")\n",
    "\n",
    "        # print(metadata['current_datetime'])\n",
    "        # print(metadata['idu_mapping'])\n",
    "        answer = {\n",
    "            \"content\": f\"{response}\",\n",
    "            \"role\": \"assistant\"\n",
    "        }\n",
    "        prompt = {\n",
    "            \"content\": common_prompt,\n",
    "            \"role\": \"system\"\n",
    "        }\n",
    "        content = \"\"\n",
    "        if train_type not in [\"WoMetadata\", \"WoMetadata+Thinking\"]:\n",
    "            content += f\"Metadata:{metadata};\"\n",
    "        content += f\"Input:{input};\"\n",
    "        user_input = {\n",
    "            \"content\": content,\n",
    "            \"role\": \"user\"\n",
    "        }\n",
    "        convos.append([prompt, user_input, answer])\n",
    "        inputs.append([prompt, user_input])\n",
    "        \n",
    "        # print(\"Answer length: \", len(response))\n",
    "        # convos.append([prompt, user_input, answer])\n",
    "        \n",
    "        # if len(response) + 50 > max_seq_length:\n",
    "        #     max_seq_length = len(response) + len(metadata) + len(input) + 50\n",
    "            # print(response)\n",
    "    \n",
    "    texts = [\n",
    "        tokenizer.apply_chat_template(convo, tokenize=False, add_generation_prompt=False)\n",
    "        for convo in convos]\n",
    "    \n",
    "    # remove \\n\\nCutting Knowledge Date: BLAH BLAH \\nToday Date: BLAH BLAH\\n\\n using regex\n",
    "    # texts = [re.sub(r'(\\nCutting Knowledge Date:.*?\\nToday Date:.*?\\n\\n)', '', text) for text in texts]\n",
    "    return {\"text\": texts, \"input\": inputs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_content(text: str):\n",
    "    \"\"\"Extract content from model output.\"\"\"\n",
    "    if \"start_header_id\" in text:\n",
    "        pattern = r\"<\\|start_header_id\\|>assistant<\\|end_header_id\\|>(.*?)<\\|eot_id\\|>\"\n",
    "    elif \"start_of_turn\" in text:\n",
    "        pattern = r\"<start_of_turn>model\\n(.*?)<eos>\"\n",
    "    elif \"im_start\" in text:\n",
    "        # <|im_start|>assistant{\"Thinking\": \"ì‚¬ìš©ìëŠ” ì˜¤ëŠ˜ 4ì¸µì— ìˆëŠ” ëª¨ë“  ë°©ì˜ ì„¤ì •ì˜¨ë„ì˜ í‰ê· ê°’ì„ ì•Œê³  ì‹¶ì–´í•©ë‹ˆë‹¤. 4ì¸µì— í•´ë‹¹í•˜ëŠ” iduë“¤(01_IB7, 02_I84, 02_I85)ì˜ ì˜¤ëŠ˜ ì„¤ì •ì˜¨ë„ ë°ì´í„°ë¥¼ ì¿¼ë¦¬í•œ í›„ í‰ê· ê°’ì„ ê³„ì‚°í•˜ì—¬ ë°˜í™˜í•˜ë©´ ë©ë‹ˆë‹¤.\", \"Expectations\": [\"ì˜¤ëŠ˜ 4ì¸µì˜ í‰ê·  ì„¤ì •ì˜¨ë„ëŠ” {{settemp_avg}}â„ƒ ì…ë‹ˆë‹¤.\"], \"Instructions\": [{\"type\": \"q\", \"args\": {\"table_name\": \"data_t\", \"columns\": [\"settemp\"], \"temporal\": \"[DATE_TRUNC('day', DATE 'CURRENT_DATE'), DATE_TRUNC('day', DATE 'CURRENT_DATE' + INTERVAL '1 day'))\", \"spatials\": [\"01_IB7\", \"02_I84\", \"02_I85\"]}, \"result_name\": \"qr\"}, {\"type\": \"o\", \"script\": \"settemp_avg = qr['settemp'].mean();\", \"returns\": [\"settemp_avg\"]}]}<|im_end|>\n",
    "        pattern = r\"<\\|im_start\\|>assistant\\n(.*?)<\\|im_end\\|>\"\n",
    "    elif \"|endofturn|\" in text:\n",
    "        pattern = r\"\\[\\|assistant\\|\\](.*?)\\[\\|endofturn\\|\\]\"\n",
    "    \n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    result = match.group(1).strip() if match else None\n",
    "    result = result.replace(\"<|finetune_right_pad_id|>\", \"\")\n",
    "    # result = result.replace(\"<|start_header_id|>\", \"\")\n",
    "    return result\n",
    "\n",
    "class CustomCallback(TrainerCallback):\n",
    "    def __init__(self, tokenizer, model, eval_inputs, inputs, metadatas, scenarios, save_dir=\"./eval_generations\", max_new_tokens=128):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model = model\n",
    "        \n",
    "        convos = []\n",
    "        for chat in eval_inputs:\n",
    "            convos.append(tokenizer.apply_chat_template(\n",
    "                chat,\n",
    "                tokenize=True,\n",
    "                add_generation_prompt=True,\n",
    "                return_tensors=\"pt\"\n",
    "            ).to(model.device))\n",
    "        \n",
    "        padded_inputs = []\n",
    "        attention_masks = []\n",
    "        \n",
    "        max_length = max(cn.size(1) for cn in convos)\n",
    "        for cn in convos:\n",
    "            pad_length = max_length - cn.size(1)\n",
    "            \n",
    "            if pad_length > 0:\n",
    "                # íŒ¨ë”© ì¶”ê°€\n",
    "                padded = torch.cat([\n",
    "                    torch.full((1, pad_length), tokenizer.pad_token_id, device=model.device),\n",
    "                    cn,\n",
    "                ], dim=1)\n",
    "                \n",
    "                # ì–´í…ì…˜ ë§ˆìŠ¤í¬ ìƒì„± (ì›ë³¸ ì‹œí€€ìŠ¤ëŠ” 1, íŒ¨ë”©ì€ 0)\n",
    "                mask = torch.cat([\n",
    "                    torch.zeros(1, pad_length, device=model.device),\n",
    "                    torch.ones(1, cn.size(1), device=model.device),\n",
    "                ], dim=1)\n",
    "            else:\n",
    "                padded = cn\n",
    "                mask = torch.ones(1, cn.size(1), device=model.device)\n",
    "            \n",
    "            padded_inputs.append(padded)\n",
    "            attention_masks.append(mask)\n",
    "        \n",
    "        # ë°°ì¹˜ í…ì„œ ìƒì„±\n",
    "        self.batch_tensor = torch.cat(padded_inputs, dim=0)\n",
    "        self.attention_mask = torch.cat(attention_masks, dim=0)\n",
    "        self.mdscs = [(md, sc) for md, sc in zip(metadatas, scenarios)]\n",
    "        self.inputs = inputs\n",
    "        self.save_dir = save_dir\n",
    "        self.max_new_tokens = max_new_tokens\n",
    "\n",
    "        os.makedirs(self.save_dir, exist_ok=True)\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        step = state.global_step\n",
    "        if step == 0:\n",
    "            return  # skip at step 0\n",
    "        \n",
    "        loss = logs.get(\"loss\", None)\n",
    "        if step < 100:\n",
    "            return\n",
    "        # inputs = self.tokenizer(\n",
    "        #     self.eval_inputs, \n",
    "        #     return_tensors=\"pt\",\n",
    "        #     padding=True,\n",
    "        #     # truncation=True,\n",
    "        # ).to(self.model.device)\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            FastLanguageModel.for_inference(self.model)\n",
    "            outputs = self.model.generate(\n",
    "                input_ids=self.batch_tensor,\n",
    "                attention_mask=self.attention_mask,\n",
    "                max_new_tokens=self.max_new_tokens,\n",
    "                do_sample=False,\n",
    "                pad_token_id=self.tokenizer.pad_token_id,\n",
    "            )\n",
    "        decoded = self.tokenizer.batch_decode(\n",
    "            outputs, \n",
    "            skip_special_tokens=False\n",
    "        )\n",
    "\n",
    "        # Save to file\n",
    "        global lora_repr\n",
    "        output_path = os.path.join(self.save_dir, f\"r-{lora_repr}-step-{step}.json\")\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            # f.write(\"[\\n\")\n",
    "            j = []\n",
    "            for i, out in enumerate(decoded):\n",
    "                try:\n",
    "                    out = extract_content(out)\n",
    "                    out = eval(out)\n",
    "                except:\n",
    "                    pass\n",
    "                result = {\n",
    "                    \"Input\": self.inputs[i],\n",
    "                    \"Scenario\": self.mdscs[i][1],\n",
    "                    \"Metadata\": self.mdscs[i][0],\n",
    "                    \"Candidate\": out\n",
    "                }\n",
    "                j.append(result)\n",
    "            try:\n",
    "                json_str = json.dumps(j, ensure_ascii=False)\n",
    "            except Exception as e:\n",
    "                print(json_str)\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "            # f.write(json_str)\n",
    "        FastLanguageModel.for_training(self.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_id = 'sh2orc/Llama-3.1-Korean-8B-Instruct'\n",
    "# model_id = 'Bllossom/llama-3.2-Korean-Bllossom-AICA-5B'\n",
    "\n",
    "def load_model(model_id, per_device_train_batch_size =60, epochs = 55, lora_r = 211):\n",
    "    model_dir = f\"/model/{model_id.replace('/', '-')}\"\n",
    "\n",
    "    global tokenizer\n",
    "    pretrained_model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name = model_id,\n",
    "        # max_seq_length = max_seq_length,\n",
    "        dtype = torch_dtype,\n",
    "        load_in_4bit = False,\n",
    "        load_in_8bit = False,\n",
    "        # quantization_config=BitsAndBytesConfig(\n",
    "        #     load_in_4bit=True,\n",
    "        #     bnb_4bit_use_double_quant=True,\n",
    "        #     bnb_4bit_quant_type=\"nf4\",\n",
    "        #     bnb_4bit_compute_dtype=torch_dtype\n",
    "        #     # load_in_8bit=True,\n",
    "        #     # llm_int8_enable_fp32_cpu_offload=False if not \"27B\" in model_id else True,\n",
    "        # ),\n",
    "        # device_map=device,\n",
    "        cache_dir=f\"{model_dir}/cache\",\n",
    "        attn_implementation=attn_implementation,\n",
    "        # trust_remote_code=False,\n",
    "        # local_files_only=True\n",
    "    )\n",
    "    tokenizer.padding_side = \"left\"\n",
    "    # tokenizer.truncation_side = \"left\"\n",
    "    print(f\"Pad Token id: {tokenizer.pad_token_id} and Pad Token: {tokenizer.pad_token}\")\n",
    "    print(f\"EOS Token id: {tokenizer.eos_token_id} and EOS Token: {tokenizer.eos_token}\")\n",
    "\n",
    "    max_seq_length = 0\n",
    "    \n",
    "\n",
    "    dataset_tr = dataset_tr_.map(formatting_prompts_func, batched=True)\n",
    "    dataset_ts = dataset_ts_.map(formatting_prompts_func, batched=True)\n",
    "\n",
    "    max_seq_length = 10000\n",
    "    max_seq_length = max([len(tokenizer.encode(dataset_tr[i]['text'])) for i in range(len(dataset_tr))]) + 100\n",
    "    # max_seq_length += len(common_prompt)\n",
    "    print(max_seq_length)\n",
    "    print(dataset_tr[0])\n",
    "    print(len(dataset_tr), len(dataset_ts))\n",
    "    # print(f\"seq length: {len(tokenizer.encode(dataset_tr[0]['text']))}\")\n",
    "\n",
    "    \n",
    "    gradient_accumulation_steps = int(np.ceil(len(dataset_tr) / per_device_train_batch_size))\n",
    "    print(f\"Gradient Accumulation Steps: {gradient_accumulation_steps}\")\n",
    "\n",
    "    # clear all checkpoints\n",
    "    lora_alpha = lora_r * 2\n",
    "    global lora_repr\n",
    "    lora_repr = f\"3rdyear_r{lora_r}_a{lora_alpha}_{model_id.replace('/', '-')}_tr{len(dataset_tr)}\"\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        # num_train_epochs = 1,\n",
    "        per_device_train_batch_size = per_device_train_batch_size,  # Controls the batch size per device\n",
    "        per_device_eval_batch_size=per_device_train_batch_size,\n",
    "        gradient_accumulation_steps = gradient_accumulation_steps,  # Accumulates gradients to simulate a larger batch\n",
    "        max_steps=gradient_accumulation_steps * epochs,\n",
    "        # ë¦¬ì†ŒìŠ¤ ì œì•½ë•Œë¬¸ì— batch sizeë¥¼ íƒ€í˜‘í•´ì•¼í•˜ëŠ” ê²½ìš°ê°€ ë°œìƒ -> micro batch sizeë¥¼ ì¤„ì´ê³ ,\n",
    "        # accumulated stepì„ ëŠ˜ë ¤, ì ì ˆí•œ sizeë¡œ gradientë¥¼ êµ¬í•´ weight update\n",
    "        # https://www.youtube.com/watch?v=ptlmj9Y9iwE\n",
    "        warmup_steps = gradient_accumulation_steps,\n",
    "        learning_rate = 1e-4,             # Sets the learning rate for optimization\n",
    "        fp16 = not torch.cuda.is_bf16_supported(),\n",
    "        bf16 = torch.cuda.is_bf16_supported(),\n",
    "        optim = \"adamw_torch\", # adamw_torch, adafactor, prodigy\n",
    "        weight_decay = 0.01,              # Regularization term for preventing overfitting\n",
    "        lr_scheduler_type = \"cosine\",  # Sets the learning rate scheduler\n",
    "        seed = 3407,                        \n",
    "        output_dir = f\"{model_dir}/chkpts/{lora_repr}\",  # Output directory for checkpoints and predictions     \n",
    "        report_to = \"none\",              # Enables Weights & Biases (W&B) logging\n",
    "        logging_steps = gradient_accumulation_steps,                # Sets frequency of logging to W&B\n",
    "        logging_strategy = \"steps\",       # Logs metrics at each specified step\n",
    "        # eval_strategy=\"steps\",  # enable evaluation during training\n",
    "        # eval_steps=gradient_accumulation_steps,\n",
    "        # eval_accumulation_steps=1, # ë‚®ì„ìˆ˜ë¡ evalì‹œ ì‚¬ìš©í•˜ëŠ” ë©”ëª¨ë¦¬ ì¤„ì–´ë“¦\n",
    "        save_steps=gradient_accumulation_steps,\n",
    "        save_strategy = \"steps\",               \n",
    "        # load_best_model_at_end = True,    # Loads the best model at the end\n",
    "        # save_only_model = False,           # Saves entire model, not only weights\n",
    "        # resume_from_checkpoint = f\"{model_dir}/chkpts/{lora_repr}\",  # Resumes training from a checkpoint\n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "    peft_model = FastLanguageModel.get_peft_model(\n",
    "        pretrained_model,\n",
    "        r=lora_r,   # LoRA rank - suggested values: 8, 16, 32, 64, 128\n",
    "        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \n",
    "                        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "                        # \"embed_tokens\",\n",
    "                        # \"lm_head\"\n",
    "                        ],\n",
    "        lora_alpha=lora_alpha,\n",
    "        lora_dropout=0.05,   # Supports any, but = 0 is optimized\n",
    "        bias=\"none\",      # Supports any, but = \"none\" is optimized\n",
    "        use_gradient_checkpointing=\"unsloth\",  # Ideal for long context tuning\n",
    "        random_state=3407,\n",
    "        use_rslora=False,   # Disable rank-sensitive LoRA for simpler tasks\n",
    "        loftq_config=None,   # No LoftQ, for standard fine-tuning\n",
    "        max_seq_length=max_seq_length,\n",
    "    )\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    print(len(dataset_tr))\n",
    "\n",
    "\n",
    "    custom_callback = CustomCallback(\n",
    "        tokenizer=tokenizer,\n",
    "        model=peft_model,\n",
    "        eval_inputs=dataset_ts['input'],  # \"input\"ì— prompt ë˜ëŠ” ì§ˆë¬¸ì´ ë“¤ì–´ê°€ì•¼ í•©ë‹ˆë‹¤\n",
    "        inputs=dataset_ts['Input'],\n",
    "        scenarios = dataset_ts['Scenarios'],\n",
    "        metadatas = dataset_ts['Metadata'],\n",
    "        save_dir=f\"../experiments\",\n",
    "        max_new_tokens=1280\n",
    "    )\n",
    "\n",
    "\n",
    "    trainer = SFTTrainer(\n",
    "        model = peft_model,\n",
    "        processing_class = tokenizer,\n",
    "        train_dataset = dataset_tr,\n",
    "        # eval_dataset = dataset_ts,\n",
    "        dataset_text_field = \"text\",\n",
    "        max_seq_length = max_seq_length,\n",
    "        dataset_num_proc = 2,\n",
    "        packing = False,        # Can make training 5x faster for short sequences.\n",
    "        args = args,\n",
    "        # compute_metrics = compute_metrics,\n",
    "        callbacks = [custom_callback]\n",
    "    )\n",
    "\n",
    "    \n",
    "    trainer_stats = unsloth_train(trainer)\n",
    "\n",
    "    # print(trainer_stats)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.8.1: Fast Llama patching. Transformers: 4.55.0.\n",
      "   \\\\   /|    NVIDIA H100 80GB HBM3. Num GPUs = 1. Max memory: 79.19 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.1+cu128. CUDA: 9.0. CUDA Toolkit: 12.8. Triton: 3.3.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = True]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c47b20eae2e046a6b2f5cea40331fd96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bllossom/llama-3.2-Korean-Bllossom-3B does not have a padding token! Will use pad_token = <|finetune_right_pad_id|>.\n",
      "Pad Token id: 128004 and Pad Token: <|finetune_right_pad_id|>\n",
      "EOS Token id: 128009 and EOS Token: <|eot_id|>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a94b5ce831e440119d0a5c09addcbf34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/27 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Metadata': [{'current_datetime': '2022-09-30 12:00:00', 'idu_mapping': {'01_IB5': ['ìš°ë¦¬ë°˜', '4ì¸µ'], '01_IB7': ['ì˜†ë°˜', '4ì¸µ'], '02_I81': ['ì•ë°˜', '4ì¸µ']}, 'modality_mapping': {'roomtemp': ['ì‹¤ë‚´ì˜¨ë„'], 'settemp': ['ì„¤ì •ì˜¨ë„']}}, {'current_datetime': '2022-09-30 12:00:00', 'idu_mapping': {'01_IB5': ['ìš°ë¦¬ë°˜', '4ì¸µ'], '01_IB7': ['ì˜†ë°˜', '4ì¸µ'], '02_I81': ['ì•ë°˜', '4ì¸µ']}, 'modality_mapping': {'roomtemp': ['ì‹¤ë‚´ì˜¨ë„'], 'settemp': ['ì„¤ì •ì˜¨ë„']}}, {'current_datetime': '2022-09-30 12:00:00', 'idu_mapping': {'01_IB5': ['ìš°ë¦¬ë°˜', '4ì¸µ'], '01_IB7': ['ì˜†ë°˜', '4ì¸µ'], '02_I81': ['ì•ë°˜', '4ì¸µ']}, 'modality_mapping': {'roomtemp': ['ì‹¤ë‚´ì˜¨ë„'], 'settemp': ['ì„¤ì •ì˜¨ë„']}}, {'current_datetime': '2022-09-30 12:00:00', 'idu_mapping': {'01_IB5': ['ìš°ë¦¬ë°˜', '4ì¸µ'], '01_IB7': ['ì˜†ë°˜', '4ì¸µ'], '02_I81': ['ì•ë°˜', '4ì¸µ']}, 'modality_mapping': {'roomtemp': ['ì‹¤ë‚´ì˜¨ë„'], 'settemp': ['ì„¤ì •ì˜¨ë„']}}, {'current_datetime': '2022-09-30 12:00:00', 'idu_mapping': {'01_IB5': ['ìš°ë¦¬ë°˜', '4ì¸µ'], '01_IB7': ['ì˜†ë°˜', '4ì¸µ'], '02_I81': ['ì•ë°˜', '4ì¸µ']}, 'modality_mapping': {'roomtemp': ['ì‹¤ë‚´ì˜¨ë„'], 'settemp': ['ì„¤ì •ì˜¨ë„']}}, {'current_datetime': '2022-09-30 12:00:00', 'idu_mapping': {'01_IB5': ['ìš°ë¦¬ë°˜', '4ì¸µ'], '01_IB7': ['ì˜†ë°˜', '4ì¸µ'], '02_I81': ['ì•ë°˜', '4ì¸µ']}, 'modality_mapping': {'roomtemp': ['ì‹¤ë‚´ì˜¨ë„'], 'settemp': ['ì„¤ì •ì˜¨ë„']}}, {'current_datetime': '2022-09-30 12:00:00', 'idu_mapping': {'01_IB5': ['ìš°ë¦¬ë°˜', '4ì¸µ'], '01_IB7': ['ì˜†ë°˜', '4ì¸µ'], '02_I81': ['ì•ë°˜', '4ì¸µ']}, 'modality_mapping': {'roomtemp': ['ì‹¤ë‚´ì˜¨ë„'], 'settemp': ['ì„¤ì •ì˜¨ë„']}}, {'current_datetime': '2022-09-30 12:00:00', 'idu_mapping': {'01_IB5': ['ìš°ë¦¬ë°˜', '4ì¸µ'], '01_IB7': ['ì˜†ë°˜', '4ì¸µ'], '02_I81': ['ì•ë°˜', '4ì¸µ']}, 'modality_mapping': {'roomtemp': ['ì‹¤ë‚´ì˜¨ë„'], 'settemp': ['ì„¤ì •ì˜¨ë„']}}, {'current_datetime': '2022-09-30 12:00:00', 'idu_mapping': {'01_IB5': ['ìš°ë¦¬ë°˜', '4ì¸µ'], '01_IB7': ['ì˜†ë°˜', '4ì¸µ'], '02_I81': ['ì•ë°˜', '4ì¸µ']}, 'modality_mapping': {'roomtemp': ['ì‹¤ë‚´ì˜¨ë„'], 'settemp': ['ì„¤ì •ì˜¨ë„']}}, {'current_datetime': '2022-09-30 12:00:00', 'idu_mapping': {'01_IB5': ['ìš°ë¦¬ë°˜', '4ì¸µ'], '01_IB7': ['ì˜†ë°˜', '4ì¸µ'], '02_I81': ['ì•ë°˜', '4ì¸µ']}, 'modality_mapping': {'roomtemp': ['ì‹¤ë‚´ì˜¨ë„'], 'settemp': ['ì„¤ì •ì˜¨ë„']}}, {'current_datetime': '2022-09-30 12:00:00', 'idu_mapping': {'01_IB5': ['ìš°ë¦¬ë°˜', '4ì¸µ'], '01_IB7': ['ì˜†ë°˜', '4ì¸µ'], '02_I81': ['ì•ë°˜', '4ì¸µ']}, 'modality_mapping': {'roomtemp': ['ì‹¤ë‚´ì˜¨ë„'], 'settemp': ['ì„¤ì •ì˜¨ë„']}}, {'current_datetime': '2022-09-30 12:00:00', 'idu_mapping': {'01_IB5': ['ìš°ë¦¬ë°˜', '4ì¸µ'], '01_IB7': ['ì˜†ë°˜', '4ì¸µ'], '02_I81': ['ì•ë°˜', '4ì¸µ']}, 'modality_mapping': {'roomtemp': ['ì‹¤ë‚´ì˜¨ë„'], 'settemp': ['ì„¤ì •ì˜¨ë„']}}, {'current_datetime': '2022-09-30 12:00:00', 'idu_mapping': {'01_IB5': ['ìš°ë¦¬ë°˜', '4ì¸µ'], '01_IB7': ['ì˜†ë°˜', '4ì¸µ'], '02_I81': ['ì•ë°˜', '4ì¸µ']}, 'modality_mapping': {'roomtemp': ['ì‹¤ë‚´ì˜¨ë„'], 'settemp': ['ì„¤ì •ì˜¨ë„']}}, {'current_datetime': '2022-09-30 12:00:00', 'idu_mapping': {'01_IB5': ['ìš°ë¦¬ë°˜', '4ì¸µ'], '01_IB7': ['ì˜†ë°˜', '4ì¸µ'], '02_I81': ['ì•ë°˜', '4ì¸µ']}, 'modality_mapping': {'roomtemp': ['ì‹¤ë‚´ì˜¨ë„'], 'settemp': ['ì„¤ì •ì˜¨ë„']}}, {'current_datetime': '2022-09-30 12:00:00', 'idu_mapping': {'01_IB5': ['ìš°ë¦¬ë°˜', '4ì¸µ'], '01_IB7': ['ì˜†ë°˜', '4ì¸µ'], '02_I81': ['ì•ë°˜', '4ì¸µ']}, 'modality_mapping': {'roomtemp': ['ì‹¤ë‚´ì˜¨ë„'], 'settemp': ['ì„¤ì •ì˜¨ë„']}}, {'current_datetime': '2022-09-30 12:00:00', 'idu_mapping': {'01_IB5': ['ìš°ë¦¬ë°˜', '4ì¸µ'], '01_IB7': ['ì˜†ë°˜', '4ì¸µ'], '02_I81': ['ì•ë°˜', '4ì¸µ']}, 'modality_mapping': {'roomtemp': ['ì‹¤ë‚´ì˜¨ë„'], 'settemp': ['ì„¤ì •ì˜¨ë„']}}, {'current_datetime': '2022-09-30 12:00:00', 'idu_mapping': {'01_IB5': ['ìš°ë¦¬ë°˜', '4ì¸µ'], '01_IB7': ['ì˜†ë°˜', '4ì¸µ'], '02_I81': ['ì•ë°˜', '4ì¸µ']}, 'modality_mapping': {'roomtemp': ['ì‹¤ë‚´ì˜¨ë„'], 'settemp': ['ì„¤ì •ì˜¨ë„']}}, {'current_datetime': '2022-09-30 12:00:00', 'idu_mapping': {'01_IB5': ['ìš°ë¦¬ë°˜', '4ì¸µ'], '01_IB7': ['ì˜†ë°˜', '4ì¸µ'], '02_I81': ['ì•ë°˜', '4ì¸µ']}, 'modality_mapping': {'roomtemp': ['ì‹¤ë‚´ì˜¨ë„'], 'settemp': ['ì„¤ì •ì˜¨ë„']}}, {'current_datetime': '2022-09-30 12:00:00', 'idu_mapping': {'01_IB5': ['ìš°ë¦¬ë°˜', '4ì¸µ'], '01_IB7': ['ì˜†ë°˜', '4ì¸µ'], '02_I81': ['ì•ë°˜', '4ì¸µ']}, 'modality_mapping': {'roomtemp': ['ì‹¤ë‚´ì˜¨ë„'], 'settemp': ['ì„¤ì •ì˜¨ë„']}}, {'current_datetime': '2022-09-30 12:00:00', 'idu_mapping': {'01_IB5': ['ìš°ë¦¬ë°˜', '4ì¸µ'], '01_IB7': ['ì˜†ë°˜', '4ì¸µ'], '02_I81': ['ì•ë°˜', '4ì¸µ']}, 'modality_mapping': {'roomtemp': ['ì‹¤ë‚´ì˜¨ë„'], 'settemp': ['ì„¤ì •ì˜¨ë„']}}, {'current_datetime': '2022-09-30 12:00:00', 'idu_mapping': {'01_IB5': ['ìš°ë¦¬ë°˜', '4ì¸µ'], '01_IB7': ['ì˜†ë°˜', '4ì¸µ'], '02_I81': ['ì•ë°˜', '4ì¸µ']}, 'modality_mapping': {'roomtemp': ['ì‹¤ë‚´ì˜¨ë„'], 'settemp': ['ì„¤ì •ì˜¨ë„']}}, {'current_datetime': '2022-09-30 12:00:00', 'idu_mapping': {'01_IB5': ['ìš°ë¦¬ë°˜', '4ì¸µ'], '01_IB7': ['ì˜†ë°˜', '4ì¸µ'], '02_I81': ['ì•ë°˜', '4ì¸µ']}, 'modality_mapping': {'roomtemp': ['ì‹¤ë‚´ì˜¨ë„'], 'settemp': ['ì„¤ì •ì˜¨ë„']}}, {'current_datetime': '2022-09-30 12:00:00', 'idu_mapping': {'01_IB5': ['ìš°ë¦¬ë°˜', '4ì¸µ'], '01_IB7': ['ì˜†ë°˜', '4ì¸µ'], '02_I81': ['ì•ë°˜', '4ì¸µ']}, 'modality_mapping': {'roomtemp': ['ì‹¤ë‚´ì˜¨ë„'], 'settemp': ['ì„¤ì •ì˜¨ë„']}}, {'current_datetime': '2022-09-30 12:00:00', 'idu_mapping': {'01_IB5': ['ìš°ë¦¬ë°˜', '4ì¸µ'], '01_IB7': ['ì˜†ë°˜', '4ì¸µ'], '02_I81': ['ì•ë°˜', '4ì¸µ']}, 'modality_mapping': {'roomtemp': ['ì‹¤ë‚´ì˜¨ë„'], 'settemp': ['ì„¤ì •ì˜¨ë„']}}, {'current_datetime': '2022-09-30 12:00:00', 'idu_mapping': {'01_IB5': ['ìš°ë¦¬ë°˜', '4ì¸µ'], '01_IB7': ['ì˜†ë°˜', '4ì¸µ'], '02_I81': ['ì•ë°˜', '4ì¸µ']}, 'modality_mapping': {'roomtemp': ['ì‹¤ë‚´ì˜¨ë„'], 'settemp': ['ì„¤ì •ì˜¨ë„']}}, {'current_datetime': '2022-09-30 12:00:00', 'idu_mapping': {'01_IB5': ['ìš°ë¦¬ë°˜', '4ì¸µ'], '01_IB7': ['ì˜†ë°˜', '4ì¸µ'], '02_I81': ['ì•ë°˜', '4ì¸µ']}, 'modality_mapping': {'roomtemp': ['ì‹¤ë‚´ì˜¨ë„'], 'settemp': ['ì„¤ì •ì˜¨ë„']}}, {'current_datetime': '2022-09-30 12:00:00', 'idu_mapping': {'01_IB5': ['ìš°ë¦¬ë°˜', '4ì¸µ'], '01_IB7': ['ì˜†ë°˜', '4ì¸µ'], '02_I81': ['ì•ë°˜', '4ì¸µ']}, 'modality_mapping': {'roomtemp': ['ì‹¤ë‚´ì˜¨ë„'], 'settemp': ['ì„¤ì •ì˜¨ë„']}}], 'Input': ['ì§€ê¸ˆ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ì•Œë ¤ì¤˜', 'ì´ë²ˆë‹¬ ì¤‘ ë’·ë°˜ ì˜¨ë„ê°€ ê°€ì¥ ë”ìš´ë‚ ì´ ì–¸ì œì•¼?', 'ìš°ë¦¬ë°˜ê³¼ ì˜†ë°˜ì¤‘ ë” ì¶”ìš´ê³³ì€ ì–´ë””ì•¼?', '4ì›” ì•ë°˜ í‰ê· ì˜¨ë„ ì•Œë ¤ì¤˜', 'ìš°ë¦¬ë°˜ ì´ë²ˆë‹¬ ì œì¼ ì¶”ì› ë˜ ë‚ ì€ ì–¸ì œëƒ?', 'ì˜†ë°˜ì˜ í˜„ì¬ ì˜¨ë„ë‘ ì„¤ì •ì˜¨ë„ ì•Œë ¤ì¤˜', 'ì´ë²ˆì£¼ ìš°ë¦¬ë°˜ í‰ê·  ì˜¨ë„ ì•Œë ¤ì¤˜', 'ì§€ë‚œë‹¬ ì˜¤ëŠ˜ ì˜¤í›„ 2ì‹œì— ì˜†ë°˜ì˜ ì„¤ì •ì˜¨ë„ëŠ” ì–´ë• ì–´?', 'ì˜¬í•´ ì—¬ë¦„ ì•ë°˜ í‰ê· ì˜¨ë„ ì•Œë ¤ì¤˜', 'ì˜¤ëŠ˜ ì˜¤í›„ 4ì‹œë¶€í„° 6ì‹œê¹Œì§€ ì‹¤ë‚´ì˜¨ë„ í‰ê·  ì•Œë ¤ì¤˜', 'ìš°ë¦¬ë°˜ì˜ í˜„ì¬ ì„¤ì • ì˜¨ë„ ì•Œë ¤ì¤˜', 'ì‘ë…„ ê²¨ìš¸ ìš°ë¦¬ë°˜ í‰ê· ì˜¨ë„ ì•Œë ¤ì¤˜', 'ì§€ê¸ˆ 4ì¸µ ìµœëŒ€ ì„¤ì •ì˜¨ë„ ì•Œë ¤ì¤˜', 'ì–´ì œ ìš°ë¦¬ë°˜ê³¼ ì˜†ë°˜ì˜ ì„¤ì •ì˜¨ë„ ì°¨ì´ ì•Œë ¤ì¤˜', 'ì§€ë‚œì£¼ì— ì„¤ì •ì˜¨ë„ì™€ ì‹¤ë‚´ì˜¨ë„ ì°¨ì´ê°€ ê°€ì¥ ë§ì´ ë‚¬ë˜ ë‚ ì€?', 'ì˜¤ëŠ˜ ì˜¤ì „ 11ì‹œì— ì˜†ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ëŠ” ì–´ë• ì–´?', 'ìš°ë¦¬ë°˜, ì˜†ë°˜, ì•ë°˜ ì¤‘ ê°€ì¥ ì¶”ìš´ ë°©ì€?', 'ë¡¯ë°ìºìŠ¬ì˜ í˜„ì¬ ì˜¨ë„ ì•Œë ¤ì¤˜', 'ì˜¤ëŠ˜ ìš°ë¦¬ë°˜ê³¼ ì˜†ë°˜ì˜ í‰ê·  ì˜¨ë„ì°¨ì´ ì•Œë ¤ì¤˜', '8ì¼ì „ ì„¤ì •ì˜¨ë„ëŠ”?', '1ì¸µ í‰ê·  ì‹¤ë‚´ì˜¨ë„ ì•Œë ¤ì¤˜', 'ì´ë²ˆë‹¬ ì¤‘ ìš°ë¦¬ë°˜ ì˜¨ë„ê°€ ê°€ì¥ ëœ ë”ìš´ë‚ ì´ ì–¸ì œì•¼?', 'ì‘ë…„ ì˜†ë°˜ ê°€ì¥ ë”ì› ë˜ ë‹¬ì€?', '2ì£¼ì „ ìš°ë¦¬ë°˜ê³¼ ì˜†ë°˜ í•©ì³ì„œ ì„¤ì •ì˜¨ë„ê°€ ê°€ì¥ ë‚®ì€ë‚ ì´ ì–¸ì œì•¼?', 'ì§€ë‚œë‹¬ ì„¤ì •ì˜¨ë„ í‰ê· ì„ ì•Œë ¤ì¤˜.', 'ì˜¬í•´ ë´„ ì˜†ë°˜ ì œì¼ ì¶”ì› ë˜ ë‚  ì•Œë ¤ì¤˜', '10ë…„ ì „ ì˜¤ëŠ˜ ìš°ë¦¬ë°˜ ì˜¨ë„ëŠ”?'], 'Scenarios': ['scenario1', 'scenario1', 'scenario1', 'scenario1', 'scenario1', 'scenario1', 'scenario1', 'scenario1', 'scenario1', 'scenario1', 'scenario1', 'scenario1', 'scenario1', 'scenario1', 'scenario1', 'scenario1', 'scenario1', 'scenario1', 'scenario1', 'scenario1', 'scenario1', 'scenario1', 'scenario1', 'scenario1', 'scenario1', 'scenario1', 'scenario1'], 'Response': ['{\"Thinking\": \"ì‚¬ìš©ìëŠ” í˜„ì¬ ìš°ë¦¬ë°˜ì˜ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ì„ ì•Œê³ ì‹¶ì–´í•¨. í˜„ì¬ ìš°ë¦¬ë°˜ì˜ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ì„ ì¿¼ë¦¬í•œ í›„ ë°˜í™˜í•˜ë©´ ë¨.\", \"Expectations\": [\"í˜„ì¬ ìš°ë¦¬ë°˜ì˜ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ì€ {{í˜„ì¬_ìš°ë¦¬ë°˜_ì—ë„ˆì§€_ì‚¬ìš©ëŸ‰}}kWhì…ë‹ˆë‹¤.\"], \"Mapping\": {\"temporal\": {\"í˜„ì¬\": \"LAST_RECORD\"}, \"spatials\": {\"ìš°ë¦¬ë°˜\": \"01_IB5\"}, \"modalities\": {\"ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰\": \"Unknown\"}}}', '{\"Thinking\": \"ì‚¬ìš©ìëŠ” ì´ë²ˆë‹¬ ë’·ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ê°€ ê°€ì¥ ë”ìš´ë‚ ì´ ì–¸ì œì¸ì§€ ë¬¼ì–´ë´„. ì´ë²ˆë‹¬ ë’·ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ë¥¼ ì¿¼ë¦¬í•œ í›„ ì‹¤ë‚´ì˜¨ë„ê°€ ê°€ì¥ ë†’ì€ ë‚ ì„ ì°¾ì•„ ê·¸ ë‚ ì§œì™€ ì˜¨ë„ë¥¼ ë°˜í™˜í•˜ë©´ ë¨.\", \"Expectations\": [\"ì´ë²ˆë‹¬ ë’·ë°˜ì€ {{ì´ë²ˆë‹¬_ë’·ë°˜_ìµœëŒ€ì‹¤ë‚´ì˜¨ë„_ë‚ ì§œ}}ì— {{ì´ë²ˆë‹¬_ë’·ë°˜_ìµœëŒ€ì‹¤ë‚´ì˜¨ë„}}â„ƒë¡œ ê°€ì¥ ë”ì› ìŠµë‹ˆë‹¤.\"], \"Mapping\": {\"temporal\": {\"ì´ë²ˆë‹¬\": \"[DATE_TRUNC(\\'month\\', DATE \\'CURRENT_DATE\\'), DATE_TRUNC(\\'month\\', DATE \\'CURRENT_DATE\\' + INTERVAL \\'1 month\\'))\"}, \"spatials\": {\"ë’·ë°˜\": \"Unknown\"}, \"modalities\": {\"ì‹¤ë‚´ì˜¨ë„\": \"roomtemp\"}}}', '{\"Thinking\": \"ì‚¬ìš©ìëŠ” í˜„ì¬ ìš°ë¦¬ë°˜ê³¼ ì˜†ë°˜ ì¤‘ ì‹¤ë‚´ì˜¨ë„ê°€ ë” ë‚®ì€ ê³³ì„ ì•Œê³ ì‹¶ì–´í•¨. í˜„ì¬ ìš°ë¦¬ë°˜ê³¼ ì˜†ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ë¥¼ ì¿¼ë¦¬í•œ í›„ ë” ë‚®ì€ ì‹¤ë‚´ì˜¨ë„ë¥¼ ê°€ì§„ ë°©ê³¼ ê·¸ ì˜¨ë„ë¥¼ ë°˜í™˜í•˜ë©´ ë¨.\", \"Expectations\": [\"{{í˜„ì¬_ì‹¤ë‚´ì˜¨ë„_ë‚®ì€_ê³µê°„}}({{í˜„ì¬_ì‹¤ë‚´ì˜¨ë„_ë‚®ì€_ê³µê°„_ì‹¤ë‚´ì˜¨ë„}}â„ƒ)ì´ {{í˜„ì¬_ì‹¤ë‚´ì˜¨ë„_ë†’ì€_ê³µê°„}}({{í˜„ì¬_ì‹¤ë‚´ì˜¨ë„_ë†’ì€_ê³µê°„_ì‹¤ë‚´ì˜¨ë„}}â„ƒ)ë³´ë‹¤ {{í˜„ì¬_ì‹¤ë‚´ì˜¨ë„_ì°¨ì´}}â„ƒ ë” ë‚®ì•„ìš”.\"], \"Mapping\": {\"temporal\": {\"í˜„ì¬\": \"LAST_RECORD\"}, \"spatials\": {\"ìš°ë¦¬ë°˜\": \"01_IB5\", \"ì˜†ë°˜\": \"01_IB7\"}, \"modalities\": {\"ì‹¤ë‚´ì˜¨ë„\": \"roomtemp\"}}, \"Script\": [\"v_í˜„ì¬_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_df = data(t=\\'í˜„ì¬\\',s=\\'ìš°ë¦¬ë°˜\\',m=\\'ì‹¤ë‚´ì˜¨ë„\\')\", \"v_í˜„ì¬_ì˜†ë°˜_ì‹¤ë‚´ì˜¨ë„_df = data(t=\\'í˜„ì¬\\',s=\\'ì˜†ë°˜\\',m=\\'ì‹¤ë‚´ì˜¨ë„\\')\", \"v_í˜„ì¬_ì‹¤ë‚´ì˜¨ë„ = {\\'ìš°ë¦¬ë°˜\\': v_í˜„ì¬_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_df[\\'ì‹¤ë‚´ì˜¨ë„\\'].values[0], \\'ì˜†ë°˜\\': v_í˜„ì¬_ì˜†ë°˜_ì‹¤ë‚´ì˜¨ë„_df[\\'ì‹¤ë‚´ì˜¨ë„\\'].values[0]}\", \"v_í˜„ì¬_ì‹¤ë‚´ì˜¨ë„_ë‚®ì€_ê³µê°„, v_í˜„ì¬_ì‹¤ë‚´ì˜¨ë„_ë†’ì€_ê³µê°„ = (\\'ìš°ë¦¬ë°˜\\', \\'ì˜†ë°˜\\') if v_í˜„ì¬_ì‹¤ë‚´ì˜¨ë„[\\'ìš°ë¦¬ë°˜\\'] < v_í˜„ì¬_ì‹¤ë‚´ì˜¨ë„[\\'ì˜†ë°˜\\'] else (\\'ì˜†ë°˜\\', \\'ìš°ë¦¬ë°˜\\')\", \"v_í˜„ì¬_ì‹¤ë‚´ì˜¨ë„_ì°¨ì´ = abs(v_í˜„ì¬_ì‹¤ë‚´ì˜¨ë„[v_í˜„ì¬_ì‹¤ë‚´ì˜¨ë„_ë‚®ì€_ê³µê°„] - v_í˜„ì¬_ì‹¤ë‚´ì˜¨ë„[v_í˜„ì¬_ì‹¤ë‚´ì˜¨ë„_ë†’ì€_ê³µê°„])\", \"v_í˜„ì¬_ì‹¤ë‚´ì˜¨ë„_ë‚®ì€_ê³µê°„_ì‹¤ë‚´ì˜¨ë„ = v_í˜„ì¬_ì‹¤ë‚´ì˜¨ë„[v_í˜„ì¬_ì‹¤ë‚´ì˜¨ë„_ë‚®ì€_ê³µê°„]\", \"v_í˜„ì¬_ì‹¤ë‚´ì˜¨ë„_ë†’ì€_ê³µê°„_ì‹¤ë‚´ì˜¨ë„ = v_í˜„ì¬_ì‹¤ë‚´ì˜¨ë„[v_í˜„ì¬_ì‹¤ë‚´ì˜¨ë„_ë†’ì€_ê³µê°„]\"]}', '{\"Thinking\": \"ì‚¬ìš©ìëŠ” 4ì›” í•œë‹¬ê°„ ì•ë°˜ì˜ í‰ê·  ì‹¤ë‚´ì˜¨ë„ë¥¼ ì•Œê³  ì‹¶ì–´í•¨. 4ì›” í•œë‹¬ê°„ ì•ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ë¥¼ ì¿¼ë¦¬í•œ í›„ í‰ê· ê°’ì„ ê³„ì‚°í•˜ì—¬ ë°˜í™˜í•˜ë©´ ë¨.\", \"Expectations\": [\"4ì›” ì•ë°˜ì˜ í‰ê·  ì˜¨ë„ëŠ” {{4ì›”_ì•ë°˜_í‰ê· _ì‹¤ë‚´ì˜¨ë„}}â„ƒ ì…ë‹ˆë‹¤.\"], \"Mapping\": {\"temporal\": {\"4ì›”\": \"[DATE \\'CURRENT_YEAR-04-01\\', DATE \\'CURRENT_YEAR-05-01\\')\"}, \"spatials\": {\"ì•ë°˜\": \"02_I81\"}, \"modalities\": {\"ì‹¤ë‚´ì˜¨ë„\": \"roomtemp\"}}, \"Script\": [\"v_4ì›”_ì•ë°˜_ì‹¤ë‚´ì˜¨ë„_df = data(t=\\'4ì›”\\',s=\\'ì•ë°˜\\',m=\\'ì‹¤ë‚´ì˜¨ë„\\')\", \"v_4ì›”_ì•ë°˜_í‰ê· _ì‹¤ë‚´ì˜¨ë„ = v_4ì›”_ì•ë°˜_ì‹¤ë‚´ì˜¨ë„_df[\\'ì‹¤ë‚´ì˜¨ë„\\'].mean()\"]}', '{\"Thinking\": \"ì‚¬ìš©ìëŠ” ì´ë²ˆë‹¬ ìš°ë¦¬ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ê°’ì´ ìµœì†Œì¸ ë‚ ì§œì„ ì•Œê³ ì‹¶ì–´í•¨. ì´ë²ˆë‹¬ ìš°ë¦¬ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ ë°ì´í„°ë¥¼ ì¿¼ë¦¬í•œ í›„ ìµœì†Œ ì‹¤ë‚´ì˜¨ë„ë¥¼ ê°€ì§„ ë‚ ê³¼ ê·¸ ì˜¨ë„ë¥¼ ë°˜í™˜í•˜ë©´ ë¨.\", \"Expectations\": [\"ì´ë²ˆë‹¬ ìš°ë¦¬ë°˜ì€ {{ì´ë²ˆë‹¬_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_ìµœì†Œ_ë‚ ì§œ}}ì— ì‹¤ë‚´ì˜¨ë„ {{ì´ë²ˆë‹¬_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_ìµœì†Œ_ì˜¨ë„}}â„ƒë¡œ ê°€ì¥ ì¶”ì› ìŠµë‹ˆë‹¤.\"], \"Mapping\": {\"temporal\": {\"ì´ë²ˆë‹¬\": \"[DATE_TRUNC(\\'month\\', DATE \\'CURRENT_DATE\\'), DATE_TRUNC(\\'month\\', DATE \\'CURRENT_DATE\\' + INTERVAL \\'1 month\\'))\"}, \"spatials\": {\"ìš°ë¦¬ë°˜\": \"01_IB5\"}, \"modalities\": {\"ì‹¤ë‚´ì˜¨ë„\": \"roomtemp\"}}, \"Script\": [\"v_ì´ë²ˆë‹¬_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_df = data(t=\\'ì´ë²ˆë‹¬\\',s=\\'ìš°ë¦¬ë°˜\\',m=\\'ì‹¤ë‚´ì˜¨ë„\\')\", \"v_ì´ë²ˆë‹¬_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_ìµœì†Œ_ì˜¨ë„ = v_ì´ë²ˆë‹¬_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_df[\\'ì‹¤ë‚´ì˜¨ë„\\'].min()\", \"v_ì´ë²ˆë‹¬_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_ìµœì†Œ_df = v_ì´ë²ˆë‹¬_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_df[v_ì´ë²ˆë‹¬_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_df[\\'ì‹¤ë‚´ì˜¨ë„\\'] == v_ì´ë²ˆë‹¬_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_ìµœì†Œ_ì˜¨ë„]\", \"v_ì´ë²ˆë‹¬_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_ìµœì†Œ_ë‚ ì§œ = get_time(v_ì´ë²ˆë‹¬_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_ìµœì†Œ_df, fmt=\\'date\\')\"]}', '{\"Thinking\": \"ì‚¬ìš©ìëŠ” ì˜†ë°˜ì˜ í˜„ì¬ ì‹¤ë‚´ì˜¨ë„ì™€ ì„¤ì •ì˜¨ë„ë¥¼ ì•Œê³  ì‹¶ì–´í•¨. í˜„ì¬ ì‹¤ë‚´ì˜¨ë„ì™€ ì„¤ì •ì˜¨ë„ë¥¼ ì¿¼ë¦¬í•œ í›„ ë°˜í™˜í•˜ë©´ ë¨.\", \"Expectations\": [\"ì˜†ë°˜ì˜ í˜„ì¬ ì‹¤ë‚´ì˜¨ë„ëŠ” {{í˜„ì¬_ì˜†ë°˜_ì‹¤ë‚´ì˜¨ë„}}â„ƒì´ê³ , ì„¤ì •ì˜¨ë„ëŠ” {{í˜„ì¬_ì˜†ë°˜_ì„¤ì •ì˜¨ë„}}â„ƒì…ë‹ˆë‹¤.\"], \"Mapping\": {\"temporal\": {\"í˜„ì¬\": \"LAST_RECORD\"}, \"spatials\": {\"ì˜†ë°˜\": \"01_IB7\"}, \"modalities\": {\"ì‹¤ë‚´ì˜¨ë„\": \"roomtemp\", \"ì„¤ì •ì˜¨ë„\": \"settemp\"}}, \"Script\": [\"v_í˜„ì¬_ì˜†ë°˜_df = data(t=\\'í˜„ì¬\\',s=\\'ì˜†ë°˜\\',m=[\\'ì‹¤ë‚´ì˜¨ë„\\', \\'ì„¤ì •ì˜¨ë„\\'])\", \"v_í˜„ì¬_ì˜†ë°˜_ì‹¤ë‚´ì˜¨ë„ = v_í˜„ì¬_ì˜†ë°˜_df[\\'ì‹¤ë‚´ì˜¨ë„\\'].values[0]\", \"v_í˜„ì¬_ì˜†ë°˜_ì„¤ì •ì˜¨ë„ = v_í˜„ì¬_ì˜†ë°˜_df[\\'ì„¤ì •ì˜¨ë„\\'].values[0]\"]}', '{\"Thinking\": \"ì‚¬ìš©ìëŠ” ì´ë²ˆì£¼ ìš°ë¦¬ë°˜ì˜ í‰ê·  ì‹¤ë‚´ì˜¨ë„ë¥¼ ì•Œê³ ì‹¶ì–´í•¨. ì´ë²ˆì£¼ ìš°ë¦¬ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ ë°ì´í„°ë¥¼ ì¿¼ë¦¬í•œ í›„ í‰ê· ê°’ì„ ê³„ì‚°í•˜ì—¬ ë°˜í™˜í•˜ë©´ ë¨.\", \"Expectations\": [\"ì´ë²ˆì£¼ ìš°ë¦¬ë°˜ì˜ í‰ê·  ì‹¤ë‚´ì˜¨ë„ëŠ” {{ì´ë²ˆì£¼_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_í‰ê· }}â„ƒ ì…ë‹ˆë‹¤.\"], \"Mapping\": {\"temporal\": {\"ì´ë²ˆì£¼\": \"[DATE_TRUNC(\\'week\\', DATE \\'CURRENT_DATE\\'), DATE_TRUNC(\\'week\\', DATE \\'CURRENT_DATE\\' + INTERVAL \\'1 week\\'))\"}, \"spatials\": {\"ìš°ë¦¬ë°˜\": \"01_IB5\"}, \"modalities\": {\"ì‹¤ë‚´ì˜¨ë„\": \"roomtemp\"}}, \"Script\": [\"v_ì´ë²ˆì£¼_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_df = data(t=\\'ì´ë²ˆì£¼\\',s=\\'ìš°ë¦¬ë°˜\\',m=\\'ì‹¤ë‚´ì˜¨ë„\\')\", \"v_ì´ë²ˆì£¼_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_í‰ê·  = v_ì´ë²ˆì£¼_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_df[\\'ì‹¤ë‚´ì˜¨ë„\\'].mean()\"]}', '{\"Thinking\": \"ì‚¬ìš©ìëŠ” ì§€ë‚œë‹¬ ì˜¤ëŠ˜ ì˜¤í›„ 2ì‹œì— ì˜†ë°˜ì˜ ì„¤ì •ì˜¨ë„ë¥¼ ì•Œê³  ì‹¶ì–´í•©ë‹ˆë‹¤. í•´ë‹¹ ì‹œê°„ëŒ€ì˜ ì„¤ì •ì˜¨ë„ ë°ì´í„°ë¥¼ ì¿¼ë¦¬í•œ í›„ ë°˜í™˜í•˜ë©´ ë©ë‹ˆë‹¤.\", \"Expectations\": [\"ì§€ë‚œë‹¬ ì˜¤ëŠ˜ ì˜¤í›„ 2ì‹œ ì˜†ë°˜ì˜ ì„¤ì •ì˜¨ë„ëŠ” {{ì§€ë‚œë‹¬ì˜¤ëŠ˜ì˜¤í›„2ì‹œ_ì˜†ë°˜_ì„¤ì •ì˜¨ë„}}â„ƒì˜€ìŠµë‹ˆë‹¤.\"], \"Mapping\": {\"temporal\": {\"ì§€ë‚œë‹¬ì˜¤ëŠ˜ì˜¤í›„2ì‹œ\": \"DATE_TRUNC(\\'day\\', DATE \\'CURRENT_DATE\\' - INTERVAL \\'1 month\\') + INTERVAL \\'14 hours\\'\"}, \"spatials\": {\"ì˜†ë°˜\": \"01_IB7\"}, \"modalities\": {\"ì„¤ì •ì˜¨ë„\": \"settemp\"}}, \"Script\": [\"v_ì§€ë‚œë‹¬ì˜¤ëŠ˜ì˜¤í›„2ì‹œ_ì˜†ë°˜_ì„¤ì •ì˜¨ë„_df = data(t=\\'ì§€ë‚œë‹¬ì˜¤ëŠ˜ì˜¤í›„2ì‹œ\\',s=\\'ì˜†ë°˜\\',m=\\'ì„¤ì •ì˜¨ë„\\')\", \"v_ì§€ë‚œë‹¬ì˜¤ëŠ˜ì˜¤í›„2ì‹œ_ì˜†ë°˜_ì„¤ì •ì˜¨ë„ = v_ì§€ë‚œë‹¬ì˜¤ëŠ˜ì˜¤í›„2ì‹œ_ì˜†ë°˜_ì„¤ì •ì˜¨ë„_df[\\'ì„¤ì •ì˜¨ë„\\']\"]}', '{\"Thinking\": \"ì‚¬ìš©ìëŠ” ì˜¬í•´ 6ì›” ~ 8ì›” ì•ë°˜ì˜ í‰ê·  ì‹¤ë‚´ì˜¨ë„ë¥¼ ì•Œê³  ì‹¶ì–´í•¨. ì˜¬í•´ ì—¬ë¦„(6ì›” ~ 8ì›”) ì•ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ë¥¼ ì¿¼ë¦¬í•œ í›„ í‰ê· ê°’ì„ ê³„ì‚°í•˜ì—¬ ë°˜í™˜í•˜ë©´ ë¨.\", \"Expectations\": [\"ì˜¬í•´ ì—¬ë¦„(6ì›” ~ 8ì›”) ì•ë°˜ì˜ í‰ê·  ì˜¨ë„ëŠ” {{ì˜¬í•´ì—¬ë¦„_ì•ë°˜_ì‹¤ë‚´ì˜¨ë„_í‰ê· }}â„ƒ ì…ë‹ˆë‹¤.\"], \"Mapping\": {\"temporal\": {\"ì˜¬í•´ì—¬ë¦„\": \"[DATE \\'CURRENT_YEAR-06-01\\', DATE \\'CURRENT_YEAR-09-01\\')\"}, \"spatials\": {\"ì•ë°˜\": \"02_I81\"}, \"modalities\": {\"ì‹¤ë‚´ì˜¨ë„\": \"roomtemp\"}}, \"Script\": [\"v_ì˜¬í•´ì—¬ë¦„_ì•ë°˜_ì‹¤ë‚´ì˜¨ë„_df = data(t=\\'ì˜¬í•´ì—¬ë¦„\\',s=\\'ì•ë°˜\\',m=\\'ì‹¤ë‚´ì˜¨ë„\\')\", \"v_ì˜¬í•´ì—¬ë¦„_ì•ë°˜_ì‹¤ë‚´ì˜¨ë„_í‰ê·  = v_ì˜¬í•´ì—¬ë¦„_ì•ë°˜_ì‹¤ë‚´ì˜¨ë„_df[\\'ì‹¤ë‚´ì˜¨ë„\\'].mean()\"]}', '{\"Thinking\": \"ì‚¬ìš©ìëŠ” ì˜¤ëŠ˜ ì˜¤í›„ 4ì‹œë¶€í„° 6ì‹œê¹Œì§€ì˜ ì‹œê°„ ë™ì•ˆ ìš°ë¦¬ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ í‰ê· ì„ ì•Œê³ ì‹¶ì–´í•¨. í•´ë‹¹ ì‹œê°„ ë²”ìœ„ì˜ ì‹¤ë‚´ì˜¨ë„ ë°ì´í„°ë¥¼ ì¿¼ë¦¬í•œ í›„ í‰ê· ê°’ì„ ê³„ì‚°í•˜ë©´ ë¨.\", \"Expectations\": [\"ì˜¤ëŠ˜ ì˜¤í›„ 4ì‹œë¶€í„° 6ì‹œê¹Œì§€ ìš°ë¦¬ë°˜ì˜ í‰ê·  ì‹¤ë‚´ì˜¨ë„ëŠ” {{ì˜¤í›„4ì‹œë¶€í„°6ì‹œ_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_í‰ê· }}â„ƒì˜€ìŠµë‹ˆë‹¤.\"], \"Mapping\": {\"temporal\": {\"ì˜¤í›„4ì‹œë¶€í„°6ì‹œ\": \"[DATE_TRUNC(\\'day\\', DATE \\'CURRENT_DATE\\') + INTERVAL \\'16 hours\\', DATE_TRUNC(\\'day\\', DATE \\'CURRENT_DATE\\') + INTERVAL \\'18 hours\\')\"}, \"spatials\": {\"ìš°ë¦¬ë°˜\": \"01_IB5\"}, \"modalities\": {\"ì‹¤ë‚´ì˜¨ë„\": \"roomtemp\"}}, \"Script\": [\"v_ì˜¤í›„4ì‹œë¶€í„°6ì‹œ_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_df = data(t=\\'ì˜¤í›„4ì‹œë¶€í„°6ì‹œ\\',s=\\'ìš°ë¦¬ë°˜\\',m=\\'ì‹¤ë‚´ì˜¨ë„\\')\", \"v_ì˜¤í›„4ì‹œë¶€í„°6ì‹œ_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_í‰ê·  = v_ì˜¤í›„4ì‹œë¶€í„°6ì‹œ_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_df[\\'ì‹¤ë‚´ì˜¨ë„\\'].mean()\"]}', '{\"Thinking\": \"ì‚¬ìš©ìëŠ” ìš°ë¦¬ë°˜ì˜ í˜„ì¬ ì„¤ì •ì˜¨ë„ë¥¼ ì•Œê³  ì‹¶ì–´í•¨. í˜„ì¬ ìš°ë¦¬ë°˜ì˜ ì„¤ì •ì˜¨ë„ë¥¼ ì¿¼ë¦¬í•œ í›„ ë°˜í™˜í•˜ë©´ ë¨.\", \"Expectations\": [\"ìš°ë¦¬ë°˜ì˜ í˜„ì¬ ì„¤ì •ì˜¨ë„ëŠ” {{í˜„ì¬_ìš°ë¦¬ë°˜_ì„¤ì •ì˜¨ë„}}â„ƒì…ë‹ˆë‹¤.\"], \"Mapping\": {\"temporal\": {\"í˜„ì¬\": \"LAST_RECORD\"}, \"spatials\": {\"ìš°ë¦¬ë°˜\": \"01_IB5\"}, \"modalities\": {\"ì„¤ì •ì˜¨ë„\": \"settemp\"}}, \"Script\": [\"v_í˜„ì¬_ìš°ë¦¬ë°˜_ì„¤ì •ì˜¨ë„_df = data(t=\\'í˜„ì¬\\',s=\\'ìš°ë¦¬ë°˜\\',m=\\'ì„¤ì •ì˜¨ë„\\')\", \"v_í˜„ì¬_ìš°ë¦¬ë°˜_ì„¤ì •ì˜¨ë„ = v_í˜„ì¬_ìš°ë¦¬ë°˜_ì„¤ì •ì˜¨ë„_df[\\'ì„¤ì •ì˜¨ë„\\'].values[0]\"]}', '{\"Thinking\": \"ì‚¬ìš©ìëŠ” ìš°ë¦¬ë°˜ì˜ 1ë…„ ì „ 12ì›” ~ ì˜¬í•´ 2ì›”ì˜ í‰ê·  ì‹¤ë‚´ì˜¨ë„ë¥¼ ì•Œê³  ì‹¶ì–´í•¨. ìš°ë¦¬ë°˜ì˜ 1ë…„ ì „ ê²¨ìš¸(12ì›” ~ 2ì›”) ì‹¤ë‚´ì˜¨ë„ë¥¼ ì¿¼ë¦¬í•œ í›„ í‰ê· ê°’ì„ ê³„ì‚°í•˜ì—¬ ë°˜í™˜í•˜ë©´ ë¨.\", \"Expectations\": [\"ì‘ë…„ ê²¨ìš¸(2021-12 ~ 2022-02) ìš°ë¦¬ë°˜ì˜ í‰ê·  ì˜¨ë„ëŠ” {{ì‘ë…„ê²¨ìš¸_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_í‰ê· }}â„ƒ ì…ë‹ˆë‹¤.\"], \"Mapping\": {\"temporal\": {\"ì‘ë…„ê²¨ìš¸\": \"[DATE \\'CURRENT_YEAR-12-01\\' - INTERVAL \\'1 year\\', DATE \\'CURRENT_YEAR-03-01\\')\"}, \"spatials\": {\"ìš°ë¦¬ë°˜\": \"01_IB5\"}, \"modalities\": {\"ì‹¤ë‚´ì˜¨ë„\": \"roomtemp\"}}, \"Script\": [\"v_ì‘ë…„ê²¨ìš¸_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_df = data(t=\\'ì‘ë…„ê²¨ìš¸\\',s=\\'ìš°ë¦¬ë°˜\\',m=\\'ì‹¤ë‚´ì˜¨ë„\\')\", \"v_ì‘ë…„ê²¨ìš¸_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_í‰ê·  = v_ì‘ë…„ê²¨ìš¸_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_df[\\'ì‹¤ë‚´ì˜¨ë„\\'].mean()\"]}', '{\"Thinking\": \"ì‚¬ìš©ìëŠ” í˜„ì¬ 4ì¸µì˜ ê³µê°„ ìµœëŒ€ ì„¤ì •ì˜¨ë„ë¥¼ ì•Œê³  ì‹¶ì–´í•¨. í˜„ì¬ 4ì¸µì— ì†í•œ ëª¨ë“  ê³µê°„ì˜ ì„¤ì •ì˜¨ë„ì˜ ìµœëŒ€ê°’ì„ ë°˜í™˜í•˜ë©´ ë¨.\", \"Expectations\": [\"ì§€ê¸ˆ 4ì¸µì˜ ìµœëŒ€ ì„¤ì •ì˜¨ë„ëŠ” {{í˜„ì¬_4ì¸µ_ì„¤ì •ì˜¨ë„_ìµœëŒ€}}â„ƒì…ë‹ˆë‹¤.\"], \"Mapping\": {\"temporal\": {\"í˜„ì¬\": \"LAST_RECORD\"}, \"spatials\": {\"4ì¸µ\": [\"01_IB5\", \"01_IB7\", \"02_I81\"]}, \"modalities\": {\"ì„¤ì •ì˜¨ë„\": \"settemp\"}}, \"Script\": [\"v_í˜„ì¬_4ì¸µ_ì„¤ì •ì˜¨ë„_df = data(t=\\'í˜„ì¬\\',s=\\'4ì¸µ\\',m=\\'ì„¤ì •ì˜¨ë„\\')\", \"v_í˜„ì¬_4ì¸µ_ì„¤ì •ì˜¨ë„_ìµœëŒ€ = v_í˜„ì¬_4ì¸µ_ì„¤ì •ì˜¨ë„_df[\\'ì„¤ì •ì˜¨ë„\\'].max()\"]}', '{\"Thinking\": \"ì–´ì œ ìš°ë¦¬ë°˜ê³¼ ì˜†ë°˜ì˜ ì„¤ì •ì˜¨ë„ë¥¼ ì¿¼ë¦¬í•œ í›„ ê° ë°˜ì˜ í‰ê·  ì„¤ì •ì˜¨ë„ ë° ê·¸ ì°¨ì´ë¥¼ ê³„ì‚°í•˜ì—¬ ë°˜í™˜í•˜ë©´ ë¨.\", \"Expectations\": [\"ì–´ì œ ìš°ë¦¬ë°˜ì˜ ì„¤ì •ì˜¨ë„({{ì–´ì œ_ìš°ë¦¬ë°˜_ì„¤ì •ì˜¨ë„_í‰ê· }}â„ƒ)ëŠ” ì˜†ë°˜ì˜ ì„¤ì •ì˜¨ë„({{ì–´ì œ_ì˜†ë°˜_ì„¤ì •ì˜¨ë„_í‰ê· }}â„ƒ)ë³´ë‹¤ {{ì–´ì œ_ì„¤ì •ì˜¨ë„_í‰ê· ì˜_ì°¨ì´}}â„ƒ ë†’ìŠµë‹ˆë‹¤.\"], \"Mapping\": {\"temporal\": {\"ì–´ì œ\": \"[DATE_TRUNC(\\'day\\', DATE \\'CURRENT_DATE\\' - INTERVAL \\'1 day\\'), DATE_TRUNC(\\'day\\', DATE \\'CURRENT_DATE\\'))\"}, \"spatials\": {\"ìš°ë¦¬ë°˜\": \"01_IB5\", \"ì˜†ë°˜\": \"01_IB7\"}, \"modalities\": {\"ì„¤ì •ì˜¨ë„\": \"settemp\"}}, \"Script\": [\"v_ì–´ì œ_ìš°ë¦¬ë°˜_ì„¤ì •ì˜¨ë„_df = data(t=\\'ì–´ì œ\\',s=\\'ìš°ë¦¬ë°˜\\',m=\\'ì„¤ì •ì˜¨ë„\\')\", \"v_ì–´ì œ_ì˜†ë°˜_ì„¤ì •ì˜¨ë„_df = data(t=\\'ì–´ì œ\\',s=\\'ì˜†ë°˜\\',m=\\'ì„¤ì •ì˜¨ë„\\')\", \"v_ì–´ì œ_ìš°ë¦¬ë°˜_ì„¤ì •ì˜¨ë„_í‰ê·  = v_ì–´ì œ_ìš°ë¦¬ë°˜_ì„¤ì •ì˜¨ë„_df[\\'ì„¤ì •ì˜¨ë„\\'].mean()\", \"v_ì–´ì œ_ì˜†ë°˜_ì„¤ì •ì˜¨ë„_í‰ê·  = v_ì–´ì œ_ì˜†ë°˜_ì„¤ì •ì˜¨ë„_df[\\'ì„¤ì •ì˜¨ë„\\'].mean()\", \"v_ì–´ì œ_ì„¤ì •ì˜¨ë„_í‰ê· ì˜_ì°¨ì´ = v_ì–´ì œ_ìš°ë¦¬ë°˜_ì„¤ì •ì˜¨ë„_í‰ê·  - v_ì–´ì œ_ì˜†ë°˜_ì„¤ì •ì˜¨ë„_í‰ê· \"]}', '{\"Thinking\": \"ì‚¬ìš©ìëŠ” ì§€ë‚œì£¼ ìš°ë¦¬ë°˜ ì„¤ì •ì˜¨ë„ì™€ ì‹¤ë‚´ì˜¨ë„ ì°¨ì´ê°€ ê°€ì¥ ì»¸ë˜ ë‚ ì§œë¥¼ ì•Œê³  ì‹¶ì–´í•¨. ì§€ë‚œì£¼ ìš°ë¦¬ë°˜ì˜ ì„¤ì •ì˜¨ë„ì™€ ì‹¤ë‚´ì˜¨ë„ ë°ì´í„°ë¥¼ ì¿¼ë¦¬í•œ í›„ ì°¨ì´ë¥¼ ê³„ì‚°í•˜ë©´ ë¨.\", \"Expectations\": [\"ì§€ë‚œì£¼ {{ì§€ë‚œì£¼_ìš°ë¦¬ë°˜_ì˜¨ë„ì°¨ì´_ìµœê³ _ë‚ ì§œ}}ì— ì„¤ì •ì˜¨ë„({{ì§€ë‚œì£¼_ìš°ë¦¬ë°˜_ì˜¨ë„ì°¨ì´_ìµœê³ _ì„¤ì •ì˜¨ë„}}â„ƒ)ì™€ ì‹¤ë‚´ì˜¨ë„({{ì§€ë‚œì£¼_ìš°ë¦¬ë°˜_ì˜¨ë„ì°¨ì´_ìµœê³ _ì‹¤ë‚´ì˜¨ë„}}â„ƒ) ì°¨ì´ê°€ {{ì§€ë‚œì£¼_ìš°ë¦¬ë°˜_ì˜¨ë„ì°¨ì´_ìµœê³ }}â„ƒë¡œ ê°€ì¥ ì»¸ìŠµë‹ˆë‹¤.\"], \"Mapping\": {\"temporal\": {\"ì§€ë‚œì£¼\": \"[DATE_TRUNC(\\'week\\', DATE \\'CURRENT_DATE\\') - INTERVAL \\'1 week\\', DATE_TRUNC(\\'week\\', DATE \\'CURRENT_DATE\\'))\"}, \"spatials\": {\"ìš°ë¦¬ë°˜\": \"01_IB5\"}, \"modalities\": {\"ì„¤ì •ì˜¨ë„\": \"settemp\", \"ì‹¤ë‚´ì˜¨ë„\": \"roomtemp\"}}, \"Script\": [\"v_ì§€ë‚œì£¼_ìš°ë¦¬ë°˜_df = data(t=\\'ì§€ë‚œì£¼\\',s=\\'ìš°ë¦¬ë°˜\\',m=[\\'ì„¤ì •ì˜¨ë„\\',\\'ì‹¤ë‚´ì˜¨ë„\\'])\", \"v_ì§€ë‚œì£¼_ìš°ë¦¬ë°˜_df[\\'ì˜¨ë„ì°¨ì´\\'] = v_ì§€ë‚œì£¼_ìš°ë¦¬ë°˜_df[\\'ì„¤ì •ì˜¨ë„\\'] - v_ì§€ë‚œì£¼_ìš°ë¦¬ë°˜_df[\\'ì‹¤ë‚´ì˜¨ë„\\']\", \"v_ì§€ë‚œì£¼_ìš°ë¦¬ë°˜_ì˜¨ë„ì°¨ì´_ìµœê³  = v_ì§€ë‚œì£¼_ìš°ë¦¬ë°˜_df[\\'ì˜¨ë„ì°¨ì´\\'].max()\", \"v_ì§€ë‚œì£¼_ìš°ë¦¬ë°˜_ì˜¨ë„ì°¨ì´_ìµœê³ _df = v_ì§€ë‚œì£¼_ìš°ë¦¬ë°˜_df[v_ì§€ë‚œì£¼_ìš°ë¦¬ë°˜_df[\\'ì˜¨ë„ì°¨ì´\\'] == v_ì§€ë‚œì£¼_ìš°ë¦¬ë°˜_ì˜¨ë„ì°¨ì´_ìµœê³ ]\", \"v_ì§€ë‚œì£¼_ìš°ë¦¬ë°˜_ì˜¨ë„ì°¨ì´_ìµœê³ _ë‚ ì§œ = get_time(v_ì§€ë‚œì£¼_ìš°ë¦¬ë°˜_ì˜¨ë„ì°¨ì´_ìµœê³ _df, fmt=\\'date\\')\", \"v_ì§€ë‚œì£¼_ìš°ë¦¬ë°˜_ì˜¨ë„ì°¨ì´_ìµœê³ _ì„¤ì •ì˜¨ë„ = v_ì§€ë‚œì£¼_ìš°ë¦¬ë°˜_ì˜¨ë„ì°¨ì´_ìµœê³ _df[\\'ì„¤ì •ì˜¨ë„\\'].values[0]\", \"v_ì§€ë‚œì£¼_ìš°ë¦¬ë°˜_ì˜¨ë„ì°¨ì´_ìµœê³ _ì‹¤ë‚´ì˜¨ë„ = v_ì§€ë‚œì£¼_ìš°ë¦¬ë°˜_ì˜¨ë„ì°¨ì´_ìµœê³ _df[\\'ì‹¤ë‚´ì˜¨ë„\\'].values[0]\"]}', '{\"Thinking\": \"ì‚¬ìš©ìëŠ” ì˜¤ëŠ˜ ì˜¤ì „ 11ì‹œì— ì˜†ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ë¥¼ ì•Œê³ ì‹¶ì–´í•¨. ì˜¤ì „ 11ì‹œì˜ ì˜†ë°˜ ì‹¤ë‚´ì˜¨ë„ ë°ì´í„°ë¥¼ ì¿¼ë¦¬í•œ í›„ ë°˜í™˜í•˜ë©´ ë¨.\", \"Expectations\": [\"ì˜¤ëŠ˜ ì˜¤ì „ 11ì‹œ ì˜†ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ëŠ” {{ì˜¤ì „11ì‹œ_ì˜†ë°˜_ì‹¤ë‚´ì˜¨ë„}}â„ƒì˜€ìŠµë‹ˆë‹¤.\"], \"Mapping\": {\"temporal\": {\"ì˜¤ëŠ˜ì˜¤ì „11ì‹œ\": \"DATE_TRUNC(\\'day\\', DATE \\'CURRENT_DATE\\') + INTERVAL \\'11 hours\\'\"}, \"spatials\": {\"ì˜†ë°˜\": \"01_IB7\"}, \"modalities\": {\"ì‹¤ë‚´ì˜¨ë„\": \"roomtemp\"}}, \"Script\": [\"v_ì˜¤ì „11ì‹œ_ì˜†ë°˜_ì‹¤ë‚´ì˜¨ë„_df = data(t=\\'ì˜¤ëŠ˜ì˜¤ì „11ì‹œ\\',s=\\'ì˜†ë°˜\\',m=\\'ì‹¤ë‚´ì˜¨ë„\\')\", \"v_ì˜¤ì „11ì‹œ_ì˜†ë°˜_ì‹¤ë‚´ì˜¨ë„ = v_ì˜¤ì „11ì‹œ_ì˜†ë°˜_ì‹¤ë‚´ì˜¨ë„_df[\\'ì‹¤ë‚´ì˜¨ë„\\'].values[0]\"]}', '{\"Thinking\": \"ì‚¬ìš©ìëŠ” í˜„ì¬ ìš°ë¦¬ë°˜, ì˜†ë°˜, ì•ë°˜ ì¤‘ ì‹¤ë‚´ì˜¨ë„ê°€ ìµœì €ì¸ ë°©ì„ ì•Œê³ ì‹¶ì–´í•¨.í˜„ì¬ ì„¸ ë°©ì˜ ì‹¤ë‚´ì˜¨ë„ë¥¼ ì¿¼ë¦¬í•œ í›„ ì‹¤ë‚´ì˜¨ë„ê°€ ìµœì €ì¸ ë°©ê³¼ ê·¸ ì˜¨ë„ë¥¼ ë°˜í™˜í•˜ë©´ ë¨.\", \"Expectations\": [\"í˜„ì¬ ì„¸ ë°© ì¤‘ {{í˜„ì¬_ì‹¤ë‚´ì˜¨ë„_ìµœì €_ë°©}}ì´(ê°€) {{í˜„ì¬_ì‹¤ë‚´ì˜¨ë„_ìµœì €}}â„ƒë¡œ ê°€ì¥ ì¶”ì›Œìš”.\"], \"Mapping\": {\"temporal\": {\"í˜„ì¬\": \"LAST_RECORD\"}, \"spatials\": {\"ìš°ë¦¬ë°˜\": \"01_IB5\", \"ì˜†ë°˜\": \"01_IB7\", \"ì•ë°˜\": \"02_I81\"}, \"modalities\": {\"ì‹¤ë‚´ì˜¨ë„\": \"roomtemp\"}}, \"Script\": [\"v_í˜„ì¬_ë°©ë³„_ì‹¤ë‚´ì˜¨ë„_df = data(t=\\'í˜„ì¬\\',s=[\\'ìš°ë¦¬ë°˜\\',\\'ì˜†ë°˜\\',\\'ì•ë°˜\\'],m=\\'ì‹¤ë‚´ì˜¨ë„\\')\", \"v_í˜„ì¬_ì‹¤ë‚´ì˜¨ë„_ìµœì € = v_í˜„ì¬_ë°©ë³„_ì‹¤ë‚´ì˜¨ë„_df[\\'ì‹¤ë‚´ì˜¨ë„\\'].min()\", \"v_í˜„ì¬_ì‹¤ë‚´ì˜¨ë„_ìµœì €_df = v_í˜„ì¬_ë°©ë³„_ì‹¤ë‚´ì˜¨ë„_df[v_í˜„ì¬_ë°©ë³„_ì‹¤ë‚´ì˜¨ë„_df[\\'ì‹¤ë‚´ì˜¨ë„\\'] == v_í˜„ì¬_ì‹¤ë‚´ì˜¨ë„_ìµœì €]\", \"v_í˜„ì¬_ì‹¤ë‚´ì˜¨ë„_ìµœì €_ë°© = get_spatials(v_í˜„ì¬_ì‹¤ë‚´ì˜¨ë„_ìµœì €_df)\"]}', '{\"Thinking\": \"ì‚¬ìš©ìëŠ” ë¡¯ë°ìºìŠ¬ì˜ í˜„ì¬ ì‹¤ë‚´ì˜¨ë„ë¥¼ ì•Œê³  ì‹¶ì–´í•¨. ë¡¯ë°ìºìŠ¬ì˜ í˜„ì¬ ì‹¤ë‚´ì˜¨ë„ê°’ì„ ë°˜í™˜í•˜ë©´ ë¨.\", \"Expectations\": [\"ë¡¯ë°ìºìŠ¬ì˜ í˜„ì¬ ì‹¤ë‚´ì˜¨ë„ëŠ” {{í˜„ì¬_ë¡¯ë°ìºìŠ¬_ì‹¤ë‚´ì˜¨ë„}}â„ƒì…ë‹ˆë‹¤.\"], \"Mapping\": {\"temporal\": {\"í˜„ì¬\": \"LAST_RECORD\"}, \"spatials\": {\"ë¡¯ë°ìºìŠ¬\": \"Unknown\"}, \"modalities\": {\"ì‹¤ë‚´ì˜¨ë„\": \"roomtemp\"}}}', '{\"Thinking\": \"ì‚¬ìš©ìëŠ” ì˜¤ëŠ˜ í•˜ë£¨ í‰ê·  ìš°ë¦¬ë°˜ê³¼ ì˜†ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ì˜ ì°¨ì´ë¥¼ ì•Œê³  ì‹¶ì–´í•¨. ì‚¬ìš©ìëŠ” ì°¨ì´ ê²°ê³¼ ë¿ë§Œ ì•„ë‹ˆë¼ ê³„ì‚°ì— ì‚¬ìš©ëœ ê° ë°˜ì˜ í‰ê·  ì‹¤ë‚´ì˜¨ë„ ê°’ë„ ê¶ê¸ˆí•  ê²ƒì„. ì˜¤ëŠ˜ í•˜ë£¨ ìš°ë¦¬ë°˜ê³¼ ì˜†ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ë¥¼ ì¿¼ë¦¬í•œ í›„ ê° ë°˜ì˜ í‰ê·  ì‹¤ë‚´ì˜¨ë„ ë° ê·¸ ì°¨ì´ë¥¼ ê³„ì‚°í•˜ì—¬ ë°˜í™˜í•˜ë©´ ë¨.\", \"Expectations\": [\"ìš°ë¦¬ë°˜({{ì˜¤ëŠ˜_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_í‰ê· }}â„ƒ)ì´ ì˜†ë°˜({{ì˜¤ëŠ˜_ì˜†ë°˜_ì‹¤ë‚´ì˜¨ë„_í‰ê· }}â„ƒ)ë³´ë‹¤ {{ì˜¤ëŠ˜_ì‹¤ë‚´ì˜¨ë„_í‰ê· ì˜_ì°¨ì´}}â„ƒ ë†’ìŠµë‹ˆë‹¤.\"], \"Mapping\": {\"temporal\": {\"ì˜¤ëŠ˜\": \"[DATE_TRUNC(\\'day\\', DATE \\'CURRENT_DATE\\'), DATE_TRUNC(\\'day\\', DATE \\'CURRENT_DATE\\' + INTERVAL \\'1 day\\'))\"}, \"spatials\": {\"ìš°ë¦¬ë°˜\": \"01_IB5\", \"ì˜†ë°˜\": \"01_IB7\"}, \"modalities\": {\"ì‹¤ë‚´ì˜¨ë„\": \"roomtemp\"}}, \"Script\": [\"v_ì˜¤ëŠ˜_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_df = data(t=\\'ì˜¤ëŠ˜\\',s=\\'ìš°ë¦¬ë°˜\\',m=\\'ì‹¤ë‚´ì˜¨ë„\\')\", \"v_ì˜¤ëŠ˜_ì˜†ë°˜_ì‹¤ë‚´ì˜¨ë„_df = data(t=\\'ì˜¤ëŠ˜\\',s=\\'ì˜†ë°˜\\',m=\\'ì‹¤ë‚´ì˜¨ë„\\')\", \"v_ì˜¤ëŠ˜_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_í‰ê·  = v_ì˜¤ëŠ˜_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_df[\\'ì‹¤ë‚´ì˜¨ë„\\'].mean()\", \"v_ì˜¤ëŠ˜_ì˜†ë°˜_ì‹¤ë‚´ì˜¨ë„_í‰ê·  = v_ì˜¤ëŠ˜_ì˜†ë°˜_ì‹¤ë‚´ì˜¨ë„_df[\\'ì‹¤ë‚´ì˜¨ë„\\'].mean()\", \"v_ì˜¤ëŠ˜_ì‹¤ë‚´ì˜¨ë„_í‰ê· ì˜_ì°¨ì´ = v_ì˜¤ëŠ˜_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_í‰ê·  - v_ì˜¤ëŠ˜_ì˜†ë°˜_ì‹¤ë‚´ì˜¨ë„_í‰ê· \"]}', '{\"Thinking\": \"ê³µê°„ ì •ë³´ê°€ ì—†ìœ¼ë¯€ë¡œ ìš°ë¦¬ë°˜ìœ¼ë¡œ ì¶”ì¸¡í•¨. ì‚¬ìš©ìëŠ” 8ì¼ ì „ ìš°ë¦¬ë°˜ì˜ ì„¤ì •ì˜¨ë„ë¥¼ ì•Œê³  ì‹¶ì–´í•¨. 8ì¼ ì „ ì„¤ì •ì˜¨ë„ì˜ ì¼í‰ê· ê°’ì„ ë°˜í™˜í•˜ë©´ ë¨.\", \"Expectations\": [\"8ì¼ì „ ìš°ë¦¬ë°˜ì˜ í‰ê·  ì„¤ì •ì˜¨ë„ëŠ” {{8ì¼ì „_ìš°ë¦¬ë°˜_í‰ê· _ì„¤ì •ì˜¨ë„}}â„ƒì˜€ìŠµë‹ˆë‹¤.\"], \"Mapping\": {\"temporal\": {\"8ì¼ì „\": \"[DATE_TRUNC(\\'day\\', DATE \\'CURRENT_DATE\\' - INTERVAL \\'8 day\\'), DATE_TRUNC(\\'day\\', DATE \\'CURRENT_DATE\\' - INTERVAL \\'7 day\\'))\"}, \"spatials\": {\"ìš°ë¦¬ë°˜\": \"01_IB5\"}, \"modalities\": {\"ì„¤ì •ì˜¨ë„\": \"settemp\"}}, \"Script\": [\"v_8ì¼ì „_ìš°ë¦¬ë°˜_ì„¤ì •ì˜¨ë„_df = data(t=\\'8ì¼ì „\\',s=\\'ìš°ë¦¬ë°˜\\',m=\\'ì„¤ì •ì˜¨ë„\\')\", \"v_8ì¼ì „_ìš°ë¦¬ë°˜_í‰ê· _ì„¤ì •ì˜¨ë„ = v_8ì¼ì „_ìš°ë¦¬ë°˜_ì„¤ì •ì˜¨ë„_df[\\'ì„¤ì •ì˜¨ë„\\'].mean()\"]}', '{\"Thinking\": \"ì‚¬ìš©ìëŠ” í˜„ì¬ 1ì¸µì˜ í‰ê·  ì‹¤ë‚´ì˜¨ë„ë¥¼ ì•Œê³ ì‹¶ì–´í•¨. í˜„ì¬ 1ì¸µì˜ ì „ì²´ ê³µê°„ì˜ ì‹¤ë‚´ì˜¨ë„ ë°ì´í„°ë¥¼ ì¿¼ë¦¬í•œ í›„ í‰ê· ê°’ì„ ë°˜í™˜í•˜ë©´ ë¨.\", \"Expectations\": [\"1ì¸µì˜ í‰ê·  ì‹¤ë‚´ì˜¨ë„ëŠ” {{í˜„ì¬_1ì¸µ_ì‹¤ë‚´ì˜¨ë„_í‰ê· }}â„ƒ ì…ë‹ˆë‹¤.\"], \"Mapping\": {\"temporal\": {\"í˜„ì¬\": \"LAST_RECORD\"}, \"spatials\": {\"1ì¸µ\": \"Unknown\"}, \"modalities\": {\"ì‹¤ë‚´ì˜¨ë„\": \"roomtemp\"}}}', '{\"Thinking\": \"ì‚¬ìš©ìëŠ” ì´ë²ˆë‹¬ ìš°ë¦¬ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ê°€ ê°€ì¥ ë‚®ì•˜ë˜ ë‚ ì§œë¥¼ ì•Œê³  ì‹¶ì–´í•¨. ì´ë²ˆë‹¬ ìš°ë¦¬ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ë¥¼ ì¿¼ë¦¬í•œ í›„ ì‹¤ë‚´ì˜¨ë„ê°€ ê°€ì¥ ë‚®ì€ ë‚ ì„ ì°¾ì•„ ê·¸ ë‚ ì§œì™€ ì˜¨ë„ë¥¼ ë°˜í™˜í•˜ë©´ ë¨.\", \"Expectations\": [\"ì´ë²ˆë‹¬ ìš°ë¦¬ë°˜ì€ {{ì´ë²ˆë‹¬_ìš°ë¦¬ë°˜_ìµœì†Œì‹¤ë‚´ì˜¨ë„_ë‚ ì§œ}}ì— {{ì´ë²ˆë‹¬_ìš°ë¦¬ë°˜_ìµœì†Œì‹¤ë‚´ì˜¨ë„}}â„ƒë¡œ ê°€ì¥ ëœ ë”ì› ìŠµë‹ˆë‹¤.\"], \"Mapping\": {\"temporal\": {\"ì´ë²ˆë‹¬\": \"[DATE_TRUNC(\\'month\\', DATE \\'CURRENT_DATE\\'), DATE_TRUNC(\\'month\\', DATE \\'CURRENT_DATE\\' + INTERVAL \\'1 month\\'))\"}, \"spatials\": {\"ìš°ë¦¬ë°˜\": \"01_IB5\"}, \"modalities\": {\"ì‹¤ë‚´ì˜¨ë„\": \"roomtemp\"}}, \"Script\": [\"v_ì´ë²ˆë‹¬_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_df = data(t=\\'ì´ë²ˆë‹¬\\',s=\\'ìš°ë¦¬ë°˜\\',m=\\'ì‹¤ë‚´ì˜¨ë„\\')\", \"v_ì´ë²ˆë‹¬_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_ìµœì†Œ = v_ì´ë²ˆë‹¬_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_df[\\'ì‹¤ë‚´ì˜¨ë„\\'].min()\", \"v_ì´ë²ˆë‹¬_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_ìµœì†Œ_ë‚ ì§œ = get_time(v_ì´ë²ˆë‹¬_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_df[v_ì´ë²ˆë‹¬_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_df[\\'ì‹¤ë‚´ì˜¨ë„\\'] == v_ì´ë²ˆë‹¬_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_ìµœì†Œ], fmt=\\'date\\')\"]}', '{\"Thinking\": \"ì‚¬ìš©ìëŠ” ì‘ë…„ ì˜†ë°˜ ì‹¤ë‚´ì˜¨ë„ê°€ ìµœê³ ì˜€ë˜ ë‹¬ê³¼ ê·¸ë•Œì˜ ì‹¤ë‚´ì˜¨ë„ë¥¼ ì•Œê³ ì‹¶ì–´í•¨. í•´ë‹¹ ê¸°ê°„ì˜ ì‹¤ë‚´ì˜¨ë„ ë°ì´í„°ë¥¼ ì¿¼ë¦¬í•œ í›„ ê°€ì¥ ë†’ì€ ì‹¤ë‚´ì˜¨ë„ë¥¼ ê¸°ë¡í•œ ë‹¬ê³¼ ê·¸ë•Œì˜ ì‹¤ë‚´ì˜¨ë„ë¥¼ ë°˜í™˜í•˜ë©´ ë¨.\", \"Expectations\": [\"ì‘ë…„ ì˜†ë°˜ì€ {{ì‘ë…„_ì˜†ë°˜_ì‹¤ë‚´ì˜¨ë„_ìµœê³ _ë‹¬}}ì— {{ì‘ë…„_ì˜†ë°˜_ì‹¤ë‚´ì˜¨ë„_ìµœê³ _ì˜¨ë„}}â„ƒë¡œ ê°€ì¥ ë”ì› ìŠµë‹ˆë‹¤.\"], \"Mapping\": {\"temporal\": {\"ì‘ë…„\": \"[DATE_TRUNC(\\'year\\', DATE \\'CURRENT_DATE\\' - INTERVAL \\'1 year\\'), DATE_TRUNC(\\'year\\', DATE \\'CURRENT_DATE\\'))\"}, \"spatials\": {\"ì˜†ë°˜\": \"01_IB7\"}, \"modalities\": {\"ì‹¤ë‚´ì˜¨ë„\": \"roomtemp\"}}, \"Script\": [\"v_ì‘ë…„_ì˜†ë°˜_ì‹¤ë‚´ì˜¨ë„_df = data(t=\\'ì‘ë…„\\',s=\\'ì˜†ë°˜\\',m=\\'ì‹¤ë‚´ì˜¨ë„\\')\", \"v_ì‘ë…„_ì˜†ë°˜_ì‹¤ë‚´ì˜¨ë„_ìµœê³ _ì˜¨ë„ = v_ì‘ë…„_ì˜†ë°˜_ì‹¤ë‚´ì˜¨ë„_df[\\'ì‹¤ë‚´ì˜¨ë„\\'].max()\", \"v_ì‘ë…„_ì˜†ë°˜_ì‹¤ë‚´ì˜¨ë„_ìµœê³ _df = v_ì‘ë…„_ì˜†ë°˜_ì‹¤ë‚´ì˜¨ë„_df[v_ì‘ë…„_ì˜†ë°˜_ì‹¤ë‚´ì˜¨ë„_df[\\'ì‹¤ë‚´ì˜¨ë„\\'] == v_ì‘ë…„_ì˜†ë°˜_ì‹¤ë‚´ì˜¨ë„_ìµœê³ _ì˜¨ë„]\", \"v_ì‘ë…„_ì˜†ë°˜_ì‹¤ë‚´ì˜¨ë„_ìµœê³ _ë‹¬ = get_time(v_ì‘ë…„_ì˜†ë°˜_ì‹¤ë‚´ì˜¨ë„_ìµœê³ _df, fmt=\\'month\\')\"]}', '{\"Thinking\": \"2ì£¼ì „ì€ ì •í™•íˆ ë§í•˜ë©´ 2ì£¼ì „ í•œì£¼ (ì›”~ì¼)ë™ì•ˆì„. ì‚¬ìš©ìëŠ” 2ì£¼ì „ ì›”ìš”ì¼ë¶€í„° ì¼ìš”ì¼ê¹Œì§€ ìš°ë¦¬ë°˜ê³¼ ì˜†ë°˜ì˜ ì„¤ì •ì˜¨ë„ê°€ ê°€ì¥ ë‚®ì•˜ë˜ ë‚ ì§œë¥¼ ì•Œê³  ì‹¶ì–´í•¨. 2ì£¼ì „ ìš°ë¦¬ë°˜ê³¼ ì˜†ë°˜ì˜ ì„¤ì •ì˜¨ë„ë¥¼ ì¿¼ë¦¬í•œ í›„ ì„¤ì •ì˜¨ë„ê°€ ê°€ì¥ ë‚®ì€ ë‚ ì„ ì°¾ì•„ ê·¸ ë‚ ì§œì™€ ì˜¨ë„ë¥¼ ë°˜í™˜í•˜ë©´ ë¨.\", \"Expectations\": [\"2ì£¼ì „ ìš°ë¦¬ë°˜ê³¼ ì˜†ë°˜ í•©ì³ì„œ ì„¤ì •ì˜¨ë„ê°€ ê°€ì¥ ë‚®ì€ ë‚ ì€ {{2ì£¼ì „_ìš°ë¦¬ë°˜ê³¼ì˜†ë°˜_ì„¤ì •ì˜¨ë„_ìµœì†Œ_ë‚ ì§œ}}ë¡œ {{2ì£¼ì „_ìš°ë¦¬ë°˜ê³¼ì˜†ë°˜_ì„¤ì •ì˜¨ë„_ìµœì†Œ}}â„ƒì˜€ìŠµë‹ˆë‹¤.\"], \"Mapping\": {\"temporal\": {\"2ì£¼ì „\": \"[DATE_TRUNC(\\'week\\', DATE \\'CURRENT_DATE\\' - INTERVAL \\'2 week\\'), DATE_TRUNC(\\'week\\', DATE \\'CURRENT_DATE\\' - INTERVAL \\'1 week\\'))\"}, \"spatials\": {\"ìš°ë¦¬ë°˜\": \"01_IB5\", \"ì˜†ë°˜\": \"01_IB7\"}, \"modalities\": {\"ì„¤ì •ì˜¨ë„\": \"settemp\"}}, \"Script\": [\"v_2ì£¼ì „_ìš°ë¦¬ë°˜ê³¼ì˜†ë°˜_ì„¤ì •ì˜¨ë„_df = data(t=\\'2ì£¼ì „\\',s=[\\'ìš°ë¦¬ë°˜\\',\\'ì˜†ë°˜\\'],m=\\'ì„¤ì •ì˜¨ë„\\')\", \"v_2ì£¼ì „_ìš°ë¦¬ë°˜ê³¼ì˜†ë°˜_ì„¤ì •ì˜¨ë„_ìµœì†Œ = v_2ì£¼ì „_ìš°ë¦¬ë°˜ê³¼ì˜†ë°˜_ì„¤ì •ì˜¨ë„_df[\\'ì„¤ì •ì˜¨ë„\\'].min()\", \"v_2ì£¼ì „_ìš°ë¦¬ë°˜ê³¼ì˜†ë°˜_ì„¤ì •ì˜¨ë„_ìµœì†Œ_ë‚ ì§œ = get_time(v_2ì£¼ì „_ìš°ë¦¬ë°˜ê³¼ì˜†ë°˜_ì„¤ì •ì˜¨ë„_df[v_2ì£¼ì „_ìš°ë¦¬ë°˜ê³¼ì˜†ë°˜_ì„¤ì •ì˜¨ë„_df[\\'ì„¤ì •ì˜¨ë„\\'] == v_2ì£¼ì „_ìš°ë¦¬ë°˜ê³¼ì˜†ë°˜_ì„¤ì •ì˜¨ë„_ìµœì†Œ], fmt=\\'date\\')\"]}', '{\"Thinking\": \"ì‚¬ìš©ìëŠ” ì§€ë‚œë‹¬ ìš°ë¦¬ë°˜ì˜ ì„¤ì •ì˜¨ë„ í‰ê· ì„ ì•Œê³ ì‹¶ì–´í•¨. í•´ë‹¹ ê¸°ê°„ì˜ ì„¤ì •ì˜¨ë„ ë°ì´í„°ë¥¼ ì¿¼ë¦¬í•œ í›„ í‰ê· ê°’ì„ ë°˜í™˜í•˜ë©´ ë¨.\", \"Expectations\": [\"ì§€ë‚œë‹¬ ì„¤ì •ì˜¨ë„ í‰ê· ì€ {{ì§€ë‚œë‹¬_ìš°ë¦¬ë°˜_ì„¤ì •ì˜¨ë„_í‰ê· }}â„ƒì˜€ìŠµë‹ˆë‹¤.\"], \"Mapping\": {\"temporal\": {\"ì§€ë‚œë‹¬\": \"[DATE_TRUNC(\\'month\\', DATE \\'CURRENT_DATE\\') - INTERVAL \\'1 month\\', DATE_TRUNC(\\'month\\', DATE \\'CURRENT_DATE\\'))\"}, \"spatials\": {\"ìš°ë¦¬ë°˜\": \"01_IB5\"}, \"modalities\": {\"ì„¤ì •ì˜¨ë„\": \"settemp\"}}, \"Script\": [\"v_ì§€ë‚œë‹¬_ìš°ë¦¬ë°˜_ì„¤ì •ì˜¨ë„_df = data(t=\\'ì§€ë‚œë‹¬\\',s=\\'ìš°ë¦¬ë°˜\\',m=\\'ì„¤ì •ì˜¨ë„\\')\", \"v_ì§€ë‚œë‹¬_ìš°ë¦¬ë°˜_ì„¤ì •ì˜¨ë„_í‰ê·  = v_ì§€ë‚œë‹¬_ìš°ë¦¬ë°˜_ì„¤ì •ì˜¨ë„_df[\\'ì„¤ì •ì˜¨ë„\\'].mean()\"]}', '{\"Thinking\": \"ì‚¬ìš©ìëŠ” ì˜¬í•´ 3ì›” ~ 5ì›” ì˜†ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ê°€ ì œì¼ ë‚®ì•˜ë˜ ë‚ ì§œë¥¼ ì•Œê³  ì‹¶ì–´í•¨. ì˜¬í•´ 3ì›” ~ 5ì›” ì˜†ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ë¥¼ ì¿¼ë¦¬í•œ í›„ ì‹¤ë‚´ì˜¨ë„ê°€ ê°€ì¥ ë‚®ì€ ë‚ ì„ ì°¾ì•„ ê·¸ ë‚ ì§œì™€ ì˜¨ë„ë¥¼ ë°˜í™˜í•˜ë©´ ë¨.\", \"Expectations\": [\"ì˜¬í•´ ë´„(3ì›” ~ 5ì›”) ì˜†ë°˜ì€ {{ì˜¬í•´ë´„_ì˜†ë°˜_ì‹¤ë‚´ì˜¨ë„_ìµœì†Œ_ë‚ ì§œ}}ì— {{ì˜¬í•´ë´„_ì˜†ë°˜_ì‹¤ë‚´ì˜¨ë„_ìµœì†Œ}}â„ƒë¡œ ì œì¼ ì¶”ì› ìŠµë‹ˆë‹¤.\"], \"Mapping\": {\"temporal\": {\"ì˜¬í•´ë´„\": \"[DATE \\'CURRENT_YEAR-03-01\\', DATE \\'CURRENT_YEAR-06-01\\')\"}, \"spatials\": {\"ì˜†ë°˜\": \"01_IB7\"}, \"modalities\": {\"ì‹¤ë‚´ì˜¨ë„\": \"roomtemp\"}}, \"Script\": [\"v_ì˜¬í•´ë´„_ì˜†ë°˜_ì‹¤ë‚´ì˜¨ë„_df = data(t=\\'ì˜¬í•´ë´„\\',s=\\'ì˜†ë°˜\\',m=\\'ì‹¤ë‚´ì˜¨ë„\\')\", \"v_ì˜¬í•´ë´„_ì˜†ë°˜_ì‹¤ë‚´ì˜¨ë„_ìµœì†Œ = v_ì˜¬í•´ë´„_ì˜†ë°˜_ì‹¤ë‚´ì˜¨ë„_df[\\'ì‹¤ë‚´ì˜¨ë„\\'].min()\", \"v_ì˜¬í•´ë´„_ì˜†ë°˜_ì‹¤ë‚´ì˜¨ë„_ìµœì†Œ_df = v_ì˜¬í•´ë´„_ì˜†ë°˜_ì‹¤ë‚´ì˜¨ë„_df[v_ì˜¬í•´ë´„_ì˜†ë°˜_ì‹¤ë‚´ì˜¨ë„_df[\\'ì‹¤ë‚´ì˜¨ë„\\'] == v_ì˜¬í•´ë´„_ì˜†ë°˜_ì‹¤ë‚´ì˜¨ë„_ìµœì†Œ]\", \"v_ì˜¬í•´ë´„_ì˜†ë°˜_ì‹¤ë‚´ì˜¨ë„_ìµœì†Œ_ë‚ ì§œ = get_time(v_ì˜¬í•´ë´„_ì˜†ë°˜_ì‹¤ë‚´ì˜¨ë„_ìµœì†Œ_df, fmt=\\'date\\')\"]}', '{\"Thinking\": \"ì‚¬ìš©ìëŠ” 10ë…„ ì „ ì˜¤ëŠ˜ ìš°ë¦¬ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ë¥¼ ì•Œê³  ì‹¶ì–´í•¨. 10ë…„ ì „ ì˜¤ëŠ˜ ìš°ë¦¬ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ì˜ í•˜ë£¨ í‰ê· ê°’ì„ ë°˜í™˜í•˜ë©´ ë¨.\", \"Expectations\": [\"10ë…„ ì „ ì˜¤ëŠ˜ ìš°ë¦¬ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ëŠ” {{10ë…„ì „ì˜¤ëŠ˜_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_í‰ê· }}â„ƒì˜€ìŠµë‹ˆë‹¤.\"], \"Mapping\": {\"temporal\": {\"10ë…„ì „ì˜¤ëŠ˜\": \"[DATE_TRUNC(\\'day\\', DATE \\'CURRENT_DATE\\' - INTERVAL \\'10 year\\'), DATE_TRUNC(\\'day\\', DATE \\'CURRENT_DATE\\' - INTERVAL \\'10 year\\' + INTERVAL \\'1 day\\'))\"}, \"spatials\": {\"ìš°ë¦¬ë°˜\": \"01_IB5\"}, \"modalities\": {\"ì‹¤ë‚´ì˜¨ë„\": \"roomtemp\"}}, \"Script\": [\"v_10ë…„ì „ì˜¤ëŠ˜_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_df = data(t=\\'10ë…„ì „ì˜¤ëŠ˜\\',s=\\'ìš°ë¦¬ë°˜\\',m=\\'ì‹¤ë‚´ì˜¨ë„\\')\", \"v_10ë…„ì „ì˜¤ëŠ˜_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_í‰ê·  = v_10ë…„ì „ì˜¤ëŠ˜_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_df[\\'ì‹¤ë‚´ì˜¨ë„\\'].mean()\"]}']}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeceaae5ad364fe7b76e42442d6c7d37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Metadata': [{'current_datetime': '2022-09-29 21:30:00', 'idu_mapping': {'01_IB5': ['ì˜†ë°˜', '4ì¸µ'], '01_IB7': ['ì•ë°˜', '4ì¸µ'], '02_I81': ['ìš°ë¦¬ë°˜', '4ì¸µ']}, 'modality_mapping': {'roomtemp': ['ì‹¤ë‚´ì˜¨ë„'], 'settemp': ['ì„¤ì •ì˜¨ë„']}}, {'current_datetime': '2022-09-29 21:30:00', 'idu_mapping': {'01_IB5': ['ì˜†ë°˜', '4ì¸µ'], '01_IB7': ['ì•ë°˜', '4ì¸µ'], '02_I81': ['ìš°ë¦¬ë°˜', '4ì¸µ']}, 'modality_mapping': {'roomtemp': ['ì‹¤ë‚´ì˜¨ë„'], 'settemp': ['ì„¤ì •ì˜¨ë„']}}, {'current_datetime': '2022-09-29 21:30:00', 'idu_mapping': {'01_IB5': ['ì˜†ë°˜', '4ì¸µ'], '01_IB7': ['ì•ë°˜', '4ì¸µ'], '02_I81': ['ìš°ë¦¬ë°˜', '4ì¸µ']}, 'modality_mapping': {'roomtemp': ['ì‹¤ë‚´ì˜¨ë„'], 'settemp': ['ì„¤ì •ì˜¨ë„']}}, {'current_datetime': '2022-09-29 21:30:00', 'idu_mapping': {'01_IB5': ['ì˜†ë°˜', '4ì¸µ'], '01_IB7': ['ì•ë°˜', '4ì¸µ'], '02_I81': ['ìš°ë¦¬ë°˜', '4ì¸µ']}, 'modality_mapping': {'roomtemp': ['ì‹¤ë‚´ì˜¨ë„'], 'settemp': ['ì„¤ì •ì˜¨ë„']}}, {'current_datetime': '2022-09-29 21:30:00', 'idu_mapping': {'01_IB5': ['ì˜†ë°˜', '4ì¸µ'], '01_IB7': ['ì•ë°˜', '4ì¸µ'], '02_I81': ['ìš°ë¦¬ë°˜', '4ì¸µ']}, 'modality_mapping': {'roomtemp': ['ì‹¤ë‚´ì˜¨ë„'], 'settemp': ['ì„¤ì •ì˜¨ë„']}}, {'current_datetime': '2022-09-29 21:30:00', 'idu_mapping': {'01_IB5': ['ì˜†ë°˜', '4ì¸µ'], '01_IB7': ['ì•ë°˜', '4ì¸µ'], '02_I81': ['ìš°ë¦¬ë°˜', '4ì¸µ']}, 'modality_mapping': {'roomtemp': ['ì‹¤ë‚´ì˜¨ë„'], 'settemp': ['ì„¤ì •ì˜¨ë„']}}, {'current_datetime': '2022-09-29 21:30:00', 'idu_mapping': {'01_IB5': ['ì˜†ë°˜', '4ì¸µ'], '01_IB7': ['ì•ë°˜', '4ì¸µ'], '02_I81': ['ìš°ë¦¬ë°˜', '4ì¸µ']}, 'modality_mapping': {'roomtemp': ['ì‹¤ë‚´ì˜¨ë„'], 'settemp': ['ì„¤ì •ì˜¨ë„']}}, {'current_datetime': '2022-09-29 21:30:00', 'idu_mapping': {'01_IB5': ['ì˜†ë°˜', '4ì¸µ'], '01_IB7': ['ì•ë°˜', '4ì¸µ'], '02_I81': ['ìš°ë¦¬ë°˜', '4ì¸µ']}, 'modality_mapping': {'roomtemp': ['ì‹¤ë‚´ì˜¨ë„'], 'settemp': ['ì„¤ì •ì˜¨ë„']}}, {'current_datetime': '2022-09-29 21:30:00', 'idu_mapping': {'01_IB5': ['ì˜†ë°˜', '4ì¸µ'], '01_IB7': ['ì•ë°˜', '4ì¸µ'], '02_I81': ['ìš°ë¦¬ë°˜', '4ì¸µ']}, 'modality_mapping': {'roomtemp': ['ì‹¤ë‚´ì˜¨ë„'], 'settemp': ['ì„¤ì •ì˜¨ë„']}}, {'current_datetime': '2022-09-29 21:30:00', 'idu_mapping': {'01_IB5': ['ì˜†ë°˜', '4ì¸µ'], '01_IB7': ['ì•ë°˜', '4ì¸µ'], '02_I81': ['ìš°ë¦¬ë°˜', '4ì¸µ']}, 'modality_mapping': {'roomtemp': ['ì‹¤ë‚´ì˜¨ë„'], 'settemp': ['ì„¤ì •ì˜¨ë„']}}, {'current_datetime': '2022-09-29 21:30:00', 'idu_mapping': {'01_IB5': ['ì˜†ë°˜', '4ì¸µ'], '01_IB7': ['ì•ë°˜', '4ì¸µ'], '02_I81': ['ìš°ë¦¬ë°˜', '4ì¸µ']}, 'modality_mapping': {'roomtemp': ['ì‹¤ë‚´ì˜¨ë„'], 'settemp': ['ì„¤ì •ì˜¨ë„']}}, {'current_datetime': '2022-09-29 21:30:00', 'idu_mapping': {'01_IB5': ['ì˜†ë°˜', '4ì¸µ'], '01_IB7': ['ì•ë°˜', '4ì¸µ'], '02_I81': ['ìš°ë¦¬ë°˜', '4ì¸µ']}, 'modality_mapping': {'roomtemp': ['ì‹¤ë‚´ì˜¨ë„'], 'settemp': ['ì„¤ì •ì˜¨ë„']}}], 'Input': ['ì´ë²ˆì£¼ ìš°ë¦¬ë°˜ê³¼ ì•ë°˜ì˜ í‰ê·  ì˜¨ë„ ì•Œë ¤ì¤˜', 'í˜„ì¬ ì„¤ì •ì˜¨ë„ë‘ ì‹¤ë‚´ì˜¨ë„ ì°¨ì´ ì•Œë ¤ì¤˜.', 'ì§€ë‚œë‹¬ì— ì„¤ì •ì˜¨ë„ì™€ ì‹¤ë‚´ì˜¨ë„ ì°¨ì´ê°€ ê°€ì¥ ë§ì´ ë‚¬ë˜ ë‚ ì€?', 'ì´ë²ˆì£¼ ìš°ë¦¬ë°˜ê³¼ ì˜†ë°˜ì˜ í‰ê·  ì‹¤ë‚´ì˜¨ë„ ì°¨ì´ ì•Œë ¤ì¤˜', '2ì£¼ì „ ê°€ì¥ ë”ì› ë˜ ë‚  ì•Œë ¤ì¤˜', 'í™”ì„±ì˜ ì„¤ì •ì˜¨ë„ í™•ì¸í•´ì¤˜', 'ì˜†ë°˜ ìŠµë„ ì•Œë ¤ì¤˜', 'ì§€ë‚œ 3ì¼ ë™ì•ˆ ìš°ë¦¬ë°˜ ì‹¤ë‚´ ì˜¨ë„ í‰ê·  ê°’ ì•Œë ¤ì¤˜.', 'ì˜¤ëŠ˜ ì˜¤í›„ 5ì‹œì— ì˜†ë°˜ì˜ ì„¤ì •ì˜¨ë„ëŠ” ì–´ë• ì–´?', 'ì˜¬í•´ ì—¬ë¦„ ìš°ë¦¬ë°˜ ì‹¤ë‚´ì˜¨ë„ ìµœëŒ€ê°’ê³¼ ìµœì†Œê°’ ì•Œë ¤ì¤˜', 'ìš°ë¦¬ë°˜ê³¼ ì•ë°˜ ì¤‘ ê°€ì¥ ë”ìš´ ë°©ì€?', 'ì§€ê¸ˆ 4ì¸µ í‰ê·  ì‹¤ë‚´ì˜¨ë„ ì•Œë ¤ì¤˜'], 'Scenarios': ['scenario2', 'scenario2', 'scenario2', 'scenario2', 'scenario2', 'scenario2', 'scenario2', 'scenario2', 'scenario2', 'scenario2', 'scenario2', 'scenario2'], 'Response': ['{\"Thinking\": \"ì‚¬ìš©ìëŠ” ì´ë²ˆì£¼ ìš°ë¦¬ë°˜ê³¼ ì•ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ì˜ í‰ê· ì„ ì•Œê³ ì‹¶ì–´í•¨. ì´ë²ˆì£¼ ìš°ë¦¬ë°˜ê³¼ ì•ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ ë°ì´í„°ë¥¼ ì¿¼ë¦¬í•œ í›„ í‰ê· ê°’ì„ ê³„ì‚°í•˜ë©´ ë¨.\", \"Expectations\": [\"ì´ë²ˆì£¼ ìš°ë¦¬ë°˜ì˜ í‰ê·  ì‹¤ë‚´ì˜¨ë„ëŠ” {{ì´ë²ˆì£¼_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_í‰ê· }}â„ƒì´ê³ , ì•ë°˜ì˜ í‰ê·  ì‹¤ë‚´ì˜¨ë„ëŠ” {{ì´ë²ˆì£¼_ì•ë°˜_ì‹¤ë‚´ì˜¨ë„_í‰ê· }}â„ƒì…ë‹ˆë‹¤.\"], \"Mapping\": {\"temporal\": {\"ì´ë²ˆì£¼\": \"[DATE_TRUNC(\\'week\\', DATE \\'CURRENT_DATE\\'), DATE_TRUNC(\\'week\\', DATE \\'CURRENT_DATE\\' + INTERVAL \\'1 week\\'))\"}, \"spatials\": {\"ìš°ë¦¬ë°˜\": \"02_I81\", \"ì•ë°˜\": \"01_IB7\"}, \"modalities\": {\"ì‹¤ë‚´ì˜¨ë„\": \"roomtemp\"}}, \"Script\": [\"v_ì´ë²ˆì£¼_ìš°ë¦¬ë°˜_df = data(t=\\'ì´ë²ˆì£¼\\',s=\\'ìš°ë¦¬ë°˜\\',m=\\'ì‹¤ë‚´ì˜¨ë„\\')\", \"v_ì´ë²ˆì£¼_ì•ë°˜_df = data(t=\\'ì´ë²ˆì£¼\\',s=\\'ì•ë°˜\\',m=\\'ì‹¤ë‚´ì˜¨ë„\\')\", \"v_ì´ë²ˆì£¼_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_í‰ê·  = v_ì´ë²ˆì£¼_ìš°ë¦¬ë°˜_df[\\'ì‹¤ë‚´ì˜¨ë„\\'].mean()\", \"v_ì´ë²ˆì£¼_ì•ë°˜_ì‹¤ë‚´ì˜¨ë„_í‰ê·  = v_ì´ë²ˆì£¼_ì•ë°˜_df[\\'ì‹¤ë‚´ì˜¨ë„\\'].mean()\"]}', '{\"Thinking\": \"ì‚¬ìš©ìëŠ” í˜„ì¬ ìš°ë¦¬ë°˜ì˜ ì„¤ì •ì˜¨ë„ì™€ ì‹¤ë‚´ì˜¨ë„ì˜ ì°¨ì´ë¥¼ ì•Œê³ ì‹¶ì–´í•¨. í˜„ì¬ ìš°ë¦¬ë°˜ì˜ ì„¤ì •ì˜¨ë„ì™€ ì‹¤ë‚´ì˜¨ë„ ë°ì´í„°ë¥¼ ì¿¼ë¦¬í•œ í›„ ì°¨ì´ë¥¼ ê³„ì‚°í•˜ë©´ ë¨.\", \"Expectations\": [\"í˜„ì¬ ì„¤ì •ì˜¨ë„({{í˜„ì¬_ìš°ë¦¬ë°˜_ì„¤ì •ì˜¨ë„}}â„ƒ)ì™€ ì‹¤ë‚´ì˜¨ë„({{í˜„ì¬_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„}}â„ƒ)ì˜ ì°¨ì´ëŠ” {{í˜„ì¬_ìš°ë¦¬ë°˜_ì˜¨ë„_ì°¨ì´}}â„ƒì…ë‹ˆë‹¤.\"], \"Mapping\": {\"temporal\": {\"í˜„ì¬\": \"LAST_RECORD\"}, \"spatials\": {\"ìš°ë¦¬ë°˜\": \"02_I81\"}, \"modalities\": {\"ì„¤ì •ì˜¨ë„\": \"settemp\", \"ì‹¤ë‚´ì˜¨ë„\": \"roomtemp\"}}, \"Script\": [\"v_í˜„ì¬_ìš°ë¦¬ë°˜_df = data(t=\\'í˜„ì¬\\',s=\\'ìš°ë¦¬ë°˜\\',m=[\\'ì„¤ì •ì˜¨ë„\\',\\'ì‹¤ë‚´ì˜¨ë„\\'])\", \"v_í˜„ì¬_ìš°ë¦¬ë°˜_ì„¤ì •ì˜¨ë„ = v_í˜„ì¬_ìš°ë¦¬ë°˜_df[\\'ì„¤ì •ì˜¨ë„\\'].values[0]\", \"v_í˜„ì¬_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„ = v_í˜„ì¬_ìš°ë¦¬ë°˜_df[\\'ì‹¤ë‚´ì˜¨ë„\\'].values[0]\", \"v_í˜„ì¬_ìš°ë¦¬ë°˜_ì˜¨ë„_ì°¨ì´ = abs(v_í˜„ì¬_ìš°ë¦¬ë°˜_ì„¤ì •ì˜¨ë„ - v_í˜„ì¬_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„)\"]}', '{\"Thinking\": \"ì‚¬ìš©ìëŠ” ì§€ë‚œë‹¬ ìš°ë¦¬ë°˜ ì„¤ì •ì˜¨ë„ì™€ ì‹¤ë‚´ì˜¨ë„ ì°¨ì´ê°€ ê°€ì¥ ì»¸ë˜ ë‚ ì§œë¥¼ ì•Œê³  ì‹¶ì–´í•¨. ì§€ë‚œë‹¬ ìš°ë¦¬ë°˜ì˜ ì„¤ì •ì˜¨ë„ì™€ ì‹¤ë‚´ì˜¨ë„ ë°ì´í„°ë¥¼ ì¿¼ë¦¬í•œ í›„ ì°¨ì´ë¥¼ ê³„ì‚°í•˜ë©´ ë¨.\", \"Expectations\": [\"ì§€ë‚œë‹¬ {{ì§€ë‚œë‹¬_ìš°ë¦¬ë°˜_ì˜¨ë„ì°¨ì´_ìµœê³ _ë‚ ì§œ}}ì— ì„¤ì •ì˜¨ë„({{ì§€ë‚œë‹¬_ìš°ë¦¬ë°˜_ì˜¨ë„ì°¨ì´_ìµœê³ _ì„¤ì •ì˜¨ë„}}â„ƒ)ì™€ ì‹¤ë‚´ì˜¨ë„({{ì§€ë‚œë‹¬_ìš°ë¦¬ë°˜_ì˜¨ë„ì°¨ì´_ìµœê³ _ì‹¤ë‚´ì˜¨ë„}}â„ƒ) ì°¨ì´ê°€ {{ì§€ë‚œë‹¬_ìš°ë¦¬ë°˜_ì˜¨ë„ì°¨ì´_ìµœê³ }}â„ƒë¡œ ê°€ì¥ ì»¸ìŠµë‹ˆë‹¤.\"], \"Mapping\": {\"temporal\": {\"ì§€ë‚œë‹¬\": \"[DATE_TRUNC(\\'month\\', DATE \\'CURRENT_DATE\\') - INTERVAL \\'1 month\\', DATE_TRUNC(\\'month\\', DATE \\'CURRENT_DATE\\'))\"}, \"spatials\": {\"ìš°ë¦¬ë°˜\": \"02_I81\"}, \"modalities\": {\"ì„¤ì •ì˜¨ë„\": \"settemp\", \"ì‹¤ë‚´ì˜¨ë„\": \"roomtemp\"}}, \"Script\": [\"v_ì§€ë‚œë‹¬_ìš°ë¦¬ë°˜_df = data(t=\\'ì§€ë‚œë‹¬\\',s=\\'ìš°ë¦¬ë°˜\\',m=[\\'ì„¤ì •ì˜¨ë„\\',\\'ì‹¤ë‚´ì˜¨ë„\\'])\", \"v_ì§€ë‚œë‹¬_ìš°ë¦¬ë°˜_df[\\'ì˜¨ë„ì°¨ì´\\'] = v_ì§€ë‚œë‹¬_ìš°ë¦¬ë°˜_df[\\'ì„¤ì •ì˜¨ë„\\'] - v_ì§€ë‚œë‹¬_ìš°ë¦¬ë°˜_df[\\'ì‹¤ë‚´ì˜¨ë„\\']\", \"v_ì§€ë‚œë‹¬_ìš°ë¦¬ë°˜_ì˜¨ë„ì°¨ì´_ìµœê³  = v_ì§€ë‚œë‹¬_ìš°ë¦¬ë°˜_df[\\'ì˜¨ë„ì°¨ì´\\'].max()\", \"v_ì§€ë‚œë‹¬_ìš°ë¦¬ë°˜_ì˜¨ë„ì°¨ì´_ìµœê³ _df = v_ì§€ë‚œë‹¬_ìš°ë¦¬ë°˜_df[v_ì§€ë‚œë‹¬_ìš°ë¦¬ë°˜_df[\\'ì˜¨ë„ì°¨ì´\\'] == v_ì§€ë‚œë‹¬_ìš°ë¦¬ë°˜_ì˜¨ë„ì°¨ì´_ìµœê³ ]\", \"v_ì§€ë‚œë‹¬_ìš°ë¦¬ë°˜_ì˜¨ë„ì°¨ì´_ìµœê³ _ë‚ ì§œ = get_time(v_ì§€ë‚œë‹¬_ìš°ë¦¬ë°˜_ì˜¨ë„ì°¨ì´_ìµœê³ _df, fmt=\\'date\\')\", \"v_ì§€ë‚œë‹¬_ìš°ë¦¬ë°˜_ì˜¨ë„ì°¨ì´_ìµœê³ _ì„¤ì •ì˜¨ë„ = v_ì§€ë‚œë‹¬_ìš°ë¦¬ë°˜_ì˜¨ë„ì°¨ì´_ìµœê³ _df[\\'ì„¤ì •ì˜¨ë„\\'].values[0]\", \"v_ì§€ë‚œë‹¬_ìš°ë¦¬ë°˜_ì˜¨ë„ì°¨ì´_ìµœê³ _ì‹¤ë‚´ì˜¨ë„ = v_ì§€ë‚œë‹¬_ìš°ë¦¬ë°˜_ì˜¨ë„ì°¨ì´_ìµœê³ _df[\\'ì‹¤ë‚´ì˜¨ë„\\'].values[0]\"]}', '{\"Thinking\": \"ì‚¬ìš©ìëŠ” ì´ë²ˆì£¼ ìš°ë¦¬ë°˜ê³¼ ì˜†ë°˜ì˜ í‰ê·  ì‹¤ë‚´ì˜¨ë„ ì°¨ì´ë¥¼ ì•Œê³ ì‹¶ì–´í•¨. ì´ë²ˆì£¼ ìš°ë¦¬ë°˜ê³¼ ì˜†ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ ë°ì´í„°ë¥¼ ì¿¼ë¦¬í•œ í›„ í‰ê· ê°’ì„ ê³„ì‚°í•˜ë©´ ë¨.\", \"Expectations\": [\"ì´ë²ˆì£¼ ìš°ë¦¬ë°˜ í‰ê·  ì‹¤ë‚´ì˜¨ë„({{ì´ë²ˆì£¼_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_í‰ê· }}â„ƒ)ì™€ ì˜†ë°˜ í‰ê·  ì‹¤ë‚´ì˜¨ë„({{ì´ë²ˆì£¼_ì˜†ë°˜_ì‹¤ë‚´ì˜¨ë„_í‰ê· }}â„ƒ) ì°¨ì´ëŠ” {{ì´ë²ˆì£¼_ì‹¤ë‚´ì˜¨ë„_í‰ê· _ì°¨ì´}}â„ƒì…ë‹ˆë‹¤.\"], \"Mapping\": {\"temporal\": {\"ì´ë²ˆì£¼\": \"[DATE_TRUNC(\\'week\\', DATE \\'CURRENT_DATE\\'), DATE_TRUNC(\\'week\\', DATE \\'CURRENT_DATE\\' + INTERVAL \\'1 week\\'))\"}, \"spatials\": {\"ìš°ë¦¬ë°˜\": \"02_I81\", \"ì˜†ë°˜\": \"01_IB5\"}, \"modalities\": {\"ì‹¤ë‚´ì˜¨ë„\": \"roomtemp\"}}, \"Script\": [\"v_ì´ë²ˆì£¼_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_df = data(t=\\'ì´ë²ˆì£¼\\',s=\\'ìš°ë¦¬ë°˜\\',m=\\'ì‹¤ë‚´ì˜¨ë„\\')\", \"v_ì´ë²ˆì£¼_ì˜†ë°˜_ì‹¤ë‚´ì˜¨ë„_df = data(t=\\'ì´ë²ˆì£¼\\',s=\\'ì˜†ë°˜\\',m=\\'ì‹¤ë‚´ì˜¨ë„\\')\", \"v_ì´ë²ˆì£¼_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_í‰ê·  = v_ì´ë²ˆì£¼_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_df[\\'ì‹¤ë‚´ì˜¨ë„\\'].mean()\", \"v_ì´ë²ˆì£¼_ì˜†ë°˜_ì‹¤ë‚´ì˜¨ë„_í‰ê·  = v_ì´ë²ˆì£¼_ì˜†ë°˜_ì‹¤ë‚´ì˜¨ë„_df[\\'ì‹¤ë‚´ì˜¨ë„\\'].mean()\", \"v_ì´ë²ˆì£¼_ì‹¤ë‚´ì˜¨ë„_í‰ê· _ì°¨ì´ = abs(v_ì´ë²ˆì£¼_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_í‰ê·  - v_ì´ë²ˆì£¼_ì˜†ë°˜_ì‹¤ë‚´ì˜¨ë„_í‰ê· )\"]}', '{\"Thinking\": \"ì‚¬ìš©ìëŠ” 2ì£¼ì „ ìš°ë¦¬ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ê°€ ê°€ì¥ ë†’ì•˜ë˜ ë‚ ì§œë¥¼ ì•Œê³  ì‹¶ì–´í•¨. 2ì£¼ì „ ìš°ë¦¬ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ ë°ì´í„°ë¥¼ ì¿¼ë¦¬í•œ í›„ ìµœê³ ê°’ì„ ê¸°ë¡í•œ ë‚ ì§œì™€ ê°’ì„ ë°˜í™˜í•˜ë©´ ë¨.\", \"Expectations\": [\"2ì£¼ì „ {{2ì£¼ì „_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_ìµœê³ _ë‚ ì§œ}}ì— ì‹¤ë‚´ì˜¨ë„({{2ì£¼ì „_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_ìµœê³ _ì‹¤ë‚´ì˜¨ë„}}â„ƒ)ê°€ ê°€ì¥ ë†’ì•˜ìŠµë‹ˆë‹¤.\"], \"Mapping\": {\"temporal\": {\"2ì£¼ì „\": \"[DATE_TRUNC(\\'week\\', DATE \\'CURRENT_DATE\\' - INTERVAL \\'2 week\\'), DATE_TRUNC(\\'week\\', DATE \\'CURRENT_DATE\\' - INTERVAL \\'1 week\\'))\"}, \"spatials\": {\"ìš°ë¦¬ë°˜\": \"02_I81\"}, \"modalities\": {\"ì‹¤ë‚´ì˜¨ë„\": \"roomtemp\"}}, \"Script\": [\"v_2ì£¼ì „_ìš°ë¦¬ë°˜_df = data(t=\\'2ì£¼ì „\\',s=\\'ìš°ë¦¬ë°˜\\',m=\\'ì‹¤ë‚´ì˜¨ë„\\')\", \"v_2ì£¼ì „_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_ìµœê³  = v_2ì£¼ì „_ìš°ë¦¬ë°˜_df[\\'ì‹¤ë‚´ì˜¨ë„\\'].max()\", \"v_2ì£¼ì „_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_ìµœê³ _df = v_2ì£¼ì „_ìš°ë¦¬ë°˜_df[v_2ì£¼ì „_ìš°ë¦¬ë°˜_df[\\'ì‹¤ë‚´ì˜¨ë„\\'] == v_2ì£¼ì „_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_ìµœê³ ]\", \"v_2ì£¼ì „_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_ìµœê³ _ë‚ ì§œ = get_time(v_2ì£¼ì „_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_ìµœê³ _df, fmt=\\'date\\')\", \"v_2ì£¼ì „_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_ìµœê³ _ì‹¤ë‚´ì˜¨ë„ = v_2ì£¼ì „_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_ìµœê³ _df[\\'ì‹¤ë‚´ì˜¨ë„\\'].values[0]\"]}', '{\"Thinking\": \"ì‚¬ìš©ìëŠ” í˜„ì¬ í™”ì„±ì˜ ì„¤ì •ì˜¨ë„ë¥¼ ì•Œê³  ì‹¶ì–´í•¨. í˜„ì¬ í™”ì„±ì˜ ì„¤ì •ì˜¨ë„ ë°ì´í„°ë¥¼ ì¿¼ë¦¬í•œ í›„ ê°’ì„ ë°˜í™˜í•˜ë©´ ë¨.\", \"Expectations\": [\"í˜„ì¬ í™”ì„±ì˜ ì„¤ì •ì˜¨ë„ëŠ” {{í˜„ì¬_í™”ì„±_ì„¤ì •ì˜¨ë„}}â„ƒì…ë‹ˆë‹¤.\"], \"Mapping\": {\"temporal\": {\"í˜„ì¬\": \"LAST_RECORD\"}, \"spatials\": {\"í™”ì„±\": \"Unknown\"}, \"modalities\": {\"ì„¤ì •ì˜¨ë„\": \"settemp\"}}}', '{\"Thinking\": \"ì‚¬ìš©ìëŠ” ì˜†ë°˜ì˜ í˜„ì¬ ìŠµë„ë¥¼ ì•Œê³  ì‹¶ì–´í•¨. ì˜†ë°˜ì˜ í˜„ì¬ ìŠµë„ ë°ì´í„°ë¥¼ ì¿¼ë¦¬í•œ í›„ ê°’ì„ ë°˜í™˜í•˜ë©´ ë¨.\", \"Expectations\": [\"ì˜†ë°˜ì˜ í˜„ì¬ ìŠµë„ëŠ” {{í˜„ì¬_ì˜†ë°˜_ìŠµë„}}%ì…ë‹ˆë‹¤.\"], \"Mapping\": {\"temporal\": {\"í˜„ì¬\": \"LAST_RECORD\"}, \"spatials\": {\"ì˜†ë°˜\": \"01_IB5\"}, \"modalities\": {\"ìŠµë„\": \"Unknown\"}}}', '{\"Thinking\": \"ì‚¬ìš©ìëŠ” ì§€ë‚œ 3ì¼ ë™ì•ˆ ìš°ë¦¬ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ í‰ê· ê°’ì„ ì•Œê³  ì‹¶ì–´í•¨. ì§€ë‚œ 3ì¼ ë™ì•ˆ ìš°ë¦¬ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ ë°ì´í„°ë¥¼ ì¿¼ë¦¬í•œ í›„ í‰ê· ê°’ì„ ê³„ì‚°í•˜ë©´ ë¨.\", \"Expectations\": [\"ì§€ë‚œ 3ì¼ê°„ ìš°ë¦¬ë°˜ ì‹¤ë‚´ì˜¨ë„ í‰ê· ê°’ì€ {{ì§€ë‚œ3ì¼_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_í‰ê· }}â„ƒì˜€ìŠµë‹ˆë‹¤.\"], \"Mapping\": {\"temporal\": {\"ì§€ë‚œ3ì¼\": \"[DATE_TRUNC(\\'day\\', DATE \\'CURRENT_DATE\\' - INTERVAL \\'3 day\\'), DATE_TRUNC(\\'day\\', DATE \\'CURRENT_DATE\\'))\"}, \"spatials\": {\"ìš°ë¦¬ë°˜\": \"02_I81\"}, \"modalities\": {\"ì‹¤ë‚´ì˜¨ë„\": \"roomtemp\"}}, \"Script\": [\"v_ì§€ë‚œ3ì¼_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_df = data(t=\\'ì§€ë‚œ3ì¼\\',s=\\'ìš°ë¦¬ë°˜\\',m=\\'ì‹¤ë‚´ì˜¨ë„\\')\", \"v_ì§€ë‚œ3ì¼_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_í‰ê·  = v_ì§€ë‚œ3ì¼_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_df[\\'ì‹¤ë‚´ì˜¨ë„\\'].mean()\"]}', '{\"Thinking\": \"ì‚¬ìš©ìëŠ” ì˜¤ëŠ˜ ì˜¤í›„ 5ì‹œì— ì˜†ë°˜ì˜ ì„¤ì •ì˜¨ë„ë¥¼ ì•Œê³  ì‹¶ì–´í•¨. ì˜¤ëŠ˜ ì˜¤í›„ 5ì‹œì— ì˜†ë°˜ì˜ ì„¤ì •ì˜¨ë„ ë°ì´í„°ë¥¼ ì¿¼ë¦¬í•œ í›„ ê°’ì„ ë°˜í™˜í•˜ë©´ ë¨.\", \"Expectations\": [\"ì˜¤ëŠ˜ ì˜¤í›„ 5ì‹œ ì˜†ë°˜ì˜ ì„¤ì •ì˜¨ë„ëŠ” {{ì˜¤ëŠ˜ì˜¤í›„5ì‹œ_ì˜†ë°˜_ì„¤ì •ì˜¨ë„}}â„ƒì˜€ìŠµë‹ˆë‹¤.\"], \"Mapping\": {\"temporal\": {\"ì˜¤ëŠ˜ì˜¤í›„5ì‹œ\": \"DATE_TRUNC(\\'day\\', DATE \\'CURRENT_DATE\\') + INTERVAL \\'17 hours\\'\"}, \"spatials\": {\"ì˜†ë°˜\": \"01_IB5\"}, \"modalities\": {\"ì„¤ì •ì˜¨ë„\": \"settemp\"}}, \"Script\": [\"v_ì˜¤ëŠ˜ì˜¤í›„5ì‹œ_ì˜†ë°˜_df = data(t=\\'ì˜¤ëŠ˜ì˜¤í›„5ì‹œ\\',s=\\'ì˜†ë°˜\\',m=\\'ì„¤ì •ì˜¨ë„\\')\", \"v_ì˜¤ëŠ˜ì˜¤í›„5ì‹œ_ì˜†ë°˜_ì„¤ì •ì˜¨ë„ = v_ì˜¤ëŠ˜ì˜¤í›„5ì‹œ_ì˜†ë°˜_df[\\'ì„¤ì •ì˜¨ë„\\'].values[0]\"]}', '{\"Thinking\": \"ì‚¬ìš©ìëŠ” ì˜¬í•´ 6ì›” ~ 8ì›” ë™ì•ˆ ìš°ë¦¬ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ ìµœëŒ€ê°’ê³¼ ìµœì†Œê°’ì„ ì•Œê³  ì‹¶ì–´í•¨. ì˜¬í•´ 6ì›” ~ 8ì›” ë™ì•ˆ ìš°ë¦¬ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ ë°ì´í„°ë¥¼ ì¿¼ë¦¬í•œ í›„ ìµœëŒ€ê°’ê³¼ ìµœì†Œê°’ì„ ê³„ì‚°í•˜ë©´ ë¨.\", \"Expectations\": [\"ì˜¬í•´ ì—¬ë¦„(6ì›” ~ 8ì›”) ìš°ë¦¬ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ ìµœëŒ€ê°’ê³¼ ìµœì†Œê°’ì€ ê°ê° {{ì˜¬í•´ì—¬ë¦„_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_ìµœëŒ€}}â„ƒì™€ {{ì˜¬í•´ì—¬ë¦„_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_ìµœì†Œ}}â„ƒì…ë‹ˆë‹¤.\"], \"Mapping\": {\"temporal\": {\"ì˜¬í•´ì—¬ë¦„\": \"[DATE \\'CURRENT_YEAR-06-01\\', DATE \\'CURRENT_YEAR-09-01\\')\"}, \"spatials\": {\"ìš°ë¦¬ë°˜\": \"02_I81\"}, \"modalities\": {\"ì‹¤ë‚´ì˜¨ë„\": \"roomtemp\"}}, \"Script\": [\"v_ì˜¬í•´ì—¬ë¦„_ìš°ë¦¬ë°˜_df = data(t=\\'ì˜¬í•´ì—¬ë¦„\\',s=\\'ìš°ë¦¬ë°˜\\',m=\\'ì‹¤ë‚´ì˜¨ë„\\')\", \"v_ì˜¬í•´ì—¬ë¦„_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_ìµœëŒ€ = v_ì˜¬í•´ì—¬ë¦„_ìš°ë¦¬ë°˜_df[\\'ì‹¤ë‚´ì˜¨ë„\\'].max()\", \"v_ì˜¬í•´ì—¬ë¦„_ìš°ë¦¬ë°˜_ì‹¤ë‚´ì˜¨ë„_ìµœì†Œ = v_ì˜¬í•´ì—¬ë¦„_ìš°ë¦¬ë°˜_df[\\'ì‹¤ë‚´ì˜¨ë„\\'].min()\"]}', '{\"Thinking\": \"ì‚¬ìš©ìëŠ” í˜„ì¬ ìš°ë¦¬ë°˜ê³¼ ì•ë°˜ ì¤‘ ì‹¤ë‚´ì˜¨ë„ê°€ ìµœê³ ì¸ ë°©ì„ ì•Œê³ ì‹¶ì–´í•¨.í˜„ì¬ ë‘ ë°©ì˜ ì‹¤ë‚´ì˜¨ë„ë¥¼ ì¿¼ë¦¬í•œ í›„ ì‹¤ë‚´ì˜¨ë„ê°€ ìµœê³ ì¸ ë°©ê³¼ ê·¸ ì˜¨ë„ë¥¼ ë°˜í™˜í•˜ë©´ ë¨.\", \"Expectations\": [\"í˜„ì¬ ë‘ ë°© ì¤‘ {{í˜„ì¬_ì‹¤ë‚´ì˜¨ë„_ìµœê³ _ë°©}}ì´(ê°€) {{í˜„ì¬_ì‹¤ë‚´ì˜¨ë„_ìµœê³ }}â„ƒë¡œ ê°€ì¥ ë”ìš´ ë°©ì´ì—ìš”.\"], \"Mapping\": {\"temporal\": {\"í˜„ì¬\": \"LAST_RECORD\"}, \"spatials\": {\"ìš°ë¦¬ë°˜\": \"02_I81\", \"ì•ë°˜\": \"01_IB7\"}, \"modalities\": {\"ì‹¤ë‚´ì˜¨ë„\": \"roomtemp\"}}, \"Script\": [\"v_í˜„ì¬_ë°©ë³„_ì‹¤ë‚´ì˜¨ë„_df = data(t=\\'í˜„ì¬\\',s=[\\'ìš°ë¦¬ë°˜\\',\\'ì•ë°˜\\'],m=\\'ì‹¤ë‚´ì˜¨ë„\\')\", \"v_í˜„ì¬_ì‹¤ë‚´ì˜¨ë„_ìµœê³  = v_í˜„ì¬_ë°©ë³„_ì‹¤ë‚´ì˜¨ë„_df[\\'ì‹¤ë‚´ì˜¨ë„\\'].max()\", \"v_í˜„ì¬_ì‹¤ë‚´ì˜¨ë„_ìµœê³ _df = v_í˜„ì¬_ë°©ë³„_ì‹¤ë‚´ì˜¨ë„_df[v_í˜„ì¬_ë°©ë³„_ì‹¤ë‚´ì˜¨ë„_df[\\'ì‹¤ë‚´ì˜¨ë„\\'] == v_í˜„ì¬_ì‹¤ë‚´ì˜¨ë„_ìµœê³ ]\", \"v_í˜„ì¬_ì‹¤ë‚´ì˜¨ë„_ìµœê³ _ë°© = get_spatials(v_í˜„ì¬_ì‹¤ë‚´ì˜¨ë„_ìµœê³ _df)\"]}', '{\"Thinking\": \"ì‚¬ìš©ìëŠ” í˜„ì¬ 4ì¸µ ë°©ë“¤ì˜ ì‹¤ë‚´ì˜¨ë„ í‰ê· ì„ ì•Œê³  ì‹¶ì–´í•¨. í˜„ì¬ 4ì¸µ ë°©ë“¤ì˜ ì‹¤ë‚´ì˜¨ë„ ë°ì´í„°ë¥¼ ì¿¼ë¦¬í•œ í›„ í‰ê· ê°’ì„ ê³„ì‚°í•˜ë©´ ë¨.\", \"Expectations\": [\"ì§€ê¸ˆ 4ì¸µ í‰ê·  ì‹¤ë‚´ì˜¨ë„ëŠ” {{í˜„ì¬_4ì¸µ_ì‹¤ë‚´ì˜¨ë„_í‰ê· }}â„ƒì…ë‹ˆë‹¤.\"], \"Mapping\": {\"temporal\": {\"í˜„ì¬\": \"LAST_RECORD\"}, \"spatials\": {\"4ì¸µ\": [\"02_I81\", \"01_IB5\", \"01_IB7\"]}, \"modalities\": {\"ì‹¤ë‚´ì˜¨ë„\": \"roomtemp\"}}, \"Script\": [\"v_í˜„ì¬_4ì¸µ_ì‹¤ë‚´ì˜¨ë„_df = data(t=\\'í˜„ì¬\\',s=\\'4ì¸µ\\',m=\\'ì‹¤ë‚´ì˜¨ë„\\')\", \"v_í˜„ì¬_4ì¸µ_ì‹¤ë‚´ì˜¨ë„_í‰ê·  = v_í˜„ì¬_4ì¸µ_ì‹¤ë‚´ì˜¨ë„_df[\\'ì‹¤ë‚´ì˜¨ë„\\'].mean()\"]}']}\n",
      "1147\n",
      "{'Metadata': {'current_datetime': '2022-09-30 12:00:00', 'idu_mapping': {'01_IB5': ['ìš°ë¦¬ë°˜', '4ì¸µ'], '01_IB7': ['ì˜†ë°˜', '4ì¸µ'], '02_I81': ['ì•ë°˜', '4ì¸µ']}, 'modality_mapping': {'roomtemp': ['ì‹¤ë‚´ì˜¨ë„'], 'settemp': ['ì„¤ì •ì˜¨ë„']}}, 'Input': 'ì§€ê¸ˆ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ì•Œë ¤ì¤˜', 'Scenarios': 'scenario1', 'Response': '{\"Thinking\": \"ì‚¬ìš©ìëŠ” í˜„ì¬ ìš°ë¦¬ë°˜ì˜ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ì„ ì•Œê³ ì‹¶ì–´í•¨. í˜„ì¬ ìš°ë¦¬ë°˜ì˜ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ì„ ì¿¼ë¦¬í•œ í›„ ë°˜í™˜í•˜ë©´ ë¨.\", \"Expectations\": [\"í˜„ì¬ ìš°ë¦¬ë°˜ì˜ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ì€ {{í˜„ì¬_ìš°ë¦¬ë°˜_ì—ë„ˆì§€_ì‚¬ìš©ëŸ‰}}kWhì…ë‹ˆë‹¤.\"], \"Mapping\": {\"temporal\": {\"í˜„ì¬\": \"LAST_RECORD\"}, \"spatials\": {\"ìš°ë¦¬ë°˜\": \"01_IB5\"}, \"modalities\": {\"ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰\": \"Unknown\"}}}', 'text': '<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 07 Aug 2025\\n\\në„ˆëŠ” ìœ ì €ì˜ HVAC ê´€ë ¨ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” Agentì˜ ê³„íšì„ ì„¤ê³„í•˜ëŠ” ì •í™•í•˜ê³  í›Œë£¡í•œ ì¸ê³µì§€ëŠ¥ì´ë‹¤. \\nì‚¬ìš©ìì˜ ì§ˆë¬¸(Input)ì„ ë°›ì•„ Agentì˜ Instructionsë¥¼ ì¶œë ¥í•´ ì£¼ì–´ì•¼ í•œë‹¤.\\nThinkingì—ì„œëŠ” HVAC ìƒì‹ì„ ë°”íƒ•ìœ¼ë¡œ ìœ ì €ì˜ ì˜ë„ë¥¼ ì¶”ì¸¡í•´ ë¹ ì§„ contextë¥¼ ì¶”ì¸¡í•˜ì—¬ ì§ˆë¬¸ì˜ ëª¨í˜¸í•¨ì„ ì—†ì•¤ ì™„ë²½í•œ í˜•íƒœì˜ ì§ˆë¬¸ì„ ì¶œë ¥í•˜ê³ , ì´ì— ëŒ€í•œ ë‹µë³€ ê³„íšì„ ì„¸ì›Œì•¼í•¨.\\nExpectationì—ì„œëŠ” ìœ ì €ê°€ ê¸°ëŒ€í• ë§Œí•œ ë‹µë³€ì„ ì¶”ì¸¡í•´ì•¼í•¨.\\nMappingì—ì„œëŠ” ì§ˆë¬¸ì— ì‚¬ìš©ëœ high-level taxonomyë¥¼ metadataë¥¼ ë°”íƒ•ìœ¼ë¡œ low-level taxonomyë¡œì˜ mappingì„ ê³„ì‚°í•˜ì—¬ì•¼ í•¨.\\nì´ë•Œ metadataì— ì—†ëŠ” ì •ë³´ë¥¼ ê¸°ìˆ í•˜ëŠ” ë“± ê±°ì§“ëœ ì¶œë ¥ì„ í•˜ë©´ ì•ˆë˜ê³ , ëª¨ë¥´ëŠ” ì •ë³´ê°€ ìˆìœ¼ë©´ Unknownì´ë¼ ë‹µë³€í•´ì•¼í•¨.\\nScriptì—ì„œëŠ” data í•¨ìˆ˜ë¥¼ ì´ìš©í•˜ì—¬ pandas dataframe í˜•ì‹ì˜ ë°ì´í„°ë¥¼ ì¿¼ë¦¬í•˜ì—¬ ë‹µë³€ì— í•„ìš”í•œ ì—°ì‚°ì„ python ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì§œ ìˆ˜í–‰í•œë‹¤. ì´ë•Œ ì‹¤í–‰ ì—ëŸ¬ì— ì¡°ì‹¬í•œë‹¤. python\\nExpectationì˜ ëª…ì‹œëœ ëª¨ë“  variableì´ scriptì—ì„œ ê³„ì‚°ë˜ì•¼ í•œë‹¤.\\njsoní˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ë©°, eval() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ê´„í˜¸ë“¤ê³¼ ë”°ì˜´í‘œë“¤ì˜ ìˆœì„œì™€ ë‹«í˜ì„ ë§¤ìš° ì‹ ê²½ì¨ì„œ ì¶œë ¥í•´ì•¼í•œë‹¤.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nMetadata:{\\'current_datetime\\': \\'2022-09-30 12:00:00\\', \\'idu_mapping\\': {\\'01_IB5\\': [\\'ìš°ë¦¬ë°˜\\', \\'4ì¸µ\\'], \\'01_IB7\\': [\\'ì˜†ë°˜\\', \\'4ì¸µ\\'], \\'02_I81\\': [\\'ì•ë°˜\\', \\'4ì¸µ\\']}, \\'modality_mapping\\': {\\'roomtemp\\': [\\'ì‹¤ë‚´ì˜¨ë„\\'], \\'settemp\\': [\\'ì„¤ì •ì˜¨ë„\\']}};Input:ì§€ê¸ˆ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ì•Œë ¤ì¤˜;<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n{\"Thinking\": \"ì‚¬ìš©ìëŠ” í˜„ì¬ ìš°ë¦¬ë°˜ì˜ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ì„ ì•Œê³ ì‹¶ì–´í•¨. í˜„ì¬ ìš°ë¦¬ë°˜ì˜ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ì„ ì¿¼ë¦¬í•œ í›„ ë°˜í™˜í•˜ë©´ ë¨.\", \"Expectations\": [\"í˜„ì¬ ìš°ë¦¬ë°˜ì˜ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ì€ {{í˜„ì¬_ìš°ë¦¬ë°˜_ì—ë„ˆì§€_ì‚¬ìš©ëŸ‰}}kWhì…ë‹ˆë‹¤.\"], \"Mapping\": {\"temporal\": {\"í˜„ì¬\": \"LAST_RECORD\"}, \"spatials\": {\"ìš°ë¦¬ë°˜\": \"01_IB5\"}, \"modalities\": {\"ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰\": \"Unknown\"}}}<|eot_id|>', 'input': [{'content': 'ë„ˆëŠ” ìœ ì €ì˜ HVAC ê´€ë ¨ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” Agentì˜ ê³„íšì„ ì„¤ê³„í•˜ëŠ” ì •í™•í•˜ê³  í›Œë£¡í•œ ì¸ê³µì§€ëŠ¥ì´ë‹¤. \\nì‚¬ìš©ìì˜ ì§ˆë¬¸(Input)ì„ ë°›ì•„ Agentì˜ Instructionsë¥¼ ì¶œë ¥í•´ ì£¼ì–´ì•¼ í•œë‹¤.\\nThinkingì—ì„œëŠ” HVAC ìƒì‹ì„ ë°”íƒ•ìœ¼ë¡œ ìœ ì €ì˜ ì˜ë„ë¥¼ ì¶”ì¸¡í•´ ë¹ ì§„ contextë¥¼ ì¶”ì¸¡í•˜ì—¬ ì§ˆë¬¸ì˜ ëª¨í˜¸í•¨ì„ ì—†ì•¤ ì™„ë²½í•œ í˜•íƒœì˜ ì§ˆë¬¸ì„ ì¶œë ¥í•˜ê³ , ì´ì— ëŒ€í•œ ë‹µë³€ ê³„íšì„ ì„¸ì›Œì•¼í•¨.\\nExpectationì—ì„œëŠ” ìœ ì €ê°€ ê¸°ëŒ€í• ë§Œí•œ ë‹µë³€ì„ ì¶”ì¸¡í•´ì•¼í•¨.\\nMappingì—ì„œëŠ” ì§ˆë¬¸ì— ì‚¬ìš©ëœ high-level taxonomyë¥¼ metadataë¥¼ ë°”íƒ•ìœ¼ë¡œ low-level taxonomyë¡œì˜ mappingì„ ê³„ì‚°í•˜ì—¬ì•¼ í•¨.\\nì´ë•Œ metadataì— ì—†ëŠ” ì •ë³´ë¥¼ ê¸°ìˆ í•˜ëŠ” ë“± ê±°ì§“ëœ ì¶œë ¥ì„ í•˜ë©´ ì•ˆë˜ê³ , ëª¨ë¥´ëŠ” ì •ë³´ê°€ ìˆìœ¼ë©´ Unknownì´ë¼ ë‹µë³€í•´ì•¼í•¨.\\nScriptì—ì„œëŠ” data í•¨ìˆ˜ë¥¼ ì´ìš©í•˜ì—¬ pandas dataframe í˜•ì‹ì˜ ë°ì´í„°ë¥¼ ì¿¼ë¦¬í•˜ì—¬ ë‹µë³€ì— í•„ìš”í•œ ì—°ì‚°ì„ python ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì§œ ìˆ˜í–‰í•œë‹¤. ì´ë•Œ ì‹¤í–‰ ì—ëŸ¬ì— ì¡°ì‹¬í•œë‹¤. python\\nExpectationì˜ ëª…ì‹œëœ ëª¨ë“  variableì´ scriptì—ì„œ ê³„ì‚°ë˜ì•¼ í•œë‹¤.\\njsoní˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ë©°, eval() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ê´„í˜¸ë“¤ê³¼ ë”°ì˜´í‘œë“¤ì˜ ìˆœì„œì™€ ë‹«í˜ì„ ë§¤ìš° ì‹ ê²½ì¨ì„œ ì¶œë ¥í•´ì•¼í•œë‹¤.', 'role': 'system'}, {'content': \"Metadata:{'current_datetime': '2022-09-30 12:00:00', 'idu_mapping': {'01_IB5': ['ìš°ë¦¬ë°˜', '4ì¸µ'], '01_IB7': ['ì˜†ë°˜', '4ì¸µ'], '02_I81': ['ì•ë°˜', '4ì¸µ']}, 'modality_mapping': {'roomtemp': ['ì‹¤ë‚´ì˜¨ë„'], 'settemp': ['ì„¤ì •ì˜¨ë„']}};Input:ì§€ê¸ˆ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ì•Œë ¤ì¤˜;\", 'role': 'user'}]}\n",
      "27 12\n",
      "Gradient Accumulation Steps: 1\n",
      "27\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b29f51a01b42431f828ce49dfa4de9c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"]:   0%|          | 0/27 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 27 | Num Epochs = 55 | Total steps = 55\n",
      "O^O/ \\_/ \\    Batch size per device = 60 | Gradient accumulation steps = 1\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (60 x 1 x 1) = 60\n",
      " \"-____-\"     Trainable parameters = 320,638,976 of 3,533,388,800 (9.07% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='55' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/55 10:46 < 13:01, 0.04 it/s, Epoch 25/55]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.889700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.889700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.992400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.336400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.852000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.503300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.290700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.181900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.141500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.118000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.103600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.090900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.080300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.070600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.061700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.053000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.045000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.035300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.031000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.026900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.025700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.021800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.020800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.017800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m model_ids = [\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m# 'sh2orc/Llama-3.1-Korean-8B-Instruct',\u001b[39;00m\n\u001b[32m      3\u001b[39m     \u001b[38;5;66;03m# 'Bllossom/llama-3.2-Korean-Bllossom-AICA-5B',\u001b[39;00m\n\u001b[32m      4\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mBllossom/llama-3.2-Korean-Bllossom-3B\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      5\u001b[39m ]\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m60\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m55\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlora_r\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m211\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 138\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(model_id, per_device_train_batch_size, epochs, lora_r)\u001b[39m\n\u001b[32m    111\u001b[39m custom_callback = CustomCallback(\n\u001b[32m    112\u001b[39m     tokenizer=tokenizer,\n\u001b[32m    113\u001b[39m     model=peft_model,\n\u001b[32m   (...)\u001b[39m\u001b[32m    119\u001b[39m     max_new_tokens=\u001b[32m1280\u001b[39m\n\u001b[32m    120\u001b[39m )\n\u001b[32m    123\u001b[39m trainer = SFTTrainer(\n\u001b[32m    124\u001b[39m     model = peft_model,\n\u001b[32m    125\u001b[39m     processing_class = tokenizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    134\u001b[39m     callbacks = [custom_callback]\n\u001b[32m    135\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m trainer_stats = \u001b[43munsloth_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/main/lib/python3.12/site-packages/unsloth/trainer.py:45\u001b[39m, in \u001b[36munsloth_train\u001b[39m\u001b[34m(trainer, *args, **kwargs)\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34munsloth_train\u001b[39m(trainer, *args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/main/lib/python3.12/site-packages/transformers/trainer.py:2238\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2236\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2237\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2238\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2239\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2240\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2241\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2242\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2243\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:407\u001b[39m, in \u001b[36m_fast_inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/main/lib/python3.12/site-packages/transformers/trainer.py:3133\u001b[39m, in \u001b[36mTrainer._maybe_log_save_evaluate\u001b[39m\u001b[34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate)\u001b[39m\n\u001b[32m   3130\u001b[39m     \u001b[38;5;28mself\u001b[39m._globalstep_last_logged = \u001b[38;5;28mself\u001b[39m.state.global_step\n\u001b[32m   3131\u001b[39m     \u001b[38;5;28mself\u001b[39m.store_flos()\n\u001b[32m-> \u001b[39m\u001b[32m3133\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3135\u001b[39m metrics = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   3136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.control.should_evaluate:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/LGHVAC_2ndyear/src/unsloth_compiled_cache/UnslothSFTTrainer.py:939\u001b[39m, in \u001b[36m_UnslothSFTTrainer.log\u001b[39m\u001b[34m(self, logs, start_time)\u001b[39m\n\u001b[32m    936\u001b[39m     metrics = {\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33meval_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m: val \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m metrics.items()}\n\u001b[32m    938\u001b[39m logs = {**logs, **metrics}\n\u001b[32m--> \u001b[39m\u001b[32m939\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[38;5;28mself\u001b[39m._metrics[mode].clear()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/main/lib/python3.12/site-packages/transformers/trainer.py:3700\u001b[39m, in \u001b[36mTrainer.log\u001b[39m\u001b[34m(self, logs, start_time)\u001b[39m\n\u001b[32m   3698\u001b[39m output = {**logs, **{\u001b[33m\"\u001b[39m\u001b[33mstep\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.state.global_step}}\n\u001b[32m   3699\u001b[39m \u001b[38;5;28mself\u001b[39m.state.log_history.append(output)\n\u001b[32m-> \u001b[39m\u001b[32m3700\u001b[39m \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallback_handler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mon_log\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/main/lib/python3.12/site-packages/transformers/trainer_callback.py:549\u001b[39m, in \u001b[36mCallbackHandler.on_log\u001b[39m\u001b[34m(self, args, state, control, logs)\u001b[39m\n\u001b[32m    547\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mon_log\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: TrainingArguments, state: TrainerState, control: TrainerControl, logs):\n\u001b[32m    548\u001b[39m     control.should_log = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_event\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mon_log\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/main/lib/python3.12/site-packages/transformers/trainer_callback.py:556\u001b[39m, in \u001b[36mCallbackHandler.call_event\u001b[39m\u001b[34m(self, event, args, state, control, **kwargs)\u001b[39m\n\u001b[32m    554\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_event\u001b[39m(\u001b[38;5;28mself\u001b[39m, event, args, state, control, **kwargs):\n\u001b[32m    555\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.callbacks:\n\u001b[32m--> \u001b[39m\u001b[32m556\u001b[39m         result = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[43m            \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    558\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    560\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    561\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprocessing_class\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprocessing_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m            \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    565\u001b[39m \u001b[43m            \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    568\u001b[39m         \u001b[38;5;66;03m# A Callback can skip the return of `control` if it doesn't change it.\u001b[39;00m\n\u001b[32m    569\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 87\u001b[39m, in \u001b[36mCustomCallback.on_log\u001b[39m\u001b[34m(self, args, state, control, logs, **kwargs)\u001b[39m\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m     86\u001b[39m     FastLanguageModel.for_inference(\u001b[38;5;28mself\u001b[39m.model)\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbatch_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m decoded = \u001b[38;5;28mself\u001b[39m.tokenizer.batch_decode(\n\u001b[32m     95\u001b[39m     outputs, \n\u001b[32m     96\u001b[39m     skip_special_tokens=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     97\u001b[39m )\n\u001b[32m     99\u001b[39m \u001b[38;5;66;03m# Save to file\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/main/lib/python3.12/site-packages/peft/peft_model.py:1973\u001b[39m, in \u001b[36mPeftModelForCausalLM.generate\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1971\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._enable_peft_forward_hooks(*args, **kwargs):\n\u001b[32m   1972\u001b[39m         kwargs = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.special_peft_forward_args}\n\u001b[32m-> \u001b[39m\u001b[32m1973\u001b[39m         outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1974\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1975\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m.base_model.generate(**kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/main/lib/python3.12/site-packages/unsloth/models/llama.py:1740\u001b[39m, in \u001b[36munsloth_fast_generate\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1738\u001b[39m \u001b[38;5;66;03m# Mixed precision autocast\u001b[39;00m\n\u001b[32m   1739\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.inference_mode(), torch.autocast(device_type = DEVICE_TYPE, dtype = dtype):\n\u001b[32m-> \u001b[39m\u001b[32m1740\u001b[39m     output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_old_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1741\u001b[39m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# Return accelerate back\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;66;03m# if accelerate_new_send_to_device is not None:\u001b[39;00m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m#     accelerate.utils.operations.send_to_device = accelerate_old_send_to_device\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# pass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/main/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/main/lib/python3.12/site-packages/transformers/generation/utils.py:2634\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2626\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2627\u001b[39m         input_ids=input_ids,\n\u001b[32m   2628\u001b[39m         expand_size=generation_config.num_return_sequences,\n\u001b[32m   2629\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2630\u001b[39m         **model_kwargs,\n\u001b[32m   2631\u001b[39m     )\n\u001b[32m   2633\u001b[39m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2634\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2635\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2636\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2637\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2638\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2639\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2640\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2641\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2642\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2644\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2645\u001b[39m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[32m   2646\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2647\u001b[39m         input_ids=input_ids,\n\u001b[32m   2648\u001b[39m         expand_size=generation_config.num_beams,\n\u001b[32m   2649\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2650\u001b[39m         **model_kwargs,\n\u001b[32m   2651\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/main/lib/python3.12/site-packages/transformers/generation/utils.py:3618\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   3616\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   3617\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3618\u001b[39m     outputs = \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   3620\u001b[39m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[32m   3621\u001b[39m model_kwargs = \u001b[38;5;28mself\u001b[39m._update_model_kwargs_for_generation(\n\u001b[32m   3622\u001b[39m     outputs,\n\u001b[32m   3623\u001b[39m     model_kwargs,\n\u001b[32m   3624\u001b[39m     is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   3625\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/main/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/main/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/main/lib/python3.12/site-packages/unsloth/models/llama.py:1125\u001b[39m, in \u001b[36mCausalLM_fast_forward.<locals>._CausalLM_fast_forward\u001b[39m\u001b[34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, num_logits_to_keep, logits_to_keep, *args, **kwargs)\u001b[39m\n\u001b[32m   1107\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_CausalLM_fast_forward\u001b[39m(\n\u001b[32m   1108\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1109\u001b[39m     input_ids: torch.LongTensor = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1122\u001b[39m     *args, **kwargs,\n\u001b[32m   1123\u001b[39m ) -> Union[Tuple, CausalLMOutputWithPast]:\n\u001b[32m   1124\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m past_key_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1125\u001b[39m         outputs = \u001b[43mfast_forward_inference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1126\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1127\u001b[39m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1128\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1129\u001b[39m \u001b[43m            \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1130\u001b[39m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1131\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1132\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1133\u001b[39m         causal_mask = xformers.attn_bias.LowerTriangularMask() \u001b[38;5;28;01mif\u001b[39;00m HAS_XFORMERS \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/main/lib/python3.12/site-packages/unsloth/models/llama.py:1058\u001b[39m, in \u001b[36m_LlamaModel_fast_forward_inference.<locals>.LlamaModel_fast_forward_inference_custom\u001b[39m\u001b[34m(self, input_ids, past_key_values, position_ids, attention_mask)\u001b[39m\n\u001b[32m   1050\u001b[39m residual.copy_(X) \u001b[38;5;66;03m# residual = X\u001b[39;00m\n\u001b[32m   1051\u001b[39m X = fast_rms_layernorm_inference(\n\u001b[32m   1052\u001b[39m     decoder_layer.input_layernorm,\n\u001b[32m   1053\u001b[39m     X,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1056\u001b[39m     variance = variance,\n\u001b[32m   1057\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1058\u001b[39m X, present_key_value = \u001b[43mattention_fast_forward_inference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1059\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1060\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1061\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1062\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1063\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1064\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdo_prefill\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpaged_attention\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1065\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1066\u001b[39m X += residual\n\u001b[32m   1068\u001b[39m residual.copy_(X) \u001b[38;5;66;03m# residual = X\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/venv/main/lib/python3.12/site-packages/unsloth/models/llama.py:347\u001b[39m, in \u001b[36mLlamaAttention_fast_forward_inference\u001b[39m\u001b[34m(self, hidden_states, past_key_value, position_ids, do_prefill, attention_mask)\u001b[39m\n\u001b[32m    345\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    346\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m SDPA_HAS_GQA:\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m         A = \u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mKnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mVnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable_gqa\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    348\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    349\u001b[39m         A = scaled_dot_product_attention(Qn, Knn, Vnn, attn_mask = attention_mask, is_causal = is_causal)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model_ids = [\n",
    "    # 'sh2orc/Llama-3.1-Korean-8B-Instruct',\n",
    "    # 'Bllossom/llama-3.2-Korean-Bllossom-AICA-5B',\n",
    "    'Bllossom/llama-3.2-Korean-Bllossom-3B'\n",
    "]\n",
    "\n",
    "load_model(model_ids[0], per_device_train_batch_size=60, epochs=55, lora_r=211)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
