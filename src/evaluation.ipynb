{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:datasets:PyTorch version 2.6.0 available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory of src to the path\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src.db.manager import DBManager\n",
    "from src.input_to_instructions.load_and_execute import *\n",
    "from src.input_to_instructions.types import *\n",
    "from src.plot_graph.execute import *\n",
    "from src.operation.execute import *\n",
    "from src.response_generation.load_and_execute import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:db.instance:Connected to the database PerSite_DB\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "import json\n",
    "import itertools\n",
    "\n",
    "from db.manager import DBManager\n",
    "from operation.execute import OperationExecutor\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import datetime\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"../\"\n",
    "def read_json(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        result = json.loads(f.read())\n",
    "    \n",
    "    # result = [{\"Input\": d[\"Input\"], \"Response\": json.dumps(d[\"Response\"], ensure_ascii=False)} for d in result]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.50.3.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 3090. Num GPUs = 2. Max memory: 23.689 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = True]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3754e1aba9b44c0ab119f8087d11bff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sh2orc/Llama-3.1-Korean-8B-Instruct does not have a padding token! Will use pad_token = <|finetune_right_pad_id|>.\n"
     ]
    }
   ],
   "source": [
    "ResponseGeneration.initialize(\n",
    "    log_output=False,\n",
    "    instance_type=\"unsloth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def summarize_variables_to_report(variables):\n",
    "#     for k, v in variables.items():\n",
    "#         if isinstance(v, pd.DataFrame):\n",
    "            \n",
    "#         elif isinstance(v, np.ndarray):\n",
    "#             variables[k] = v.tolist()\n",
    "#     return variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "from src.input_to_instructions.types import InstructionQ_raw, InstructionQ_v2\n",
    "from src.plot_graph.execute import plot_graph_plotly\n",
    "matplotlib.rcParams['font.family'] = 'NanumGothicCoding'\n",
    "\n",
    "def get_time(df, fmt=\"datetime\"):\n",
    "    # from df get 'timestamp' column and return them in format\n",
    "    if fmt == \"date\":\n",
    "        fmt = '%Y-%m-%d'\n",
    "    elif fmt == \"month\":\n",
    "        fmt = '%Y-%m'\n",
    "    elif fmt == \"year\":\n",
    "        fmt = '%Y'\n",
    "    else:\n",
    "        fmt = '%Y-%m-%d %H:%M:%S'\n",
    "    \n",
    "    if isinstance(df['timestamp'], pd.Timestamp):\n",
    "        result = df['timestamp'].strftime(fmt)\n",
    "    else:\n",
    "        result = df['timestamp'].apply(lambda x: x.strftime(fmt))\n",
    "    return set(result)\n",
    "\n",
    "def get_spatials(df):\n",
    "    return pd.unique(df['idu_name'])\n",
    "\n",
    "def get_tv(df, col:str|list[str], fmt=\"datetime\"):\n",
    "    if isinstance(col, str):\n",
    "        col = [col]\n",
    "    \n",
    "    timestamps = get_time(df, fmt)\n",
    "    return_tuple = tuple([timestamps] + [df[c] for c in col])\n",
    "    return return_tuple\n",
    "\n",
    "def data(metadata, mapping, query_results, t=str|list[str], s=str|list[str], m=str|list[str]):\n",
    "    if isinstance(t, str):\n",
    "        t = [t]\n",
    "    if isinstance(s, str):\n",
    "        s = [s]\n",
    "    if isinstance(m, str):\n",
    "        m = [m]\n",
    "\n",
    "    t_raw = [mapping.temporal[t_highlevel] for t_highlevel in t]\n",
    "    s_raw = [mapping.spatials[s_highlevel] for s_highlevel in s]\n",
    "    m_raw = [mapping.modalities[m_highlevel] for m_highlevel in m]\n",
    "\n",
    "    result_df = DBManager.structured_query_data_t_v2(metadata, m_raw, t_raw, s_raw, get_rowids=True)\n",
    "\n",
    "    cols = list(result_df.columns)\n",
    "    cols.remove(\"id\")\n",
    "    cols.remove(\"idu_name\")\n",
    "    cols.remove(\"timestamp\")\n",
    "    rows = list(result_df[\"id\"])\n",
    "    query_results.append({\n",
    "        \"result_columns\": cols,\n",
    "        \"result_indices\": rows,\n",
    "    })\n",
    "\n",
    "    # For demo, drop rows where any value is -1\n",
    "    result_df = result_df.loc[(result_df != -1).all(axis=1)]\n",
    "\n",
    "    # drop \"id\" from result_df\n",
    "    result_df = result_df.drop(columns=['id'])\n",
    "\n",
    "    # change column names to high level\n",
    "    inverse_mapping = {v: k for k, v in mapping.modalities.items()}\n",
    "    result_df.columns = [inverse_mapping[col] if col in inverse_mapping else col for col in result_df.columns]\n",
    "\n",
    "    # change idu_name raw values to high level\n",
    "    inverse_mapping = {v: k for k, v in mapping.spatials.items()}\n",
    "    result_df[\"idu_name\"] = result_df[\"idu_name\"].map(inverse_mapping)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "\n",
    "def run_query_v2(user_input, metadata, instructions):\n",
    "    instruction_q:InstructionQ_v2 = [i for i in instructions if isinstance(i, InstructionQ_v2)][0]\n",
    "    mapping = instruction_q\n",
    "    \n",
    "    instruction_o:InstructionO = [i for i in instructions if isinstance(i, InstructionO)]\n",
    "    query_results = []\n",
    "    if len(instruction_o) != 0:\n",
    "        instruction_o = instruction_o[0]\n",
    "        scripts = instruction_o.scripts\n",
    "\n",
    "        # search data(t=~~, ...,)\n",
    "        globals()['metadata'] = metadata\n",
    "        globals()['mapping'] = mapping\n",
    "        globals()['query_results'] = query_results\n",
    "        for script in scripts:\n",
    "            \n",
    "            if \"data\" in script:\n",
    "                script = script.replace(\"data(\", \"data(metadata, mapping, query_results, \")\n",
    "            exec(script, globals())\n",
    "        \n",
    "        variables = {name:globals()[name] for name in globals() if name.startswith(\"v_\")}\n",
    "        instruction_r:InstructionR = [i for i in instructions if isinstance(i, InstructionR)][0]\n",
    "    else:\n",
    "        variables = {}\n",
    "        unknown_spatials = [k for k, v in mapping.spatials.items() if v == \"Unknown\"]\n",
    "        unknown_modalities = [k for k, v in mapping.modalities.items() if v == \"Unknown\"]\n",
    "        \n",
    "        response_unknown = f\"Ï£ÑÏÜ°Ìï©ÎãàÎã§, {unknown_spatials + unknown_modalities}Îäî Ï°¥Ïû¨ÌïòÏßÄ ÏïäÎäî Í≥µÍ∞ÑÏù¥ÎÇò Î™®Îã¨Î¶¨Ìã∞ ÏûÖÎãàÎã§.\"\n",
    "        return response_unknown, variables, [], query_results\n",
    "\n",
    "\n",
    "    response, required_variables = ResponseGeneration.execute(instruction_r, variables, user_input, None, exp_tag=None)\n",
    "    return response, variables, required_variables, query_results\n",
    "\n",
    "\n",
    "def run_query(user_input, metadata, instructions, exp_tag=None):\n",
    "    variables = {\n",
    "        \"Metadata\": metadata,\n",
    "    }\n",
    "    query_results = []\n",
    "        \n",
    "    \n",
    "    for instruction in instructions:\n",
    "        # logger.debug(f\"Executing instruction: {instruction.__class__.__name__}\")\n",
    "        # print(f\"Executing instruction: {instruction.__class__.__name__}\")\n",
    "        \n",
    "        if type(instruction) == InstructionQ:\n",
    "            # Execute query\n",
    "            result_df = DBManager.structured_query_data_t(metadata, instruction.args, get_rowids=True)\n",
    "            # if result_df is None:\n",
    "                # print(\"Ï£ÑÏÜ°Ìï©ÎãàÎã§, Í¥ÄÎ†® Îç∞Ïù¥ÌÑ∞Î•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.\", \"response\")\n",
    "                # return\n",
    "\n",
    "            cols = list(result_df.columns)\n",
    "            cols.remove(\"id\")\n",
    "            cols.remove(\"idu\")\n",
    "            rows = list(result_df[\"id\"])\n",
    "\n",
    "            query_results.append({\n",
    "                \"result_columns\": cols,\n",
    "                \"result_indices\": rows,\n",
    "            })\n",
    "\n",
    "            # For demo, drop rows where any value is -1\n",
    "            result_df = result_df.loc[(result_df != -1).all(axis=1)]\n",
    "\n",
    "            # drop \"id\" from result_df\n",
    "            result_df = result_df.drop(columns=['id'])\n",
    "           \n",
    "            #pd.set_option('display.max_rows', 10000)        \n",
    "            #pd.set_option('display.max_columns', 1000)\n",
    "            #pd.set_option('display.width', 1000)\n",
    "            #pd.set_option('display.max_colwidth', 1000)\n",
    "            #print(f\"QueryResult: {result_df}\")\n",
    "\n",
    "            variables[instruction.result_name] = result_df\n",
    "        elif type(instruction) == InstructionQ_raw:\n",
    "            instruction.query = instruction.query.replace(\" FROM \\\"data_t\\\"\", \", \\\"id\\\" FROM \\\"data_t\\\"\")\n",
    "            result_df = DBManager.execute_structured_query_string(\n",
    "                instruction.query\n",
    "            )\n",
    "            # rename idu_name to idu\n",
    "            result_df = result_df.rename(columns={'idu_name': 'idu'})\n",
    "            \n",
    "            cols = list(result_df.columns)\n",
    "            cols.remove(\"id\")\n",
    "            cols.remove(\"idu\")\n",
    "            rows = list(result_df[\"id\"])\n",
    "\n",
    "            query_results.append({\n",
    "                \"result_columns\": cols,\n",
    "                \"result_indices\": rows,\n",
    "            })\n",
    "\n",
    "            # drop \"id\" from result_df\n",
    "            result_df = result_df.drop(columns=['id'])\n",
    "            \n",
    "            variables[instruction.result_name] = result_df\n",
    "            # print(result_df, flush=True)\n",
    "\n",
    "        elif type(instruction) == InstructionO:\n",
    "            # Execute operation\n",
    "            # variables_to_report = {k: v for k, v in variables.items() if k not in [\"Metadata\"]}\n",
    "            # print(variables_to_report)\n",
    "            result_dict = OperationExecutor.execute(variables, instruction.scripts)\n",
    "            # print(instruction.scripts, instruction.returns, result_dict)\n",
    "            variables.update(result_dict)\n",
    "            pass\n",
    "            # print(fig, \"graph\")\n",
    "        elif type(instruction) == InstructionR:\n",
    "            # Execute response generation\n",
    "            variables_to_report = {k: v for k, v in variables.items() if k not in [\"Metadata\"]}\n",
    "            # print(variables_to_report)\n",
    "            # variables_to_report = ResponseGeneration.stringify_variables(variables_to_report)\n",
    "            # variables_to_report = summarize_variables_to_report(variables_to_report)\n",
    "\n",
    "            # print(f\"Variables: {variables_to_report}\")\n",
    "\n",
    "            keys_to_leave = [\"modality_mapping\", \"idu_mapping\"]\n",
    "            metadata_ = {}\n",
    "            for key in metadata.keys():\n",
    "                if key in keys_to_leave:\n",
    "                    metadata_[key] = metadata[key]\n",
    "\n",
    "            response, required_variables = ResponseGeneration.execute(instruction, variables, user_input, metadata_, exp_tag=exp_tag)\n",
    "            # print(f\"Required variables: {required_variables}\")\n",
    "            \n",
    "            # response = instruction.expectations[0] # \"{{var}}...\"\n",
    "            # for var_name, var_value in required_variables.items():\n",
    "            #     placeholder = f\"{{{{{var_name}}}}}\"\n",
    "            #     if placeholder in response:\n",
    "            #         response = response.replace(placeholder, str(var_value))\n",
    "\n",
    "            \n",
    "            return response, variables_to_report, required_variables, query_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "def build_query_groundtruth():\n",
    "    dataset_name = \"v7-250309-reduceinputanddatefunctioncall\"\n",
    "    def read(path):\n",
    "        data = read_json(path)\n",
    "        for i, d in enumerate(data):\n",
    "            data[i][\"Scenario\"] = directory.name\n",
    "            if \"v7\" in dataset_name:\n",
    "                data[i][\"Metadata\"] = metadata\n",
    "        return data\n",
    "\n",
    "    ds_ts = []\n",
    "    base_dataset_dir = Path(f\"{BASE_DIR}/finetuning/dataset/{dataset_name}\")\n",
    "    \n",
    "    for directory in base_dataset_dir.iterdir():\n",
    "        if directory.is_dir():\n",
    "            if \"v7\" in dataset_name:\n",
    "                metadata = read_json(f\"{directory}/metadata.json\")\n",
    "            \n",
    "            # d = read(f\"{directory}/onlyq_ts.json\")\n",
    "            \n",
    "            ds_ts.extend(read(f\"{directory}/onlyq_ts.json\"))\n",
    "            ds_ts.extend(read(f\"{directory}/onlyq_tr.json\"))\n",
    "            # ds_tr.extend(read(f\"{directory}/graph.json\"))\n",
    "    \n",
    "    ds = ds_ts\n",
    "    print(len(ds))\n",
    "    # if \"v7\" in dataset_name:\n",
    "    #     db_gt_filename = f\"{BASE_DIR}/experiments/db_gt_v7.json\"\n",
    "    # else:\n",
    "    #     db_gt_filename = f\"{BASE_DIR}/experiments/db_gt.json\"\n",
    "    #     metadata = None\n",
    "    \n",
    "    # with open(db_gt_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        # f.write(\"[\")\n",
    "    # with tqdm(total=len(ds)) as pbar:\n",
    "    \n",
    "    gts = []\n",
    "\n",
    "    for d in ds:\n",
    "        cont = False\n",
    "        tags = d[\"Tags\"][\"Style\"]\n",
    "        skip_tags = [\"Reason\", \"Graph\", \"Unrelated\", \"Prediction\"]\n",
    "        for st in skip_tags:\n",
    "            if st in tags:\n",
    "                cont = True\n",
    "                break\n",
    "        if cont:\n",
    "            continue\n",
    "\n",
    "        # pbar.set_description(f\"Processing {d['Input']}\")\n",
    "        # print(\"--\")\n",
    "        exp_tag = \"v2\"\n",
    "        # print(f\"Warning! exp_tag is v2\")\n",
    "        instructions = InputToInstruction.postprocess(deepcopy(d['Response']), exp_tag=exp_tag)\n",
    "        user_input, tags, metadata, scenario = d[\"Input\"], d[\"Tags\"], d[\"Metadata\"], d[\"Scenario\"]\n",
    "        # if user_input != \"ÏßÄÍ∏à Î™áÏãúÏïº?\":\n",
    "        #     continue\n",
    "\n",
    "        response, variables_to_report, required_variables, query_results = run_query_v2(user_input, metadata, instructions)\n",
    "        print(f\"Ï∂úÎ†•: {response}\")\n",
    "        # print({k: (v, type(v)) for k, v in variables_to_report.items()})\n",
    "        gts.append({\n",
    "            \"Input\": user_input,\n",
    "            \"Metadata\": metadata,\n",
    "            \"Scenario\": scenario,\n",
    "            \"Tags\": tags,\n",
    "            \"GT\": d['Response'],\n",
    "            \"Response\": response,\n",
    "            # \"RequiredVariables\": required_variables,\n",
    "            \"QueryResults\": query_results,\n",
    "            # \"VariablesToReport\": variables_to_report,\n",
    "        })\n",
    "\n",
    "    # save to json\n",
    "    with open(f\"./gts.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(gts, f, ensure_ascii=False, indent=4)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# build_query_groundtruth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EM:\n",
    "    json_structure = \"JsonStructureCorrectness\"\n",
    "    true_positive = \"QueryTruePositive\"\n",
    "    false_positive = \"QueryFalsePositive\"\n",
    "    false_negative = \"QueryFalseNegative\"\n",
    "    \n",
    "def eval_query(cand_response_filename, db_gt_filename=\"./gts.json\"):\n",
    "    db_gts = read_json(db_gt_filename)\n",
    "    cand_responses = read_json(cand_response_filename)\n",
    "    # metadata_ = read_json(f\"{BASE_DIR}/finetuning/dataset/v7-250309-reduceinputanddatefunctioncall/scenario1/metadata.json\")\n",
    "    evaluation_reports = []\n",
    "    response_reports = []\n",
    "    with tqdm(total=len(cand_responses)) as pbar:\n",
    "        for cand_response in cand_responses:\n",
    "            pbar.set_description(f\"Processing {cand_response['Input']}\")\n",
    "            input = cand_response[\"Input\"]\n",
    "            scenario = cand_response[\"Scenario\"]\n",
    "\n",
    "            # if \"Ïò§Îäò ÏïÑÏπ®Í≥º Ï†ÄÎÖÅ\" not in input:\n",
    "            #     continue\n",
    "\n",
    "            if \"Metadata\" in cand_response:\n",
    "                metadata = cand_response[\"Metadata\"]\n",
    "            else:\n",
    "                # metadata = metadata_\n",
    "                metadata = None\n",
    "            # Í¥ÄÍ≥Ñ ÏóÜÎäî ÏßàÎ¨∏Îì§ÏùÄ Í±¥ÎÑàÎõ∞Ïûê\n",
    "            gt_report = [d for d in db_gts if d[\"Input\"] == input and d[\"Scenario\"] == scenario]\n",
    "            assert len(gt_report) <= 1\n",
    "            if len(gt_report) == 0:\n",
    "                pbar.update(1)\n",
    "                continue\n",
    "\n",
    "            gt_report = gt_report[0]\n",
    "            tags = gt_report[\"Tags\"]\n",
    "            # assert gt_report[\"QueryResults\"] != []\n",
    "            # if gt_report[\"Result\"] == []:\n",
    "            #     pbar.update(1)\n",
    "            #     continue\n",
    "            \n",
    "            gt_results = [d for d in gt_report[\"QueryResults\"]]\n",
    "            gt_query_results = defaultdict(list)\n",
    "            for gt_result in gt_results:\n",
    "                for col in gt_result[\"result_columns\"]:\n",
    "                    gt_query_results[col].extend(gt_result[\"result_indices\"])\n",
    "\n",
    "            gt_total_combinations = sum(len(v) for v in gt_query_results.values())\n",
    "\n",
    "            gt_response = gt_report[\"Response\"]\n",
    "            # gt_required_variables = gt_report[\"RequiredVariables\"]\n",
    "            # gt_variables_to_report = gt_report[\"VariablesToReport\"]\n",
    "            user_input = gt_report[\"Input\"]\n",
    "\n",
    "            response_report = {\n",
    "                \"Input\": user_input,\n",
    "                \"Metadata\": metadata,\n",
    "                \"GT_Response\": gt_response,\n",
    "                # \"GT_RequiredVariables\": gt_required_variables,\n",
    "                # \"GT_VariablesToReport\": gt_variables_to_report,\n",
    "            }\n",
    "            # ---\n",
    "            \n",
    "            evaluation_report = defaultdict(lambda: None)\n",
    "            evaluation_report[\"Input\"] = input\n",
    "            evaluation_report[\"Metadata\"] = metadata\n",
    "            evaluation_report[\"Tags\"] = tags\n",
    "            \n",
    "            if isinstance(cand_response[\"Candidate\"], dict) and (\"Instruction Set\" in cand_response[\"Candidate\"] or \"ÏßÄÏãú\" in cand_response[\"Candidate\"] or \"Instructions\" in cand_response[\"Candidate\"]):\n",
    "                if \"Instruction Set\" in cand_response[\"Candidate\"]:\n",
    "                    cand_instruction_set = cand_response[\"Candidate\"][\"Instruction Set\"]\n",
    "                elif \"ÏßÄÏãú\" in cand_response[\"Candidate\"]:\n",
    "                    cand_instruction_set = cand_response[\"Candidate\"][\"ÏßÄÏãú\"]\n",
    "                elif \"Instructions\" in cand_response[\"Candidate\"]:\n",
    "                    cand_instruction_set = cand_response[\"Candidate\"][\"Instructions\"]\n",
    "\n",
    "                evaluation_report[EM.json_structure] = True\n",
    "            else:\n",
    "                evaluation_report[EM.json_structure] = False\n",
    "                try:\n",
    "                    import re\n",
    "                    # get data between \"Instruction Set\": [ and the last]\n",
    "                    cand_instruction_set = re.search(r'(?<=\"Instructions\": \\[)(.*)(?=\\])', cand_response[\"Candidate\"], re.DOTALL).group(0)\n",
    "                    # find all {\"type\": ~ }, {\"type\": ~ }, {\"type\": ~ }\n",
    "                    cand_instruction_set = re.findall(r'({\"type\".*?})', cand_instruction_set)\n",
    "                    # print(list(cand_instruction_set))\n",
    "                    cand_instruction_set = [eval(d) for d in cand_instruction_set]\n",
    "                except Exception as e:\n",
    "                    evaluation_report[EM.json_structure] = False\n",
    "                    evaluation_report[EM.true_positive] = 0\n",
    "                    evaluation_report[EM.false_positive] = 0\n",
    "                    evaluation_report[EM.false_negative] = gt_total_combinations\n",
    "\n",
    "                    print(\"Failed to parse input: \", input, cand_response[\"Candidate\"])\n",
    "                    print(e)\n",
    "                    evaluation_reports.append(evaluation_report)\n",
    "                    pbar.update(1)\n",
    "                    response_reports.append(response_report)\n",
    "                    continue\n",
    "            \n",
    "            \n",
    "            exp_tag = \\\n",
    "                \"woCoTExp\" if \"woCoTExp\" in str(cand_response_filename) else \\\n",
    "                \"woOp\" if \"woOp\" in str(cand_response_filename) else \\\n",
    "                \"woQM\" if \"woQM\" in str(cand_response_filename) else \\\n",
    "                None\n",
    "            exp_tag = \"v2\"\n",
    "            instructions = InputToInstruction.postprocess(\n",
    "                deepcopy(cand_response[\"Candidate\"]), \n",
    "                exp_tag=exp_tag\n",
    "            )\n",
    "            \n",
    "            try:\n",
    "                # response, variables_to_report, required_variables, _cand_query_results = run_query_v2(user_input, metadata, instructions, exp_tag=exp_tag)\n",
    "                response, variables_to_report, required_variables, _cand_query_results = run_query_v2(user_input, metadata, instructions)\n",
    "                print(response)\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "                evaluation_report[EM.true_positive] = 0\n",
    "                evaluation_report[EM.false_positive] = 0\n",
    "                evaluation_report[EM.false_negative] = gt_total_combinations\n",
    "                            \n",
    "                evaluation_reports.append(evaluation_report)\n",
    "\n",
    "                response_reports.append(response_report)\n",
    "                            \n",
    "                pbar.update(1)\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            # required_variables = summarize_variables_to_report(required_variables)\n",
    "            required_variables = ResponseGeneration.stringify_variables(required_variables)\n",
    "            response_report[\"PD_Response\"] = response\n",
    "            # response_report[\"PD_RequiredVariables\"] = required_variables\n",
    "            # response_report[\"PD_VariablesToReport\"] = variables_to_report\n",
    "            response_reports.append(response_report)\n",
    "\n",
    "            if len(_cand_query_results) == 0:\n",
    "                evaluation_report[EM.true_positive] = 0\n",
    "                evaluation_report[EM.false_positive] = 0\n",
    "                evaluation_report[EM.false_negative] = gt_total_combinations\n",
    "                            \n",
    "                evaluation_reports.append(evaluation_report)\n",
    "                pbar.update(1)\n",
    "                continue\n",
    "            \n",
    "            cand_query_results = defaultdict(list)\n",
    "            for cand_query_result in _cand_query_results:\n",
    "                for col in cand_query_result[\"result_columns\"]:\n",
    "                    cand_query_results[col].extend(cand_query_result[\"result_indices\"])\n",
    "\n",
    "            cand_total_combinations = sum(len(v) for v in gt_query_results.values())\n",
    "\n",
    "\n",
    "            if len(gt_results) == 0:\n",
    "                evaluation_report[EM.true_positive] = 0\n",
    "                evaluation_report[EM.false_positive] = cand_total_combinations\n",
    "                evaluation_report[EM.false_negative] = 0\n",
    "\n",
    "                evaluation_reports.append(evaluation_report)\n",
    "                pbar.update(1)\n",
    "\n",
    "                continue\n",
    "            \n",
    "            # print(gt_total_combinations, cand_total_combinations)\n",
    "            # True Positive: Í≥µÌÜµÎêú Ïª¨ÎüºÍ≥º Î°úÏö∞Ïùò Î™®Îì† Ï°∞Ìï©\n",
    "            true_positive = 0\n",
    "            false_negative = 0\n",
    "            false_positive = 0\n",
    "            for col in set(gt_query_results.keys())&set(cand_query_results.keys()):\n",
    "                s_gt_query_result = set(gt_query_results[col])\n",
    "                s_cand_query_result = set(cand_query_results[col])\n",
    "                true_positive += len(s_gt_query_result & s_cand_query_result)\n",
    "                false_negative += len(s_gt_query_result - s_cand_query_result)\n",
    "                false_positive += len(s_cand_query_result - s_gt_query_result)\n",
    "\n",
    "                # print(true_positive, false_negative, false_positive, len(s_gt_query_result), len(s_cand_query_result))\n",
    "            # assert true_positive + false_positive + false_negative == gt_total_combinations\n",
    "            \n",
    "\n",
    "            evaluation_report[EM.true_positive] = true_positive\n",
    "            evaluation_report[EM.false_positive] = false_positive\n",
    "            evaluation_report[EM.false_negative] = false_negative\n",
    "\n",
    "            evaluation_reports.append(evaluation_report)\n",
    "            # print(evaluation_report)\n",
    "            \n",
    "            pbar.update(1)\n",
    "\n",
    "    with open(f\"{cand_response_filename.replace('.json', '_response.json')}\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(response_reports, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    eval_df = pd.DataFrame(evaluation_reports)\n",
    "    # print(eval_df)\n",
    "\n",
    "    eval_df['ExactMatch'] = eval_df.apply(lambda x: x[EM.false_positive] == 0 and x[EM.false_negative] == 0, axis=1).astype(int)\n",
    "    # eval_df['TruePositive'] = eval_df['TruePositive'].astype(int)\n",
    "    # eval_df['FalsePositive'] = eval_df['FalsePositive'].astype(int)\n",
    "    # eval_df['FalseNegative'] = eval_df['FalseNegative'].astype(int)\n",
    "\n",
    "    final_result = {}\n",
    "\n",
    "    for col in [\"JsonStructureCorrectness\", \"ExactMatch\"]:\n",
    "        # print(f\"{col}: {eval_df[col].mean()}\")\n",
    "        final_result[col] = eval_df[col].mean()\n",
    "    \n",
    "    # normalize per query\n",
    "    eval_df[\"Total\"] = eval_df[EM.true_positive] + eval_df[EM.false_positive] + eval_df[EM.false_negative]\n",
    "    eval_print = eval_df.drop(columns=[\"Input\", \"Metadata\", \"Tags\"])\n",
    "    print(eval_print)\n",
    "    eval_df[EM.true_positive] = eval_df[EM.true_positive] / eval_df[\"Total\"]\n",
    "    eval_df[EM.false_positive] = eval_df[EM.false_positive] / eval_df[\"Total\"]\n",
    "    eval_df[EM.false_negative] = eval_df[EM.false_negative] / eval_df[\"Total\"]\n",
    "\n",
    "    # # replace nan with 0\n",
    "    # eval_df.fillna(0, inplace=True)\n",
    "\n",
    "    # # F1 score except nans.\n",
    "    truepos_sum, falsepos_sum, falseneg_sum = eval_df[EM.true_positive].sum(), eval_df[EM.false_positive].sum(), eval_df[EM.false_negative].sum()\n",
    "    precision = truepos_sum / (truepos_sum + falsepos_sum)\n",
    "    recall = truepos_sum / (truepos_sum + falseneg_sum)\n",
    "    print(truepos_sum, falsepos_sum, falseneg_sum)\n",
    "    print(precision, recall)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    # print(f\"F1: {f1}\")\n",
    "    final_result[\"F1\"] = f1\n",
    "    final_result[\"Recall\"] = recall\n",
    "\n",
    "    for col in final_result:\n",
    "        print(f\"{col}: {final_result[col]:.2f}\")\n",
    "    \n",
    "    return eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing ÏßÄÍ∏à ÏòÜÎ∞ò Ïò®ÎèÑÎûë Ïö∞Î¶¨Î∞ò Ïò®ÎèÑ ÏïåÎ†§Ï§ò:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÏßàÎ¨∏: ÏßÄÍ∏à ÏòÜÎ∞ò Ïò®ÎèÑÎûë Ïö∞Î¶¨Î∞ò Ïò®ÎèÑ ÏïåÎ†§Ï§ò; Ìè¨Îß∑: ['ÌòÑÏû¨ ÏòÜÎ∞òÏùò Ïã§ÎÇ¥Ïò®ÎèÑ({{v_ÌòÑÏû¨_ÏòÜÎ∞ò_Ïã§ÎÇ¥Ïò®ÎèÑ}}‚ÑÉ)Îäî Ïö∞Î¶¨Î∞òÏùò Ïã§ÎÇ¥Ïò®ÎèÑ({{v_ÌòÑÏû¨_Ïö∞Î¶¨Î∞ò_Ïã§ÎÇ¥Ïò®ÎèÑ}}‚ÑÉ)Î≥¥Îã§ {{v_ÌòÑÏû¨_ÏòÜÎ∞ò_Ïã§ÎÇ¥Ïò®ÎèÑ - ÌòÑÏû¨_Ïö∞Î¶¨Î∞ò_Ïã§ÎÇ¥Ïò®ÎèÑ}}‚ÑÉ ÎÜíÏäµÎãàÎã§.']; Îç∞Ïù¥ÌÑ∞: {'v_ÌòÑÏû¨_ÏòÜÎ∞ò_Ïã§ÎÇ¥Ïò®ÎèÑ': 0    27.0\n",
      "Name: Ïã§ÎÇ¥Ïò®ÎèÑ, dtype: float64, 'v_ÌòÑÏû¨_Ïö∞Î¶¨Î∞ò_Ïã§ÎÇ¥Ïò®ÎèÑ': 0    28.5\n",
      "Name: Ïã§ÎÇ¥Ïò®ÎèÑ, dtype: float64};\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 1ÏãúÍ∞Ñ Ï†Ñ ÏÑ§Ï†ïÏò®ÎèÑÎûë Ïã§ÎÇ¥Ïò®ÎèÑ Ï∞®Ïù¥ ÏïåÎ†§Ï§ò.:  20%|‚ñà‚ñà        | 1/5 [00:01<00:04,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÌòÑÏû¨ ÏòÜÎ∞òÏùò Ïã§ÎÇ¥Ïò®ÎèÑ(27.00‚ÑÉ)Îäî Ïö∞Î¶¨Î∞òÏùò Ïã§ÎÇ¥Ïò®ÎèÑ(28.50‚ÑÉ)Î≥¥Îã§ -1.50‚ÑÉ ÎÇÆÏäµÎãàÎã§.\n",
      "ÏßàÎ¨∏: 1ÏãúÍ∞Ñ Ï†Ñ ÏÑ§Ï†ïÏò®ÎèÑÎûë Ïã§ÎÇ¥Ïò®ÎèÑ Ï∞®Ïù¥ ÏïåÎ†§Ï§ò.; Ìè¨Îß∑: ['1ÏãúÍ∞Ñ Ï†Ñ ÏÑ§Ï†ïÏò®ÎèÑ({{v_1ÏãúÍ∞ÑÏ†Ñ_ÏÑ§Ï†ïÏò®ÎèÑ_Ïã§ÎÇ¥Ïò®ÎèÑ_Ï∞®Ïù¥}}‚ÑÉ)Îäî Ïã§ÎÇ¥Ïò®ÎèÑ({{v_1ÏãúÍ∞ÑÏ†Ñ_Ïã§ÎÇ¥Ïò®ÎèÑ}}‚ÑÉ)Î≥¥Îã§ {{v_1ÏãúÍ∞ÑÏ†Ñ_ÏÑ§Ï†ïÏò®ÎèÑ_Ïã§ÎÇ¥Ïò®ÎèÑ_Ï∞®Ïù¥}}‚ÑÉ ÎÜíÏäµÎãàÎã§.']; Îç∞Ïù¥ÌÑ∞: {'v_1ÏãúÍ∞ÑÏ†Ñ_ÏÑ§Ï†ïÏò®ÎèÑ_Ïã§ÎÇ¥Ïò®ÎèÑ_Ï∞®Ïù¥': 0     -1.0\n",
      "1     -2.5\n",
      "2     -2.5\n",
      "3     -2.5\n",
      "4     -2.5\n",
      "      ... \n",
      "175   -2.5\n",
      "176   -2.5\n",
      "177   -2.5\n",
      "178    0.0\n",
      "179   -2.5\n",
      "Length: 180, dtype: float64};\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing ÏòÜÎ∞òÏùò Í∞ÄÏû• ÏµúÍ∑º Ïò®ÎèÑÎûë ÏÑ§Ï†ïÏò®ÎèÑ ÏïåÎ†§Ï§ò:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:02<00:03,  1.09s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1ÏãúÍ∞Ñ Ï†Ñ ÏÑ§Ï†ïÏò®ÎèÑ(0.00‚ÑÉ)Îäî Ïã§ÎÇ¥Ïò®ÎèÑ(28.00‚ÑÉ)Î≥¥Îã§ -2.50‚ÑÉ ÎÜíÏäµÎãàÎã§.\n",
      "ÏßàÎ¨∏: ÏòÜÎ∞òÏùò Í∞ÄÏû• ÏµúÍ∑º Ïò®ÎèÑÎûë ÏÑ§Ï†ïÏò®ÎèÑ ÏïåÎ†§Ï§ò; Ìè¨Îß∑: ['ÏòÜÎ∞òÏùò Í∞ÄÏû• ÏµúÍ∑º Ïã§ÎÇ¥Ïò®ÎèÑÎäî {{v_Í∞ÄÏû•ÏµúÍ∑º_ÏòÜÎ∞ò_Ïã§ÎÇ¥Ïò®ÎèÑ}}‚ÑÉÎ°ú, ÏÑ§Ï†ïÏò®ÎèÑÎäî {{v_Í∞ÄÏû•ÏµúÍ∑º_ÏòÜÎ∞ò_ÏÑ§Ï†ïÏò®ÎèÑ}}‚ÑÉÏûÖÎãàÎã§.']; Îç∞Ïù¥ÌÑ∞: {'v_Í∞ÄÏû•ÏµúÍ∑º_ÏòÜÎ∞ò_Ïã§ÎÇ¥Ïò®ÎèÑ': 0    27.0\n",
      "Name: Ïã§ÎÇ¥Ïò®ÎèÑ, dtype: float64, 'v_Í∞ÄÏû•ÏµúÍ∑º_ÏòÜÎ∞ò_ÏÑ§Ï†ïÏò®ÎèÑ': 0    23.0\n",
      "Name: ÏÑ§Ï†ïÏò®ÎèÑ, dtype: float64};\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Ïù¥Î≤àÏ£º Ïö∞Î¶¨Î∞ò ÌèâÍ∑† Ïò®ÎèÑ ÏïåÎ†§Ï§ò:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:02<00:01,  1.13it/s]         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.00‚ÑÉÎ°ú, ÏÑ§Ï†ïÏò®ÎèÑÎäî 23.00‚ÑÉÏûÖÎãàÎã§.\n",
      "ÏßàÎ¨∏: Ïù¥Î≤àÏ£º Ïö∞Î¶¨Î∞ò ÌèâÍ∑† Ïò®ÎèÑ ÏïåÎ†§Ï§ò; Ìè¨Îß∑: ['Ïù¥Î≤àÏ£º Ïö∞Î¶¨Î∞òÏùò ÌèâÍ∑† Ïò®ÎèÑÎäî {{v_Ïù¥Î≤àÏ£º_Ïö∞Î¶¨Î∞ò_Ïã§ÎÇ¥Ïò®ÎèÑ_ÌèâÍ∑†}}‚ÑÉ ÏûÖÎãàÎã§.']; Îç∞Ïù¥ÌÑ∞: {'v_Ïù¥Î≤àÏ£º_Ïö∞Î¶¨Î∞ò_Ïã§ÎÇ¥Ïò®ÎèÑ_ÌèâÍ∑†': np.float64(25.66922751621088)};\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing ÏßÄÎÇú ÌïúÎã¨Í∞Ñ ÏÑ§Ï†ïÏò®ÎèÑ ÌèâÍ∑†ÏùÑ ÏïåÎ†§Ï§ò.:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:03<00:00,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ïù¥Î≤àÏ£º Ïö∞Î¶¨Î∞òÏùò ÌèâÍ∑† Ïò®ÎèÑÎäî 25.67‚ÑÉ ÏûÖÎãàÎã§.\n",
      "ÏßàÎ¨∏: ÏßÄÎÇú ÌïúÎã¨Í∞Ñ ÏÑ§Ï†ïÏò®ÎèÑ ÌèâÍ∑†ÏùÑ ÏïåÎ†§Ï§ò.; Ìè¨Îß∑: ['ÏßÄÎÇú ÌïúÎã¨Í∞Ñ ÏÑ§Ï†ïÏò®ÎèÑ ÌèâÍ∑†ÏùÄ {{v_ÏßÄÎÇúÌïúÎã¨_ÏÑ§Ï†ïÏò®ÎèÑ_ÌèâÍ∑†}}‚ÑÉ ÏûÖÎãàÎã§.']; Îç∞Ïù¥ÌÑ∞: {'v_ÏßÄÎÇúÌïúÎã¨_ÏÑ§Ï†ïÏò®ÎèÑ_ÌèâÍ∑†': np.float64(22.950033280890718)};\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing ÏßÄÎÇú ÌïúÎã¨Í∞Ñ ÏÑ§Ï†ïÏò®ÎèÑ ÌèâÍ∑†ÏùÑ ÏïåÎ†§Ï§ò.: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:04<00:00,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÏßÄÎÇú ÌïúÎã¨Í∞Ñ ÏÑ§Ï†ïÏò®ÎèÑ ÌèâÍ∑†ÏùÄ 22.95‚ÑÉ ÏûÖÎãàÎã§.\n",
      "   JsonStructureCorrectness  QueryTruePositive  QueryFalsePositive  \\\n",
      "0                      True                  2                   0   \n",
      "1                      True                  0                 360   \n",
      "2                      True                  2                   0   \n",
      "3                      True               7094                   0   \n",
      "4                      True               2865              129343   \n",
      "\n",
      "   QueryFalseNegative  ExactMatch   Total  \n",
      "0                   0           1       2  \n",
      "1                   2           0     362  \n",
      "2                   0           1       2  \n",
      "3                   0           1    7094  \n",
      "4               41136           0  173344  \n",
      "3.0165278290566735 1.740638835740155 0.24283333520317152\n",
      "0.6341017756176311 0.9254966470528234\n",
      "JsonStructureCorrectness: 1.00\n",
      "ExactMatch: 0.60\n",
      "F1: 0.75\n",
      "Recall: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# name = \"r-v7_r256_a512_ours_tr6_0503-checkpoint-63\"\n",
    "# name = \"r-v7_r256_a512_ours_tr18_0503-checkpoint-52\"\n",
    "# name = \"r-v7_r256_a512_ours_tr30_0503-checkpoint-54\"\n",
    "# name = \"r-v7_r256_a512_ours_tr45_0503-checkpoint-95\"\n",
    "# name = \"r-v7_r256_a512_ours_tr60_0503-checkpoint-108\"\n",
    "\n",
    "# name = \"r-v7_r256_a512_woall_tr6_0503-checkpoint-28\"\n",
    "# name = \"r-v7_r256_a512_woall_tr18_0503-checkpoint-70\"\n",
    "# name = \"r-v7_r256_a512_woall_tr30_0503-checkpoint-57\"\n",
    "# name = \"r-v7_r256_a512_woall_tr45_0503-checkpoint-95\"\n",
    "# name = \"r-v7_r256_a512_woall_tr60_0503-checkpoint-90\"\n",
    "\n",
    "names = [\n",
    "# \"r-v7_r256_a512_ours_tr6_0503-checkpoint-63\",\n",
    "# \"r-v7_r256_a512_ours_tr18_0503-checkpoint-52\",\n",
    "# \"r-v7_r256_a512_ours_tr30_0503-checkpoint-54\",\n",
    "# \"r-v7_r256_a512_ours_tr45_0503-checkpoint-95\",\n",
    "# \"r-v7_r256_a512_ours_tr60_0503-checkpoint-54\",\n",
    "# \"r-v7_r256_a512_woCoT_tr60_0503--checkpoint-84\",\n",
    "# \"r-v7_r256_a512_woCoTExp_tr60_0503--checkpoint-102\",\n",
    "# \"r-v7_r256_a512_woOp_tr60_0503--checkpoint-90\",\n",
    "# \"r-v7_r256_a512_woQM_tr60_0503--checkpoint-54\"\n",
    "# \"r-v7_r170_a340_ours_tr56_0613--checkpoint-60\",\n",
    "# \"r-v7_r256_a512_ours_tr56_0613--checkpoint-68\",\n",
    "\"r-v7_r256_a512_ours_tr17_0613--checkpoint-25\"\n",
    "# \"test\"\n",
    "# \"v8\"\n",
    "]\n",
    "\n",
    "for name in names:\n",
    "    eval_query(\n",
    "        f\"../experiments/{name}.json\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
