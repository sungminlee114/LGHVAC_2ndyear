{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:datasets:PyTorch version 2.7.0+cu128 available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory of src to the path\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src.db.manager import DBManager\n",
    "from src.input_to_instructions.load_and_execute import *\n",
    "from src.input_to_instructions.types import *\n",
    "from src.operation.execute import *\n",
    "from src.response_generation.load_and_execute import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "import json\n",
    "import itertools\n",
    "\n",
    "# from db.manager import DBManager\n",
    "from operation.execute import OperationExecutor\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import datetime\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"../\"\n",
    "def read_json(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        result = json.loads(f.read())\n",
    "    \n",
    "    # result = [{\"Input\": d[\"Input\"], \"Response\": json.dumps(d[\"Response\"], ensure_ascii=False)} for d in result]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: WARNING `trust_remote_code` is True.\n",
      "Are you certain you want to do remote code execution?\n",
      "==((====))==  Unsloth 2025.6.2: Fast Siglip patching. Transformers: 4.52.3.\n",
      "   \\\\   /|    NVIDIA H100 80GB HBM3. Num GPUs = 1. Max memory: 79.189 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu128. CUDA: 9.0. CUDA Toolkit: 12.8. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = True]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Unsloth: Siglip does not support SDPA - switching to eager!\n",
      "Unsloth: QLoRA and full finetuning all not selected. Switching to 16bit LoRA.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "407f8c27122e45429125640cc207704b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ResponseGeneration.initialize(\n",
    "    log_output=False,\n",
    "    instance_type=\"unsloth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from src.input_to_instructions.types import InstructionQ_raw\n",
    "def get_time(df, fmt=\"datetime\"):\n",
    "    # from df get 'timestamp' column and return them in format\n",
    "    if fmt == \"date\":\n",
    "        fmt = '%Y-%m-%d'\n",
    "    elif fmt == \"month\":\n",
    "        fmt = '%Y-%m'\n",
    "    elif fmt == \"year\":\n",
    "        fmt = '%Y'\n",
    "    else:\n",
    "        fmt = '%Y-%m-%d %H:%M:%S'\n",
    "    \n",
    "    if isinstance(df['timestamp'], pd.Timestamp):\n",
    "        result = df['timestamp'].strftime(fmt)\n",
    "    else:\n",
    "        result = df['timestamp'].apply(lambda x: x.strftime(fmt))\n",
    "    return sorted(list(set(result)))\n",
    "\n",
    "def get_spatials(df):\n",
    "    return pd.unique(df['idu_name'])\n",
    "\n",
    "def get_tv(df, col:str|list[str], fmt=\"datetime\"):\n",
    "    if isinstance(col, str):\n",
    "        col = [col]\n",
    "    \n",
    "    timestamps = get_time(df, fmt)\n",
    "    return_tuple = tuple([timestamps] + [df[c] for c in col])\n",
    "    return return_tuple\n",
    "\n",
    "def data(metadata, mapping, query_results, t=str|list[str], s=str|list[str], m=str|list[str]):\n",
    "    if isinstance(t, str):\n",
    "        t = [t]\n",
    "    if isinstance(s, str):\n",
    "        s = [s]\n",
    "    if isinstance(m, str):\n",
    "        m = [m]\n",
    "\n",
    "    t_raw = [mapping.temporal[t_highlevel] for t_highlevel in t]\n",
    "    s_raw = [mapping.spatials[s_highlevel] for s_highlevel in s]\n",
    "    m_raw = [mapping.modalities[m_highlevel] for m_highlevel in m]\n",
    "    \n",
    "    print(m_raw, t_raw, s_raw)\n",
    "    result_df = DBManager.structured_query_data_t_v2(metadata, m_raw, t_raw, s_raw, get_rowids=True)\n",
    "\n",
    "    cols = list(result_df.columns)\n",
    "    cols.remove(\"id\")\n",
    "    cols.remove(\"idu_name\")\n",
    "    cols.remove(\"timestamp\")\n",
    "    rows = list(result_df[\"id\"])\n",
    "    query_results.append({\n",
    "        \"result_columns\": cols,\n",
    "        \"result_indices\": rows,\n",
    "    })\n",
    "    print(cols, rows)\n",
    "\n",
    "    # For demo, drop rows where any value is -1\n",
    "    result_df = result_df.loc[(result_df != -1).all(axis=1)]\n",
    "\n",
    "    # drop \"id\" from result_df\n",
    "    result_df = result_df.drop(columns=['id'])\n",
    "\n",
    "    # change column names to high level\n",
    "    inverse_mapping = {v: k for k, v in mapping.modalities.items()}\n",
    "    result_df.columns = [inverse_mapping[col] if col in inverse_mapping else col for col in result_df.columns]\n",
    "\n",
    "    # change idu_name raw values to high level\n",
    "    inverse_mapping = {v: k for k, v in mapping.spatials.items()}\n",
    "    result_df[\"idu_name\"] = result_df[\"idu_name\"].map(inverse_mapping)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "\n",
    "def run_query_v2(user_input, metadata, mapping, expectations, required_variables, scripts):\n",
    "    query_results = []\n",
    "    variables = {}\n",
    "    if scripts is not None:\n",
    "\n",
    "        # search data(t=~~, ...,)\n",
    "        globals()['metadata'] = metadata\n",
    "        globals()['mapping'] = mapping\n",
    "        globals()['query_results'] = query_results\n",
    "        try:\n",
    "            for script in scripts:\n",
    "                \n",
    "                if \"data\" in script:\n",
    "                    script = script.replace(\"data(\", \"data(metadata, mapping, query_results, \")\n",
    "                \n",
    "                try:\n",
    "                    exec(script, globals())\n",
    "                except Exception as e:\n",
    "                    print(f\"Error in executing script: {script}\")\n",
    "                    print(e)\n",
    "                    raise e\n",
    "        \n",
    "            variables = {name:globals()[name] for name in globals() if name.startswith(\"v_\")}\n",
    "\n",
    "            response, required_variables = ResponseGeneration.execute_v2(expectations, required_variables, variables, user_input, exp_tag=None)\n",
    "            return response, variables, required_variables, query_results\n",
    "        except Exception as e:\n",
    "            print(f\"Error in running query_v2: {e}\")\n",
    "            return \"Ïã§ÌñâÏ§ë ÏóêÎü¨Í∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§.\", variables, None, query_results\n",
    "    else:\n",
    "        variables = {}\n",
    "        unknown_spatials = [k for k, v in mapping.spatials.items() if v == \"Unknown\"]\n",
    "        unknown_modalities = [k for k, v in mapping.modalities.items() if v == \"Unknown\"]\n",
    "        \n",
    "        response_unknown = f\"Ï£ÑÏÜ°Ìï©ÎãàÎã§, {unknown_spatials + unknown_modalities}Îäî Ï°¥Ïû¨ÌïòÏßÄ ÏïäÎäî Í≥µÍ∞ÑÏù¥ÎÇò Î™®Îã¨Î¶¨Ìã∞ ÏûÖÎãàÎã§.\"\n",
    "        return response_unknown, variables, [], query_results\n",
    "\n",
    "\n",
    "def run_query(user_input, metadata, instructions, exp_tag=None):\n",
    "    variables = {\n",
    "        \"Metadata\": metadata,\n",
    "    }\n",
    "    query_results = []\n",
    "        \n",
    "    \n",
    "    for instruction in instructions:\n",
    "        # logger.debug(f\"Executing instruction: {instruction.__class__.__name__}\")\n",
    "        # print(f\"Executing instruction: {instruction.__class__.__name__}\")\n",
    "        \n",
    "        if type(instruction) == InstructionQ:\n",
    "            # Execute query\n",
    "            result_df = DBManager.structured_query_data_t(metadata, instruction.args, get_rowids=True)\n",
    "            # if result_df is None:\n",
    "                # print(\"Ï£ÑÏÜ°Ìï©ÎãàÎã§, Í¥ÄÎ†® Îç∞Ïù¥ÌÑ∞Î•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.\", \"response\")\n",
    "                # return\n",
    "\n",
    "            cols = list(result_df.columns)\n",
    "            cols.remove(\"id\")\n",
    "            cols.remove(\"idu\")\n",
    "            rows = list(result_df[\"id\"])\n",
    "\n",
    "            query_results.append({\n",
    "                \"result_columns\": cols,\n",
    "                \"result_indices\": rows,\n",
    "            })\n",
    "\n",
    "            # For demo, drop rows where any value is -1\n",
    "            result_df = result_df.loc[(result_df != -1).all(axis=1)]\n",
    "\n",
    "            # drop \"id\" from result_df\n",
    "            result_df = result_df.drop(columns=['id'])\n",
    "           \n",
    "            #pd.set_option('display.max_rows', 10000)        \n",
    "            #pd.set_option('display.max_columns', 1000)\n",
    "            #pd.set_option('display.width', 1000)\n",
    "            #pd.set_option('display.max_colwidth', 1000)\n",
    "            #print(f\"QueryResult: {result_df}\")\n",
    "\n",
    "            variables[instruction.result_name] = result_df\n",
    "        elif type(instruction) == InstructionQ_raw:\n",
    "            instruction.query = instruction.query.replace(\" FROM \\\"data_t\\\"\", \", \\\"id\\\" FROM \\\"data_t\\\"\")\n",
    "            result_df = DBManager.execute_structured_query_string(\n",
    "                instruction.query\n",
    "            )\n",
    "            # rename idu_name to idu\n",
    "            result_df = result_df.rename(columns={'idu_name': 'idu'})\n",
    "            \n",
    "            cols = list(result_df.columns)\n",
    "            cols.remove(\"id\")\n",
    "            cols.remove(\"idu\")\n",
    "            rows = list(result_df[\"id\"])\n",
    "\n",
    "            query_results.append({\n",
    "                \"result_columns\": cols,\n",
    "                \"result_indices\": rows,\n",
    "            })\n",
    "\n",
    "            # drop \"id\" from result_df\n",
    "            result_df = result_df.drop(columns=['id'])\n",
    "            \n",
    "            variables[instruction.result_name] = result_df\n",
    "            # print(result_df, flush=True)\n",
    "\n",
    "        elif type(instruction) == InstructionO:\n",
    "            # Execute operation\n",
    "            # variables_to_report = {k: v for k, v in variables.items() if k not in [\"Metadata\"]}\n",
    "            # print(variables_to_report)\n",
    "            result_dict = OperationExecutor.execute(variables, instruction.scripts)\n",
    "            # print(instruction.scripts, instruction.returns, result_dict)\n",
    "            variables.update(result_dict)\n",
    "            pass\n",
    "            # print(fig, \"graph\")\n",
    "        elif type(instruction) == InstructionR:\n",
    "            # Execute response generation\n",
    "            variables_to_report = {k: v for k, v in variables.items() if k not in [\"Metadata\"]}\n",
    "            # print(variables_to_report)\n",
    "            # variables_to_report = ResponseGeneration.stringify_variables(variables_to_report)\n",
    "            # variables_to_report = summarize_variables_to_report(variables_to_report)\n",
    "\n",
    "            # print(f\"Variables: {variables_to_report}\")\n",
    "\n",
    "            keys_to_leave = [\"modality_mapping\", \"idu_mapping\"]\n",
    "            metadata_ = {}\n",
    "            for key in metadata.keys():\n",
    "                if key in keys_to_leave:\n",
    "                    metadata_[key] = metadata[key]\n",
    "\n",
    "            response, required_variables = ResponseGeneration.execute(instruction, variables, user_input, metadata_, exp_tag=exp_tag)\n",
    "            # print(f\"Required variables: {required_variables}\")\n",
    "            \n",
    "            # response = instruction.expectations[0] # \"{{var}}...\"\n",
    "            # for var_name, var_value in required_variables.items():\n",
    "            #     placeholder = f\"{{{{{var_name}}}}}\"\n",
    "            #     if placeholder in response:\n",
    "            #         response = response.replace(placeholder, str(var_value))\n",
    "\n",
    "            \n",
    "            return response, variables_to_report, required_variables, query_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "def build_query_groundtruth():\n",
    "    dataset_name = \"v7-250309-reduceinputanddatefunctioncall\"\n",
    "    def read(path):\n",
    "        data = read_json(path)\n",
    "        for i, d in enumerate(data):\n",
    "            data[i][\"Scenario\"] = directory.name\n",
    "            if \"v7\" in dataset_name:\n",
    "                data[i][\"Metadata\"] = metadata\n",
    "        return data\n",
    "\n",
    "    ds_ts = []\n",
    "    base_dataset_dir = Path(f\"{BASE_DIR}/finetuning/dataset/{dataset_name}\")\n",
    "    \n",
    "    for directory in base_dataset_dir.iterdir():\n",
    "        if directory.is_dir():\n",
    "            if \"v7\" in dataset_name:\n",
    "                metadata = read_json(f\"{directory}/metadata.json\")\n",
    "            \n",
    "            # d = read(f\"{directory}/onlyq_ts.json\")\n",
    "            \n",
    "            ds_ts.extend(read(f\"{directory}/onlyq_ts.json\"))\n",
    "            ds_ts.extend(read(f\"{directory}/onlyq_tr.json\"))\n",
    "            # ds_tr.extend(read(f\"{directory}/graph.json\"))\n",
    "    \n",
    "    ds = ds_ts\n",
    "    print(len(ds))\n",
    "    # if \"v7\" in dataset_name:\n",
    "    #     db_gt_filename = f\"{BASE_DIR}/experiments/db_gt_v7.json\"\n",
    "    # else:\n",
    "    #     db_gt_filename = f\"{BASE_DIR}/experiments/db_gt.json\"\n",
    "    #     metadata = None\n",
    "    \n",
    "    # with open(db_gt_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        # f.write(\"[\")\n",
    "    # with tqdm(total=len(ds)) as pbar:\n",
    "    \n",
    "    gts = []\n",
    "\n",
    "    for d in ds:\n",
    "        cont = False\n",
    "        tags = d[\"Tags\"][\"Style\"]\n",
    "        skip_tags = [\"Reason\", \"Graph\", \"Unrelated\", \"Prediction\"]\n",
    "        for st in skip_tags:\n",
    "            if st in tags:\n",
    "                cont = True\n",
    "                break\n",
    "        if cont:\n",
    "            continue\n",
    "\n",
    "        # pbar.set_description(f\"Processing {d['Input']}\")\n",
    "        # print(\"--\")\n",
    "        exp_tag = \"v2\"\n",
    "        # print(f\"Warning! exp_tag is v2\")\n",
    "        mapping, expectations, required_variables, scripts = InputToInstruction.postprocess_v2(deepcopy(d['Response']), exp_tag=exp_tag)\n",
    "        user_input, tags, metadata, scenario = d[\"Input\"], d[\"Tags\"], d[\"Metadata\"], d[\"Scenario\"]\n",
    "        # if user_input != \"ÏßÄÍ∏à Î™áÏãúÏïº?\":\n",
    "        #     continue\n",
    "\n",
    "        response, variables_to_report, required_variables, query_results = run_query_v2(user_input, metadata, mapping, expectations, required_variables, scripts)\n",
    "        print(f\"Ï∂úÎ†•: {response}\")\n",
    "        # print({k: (v, type(v)) for k, v in variables_to_report.items()})\n",
    "        gts.append({\n",
    "            \"Input\": user_input,\n",
    "            \"Metadata\": metadata,\n",
    "            \"Scenario\": scenario,\n",
    "            \"Tags\": tags,\n",
    "            \"GT\": d['Response'],\n",
    "            \"Response\": response,\n",
    "            # \"RequiredVariables\": required_variables,\n",
    "            \"QueryResults\": query_results,\n",
    "            # \"VariablesToReport\": variables_to_report,\n",
    "        })\n",
    "\n",
    "    # save to json\n",
    "    with open(f\"./gts.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(gts, f, ensure_ascii=False, indent=4)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "Ï∂úÎ†•: Ïù¥Î≤àÏ£º Ïö∞Î¶¨Î∞òÏùò ÌèâÍ∑† Ïã§ÎÇ¥Ïò®ÎèÑ(25.67¬∞C)ÏôÄ ÏïûÎ∞òÏùò ÌèâÍ∑† Ïã§ÎÇ¥Ïò®ÎèÑ(25.98¬∞C)Ïùò Ï∞®Ïù¥Îäî 0.31¬∞CÏûÖÎãàÎã§.\n",
      "Ï∂úÎ†•: ÌòÑÏû¨ ÏÑ§Ï†ïÏò®ÎèÑ(23.00¬∞C)ÏôÄ Ïã§ÎÇ¥Ïò®ÎèÑ(28.50¬∞C)Ïùò Ï∞®Ïù¥Îäî 5.50¬∞CÏûÖÎãàÎã§.\n",
      "Ï∂úÎ†•: ÏßÄÎÇúÎã¨ 8Ïõî 19ÏùºÏóê ÏÑ§Ï†ïÏò®ÎèÑ(23.00¬∞C)ÏôÄ Ïã§ÎÇ¥Ïò®ÎèÑ(22.00¬∞C) Ï∞®Ïù¥Í∞Ä 1.00¬∞CÎ°ú Í∞ÄÏû• Ïª∏ÏäµÎãàÎã§.\n",
      "Ï∂úÎ†•: Ïù¥Î≤àÏ£º Ïö∞Î¶¨Î∞ò ÌèâÍ∑† Ïã§ÎÇ¥Ïò®ÎèÑ(25.67¬∞C)ÏôÄ ÏòÜÎ∞ò ÌèâÍ∑† Ïã§ÎÇ¥Ïò®ÎèÑ(25.11¬∞C) Ï∞®Ïù¥Îäî 0.56¬∞CÏûÖÎãàÎã§.\n",
      "Ï∂úÎ†•: 2Ï£ºÏ†Ñ 9Ïõî 12Ïùº, 13Ïùº, 14Ïùº, 15Ïùº, 16Ïùº, 17Ïùº, 18ÏùºÏóê Ïã§ÎÇ¥Ïò®ÎèÑ(26.00¬∞C)Í∞Ä Í∞ÄÏû• ÎÜíÏïòÏäµÎãàÎã§.\n",
      "Ï∂úÎ†•: Ï£ÑÏÜ°Ìï©ÎãàÎã§, ['ÌôîÏÑ±']Îäî Ï°¥Ïû¨ÌïòÏßÄ ÏïäÎäî Í≥µÍ∞ÑÏù¥ÎÇò Î™®Îã¨Î¶¨Ìã∞ ÏûÖÎãàÎã§.\n",
      "Ï∂úÎ†•: Ï£ÑÏÜ°Ìï©ÎãàÎã§, ['ÏäµÎèÑ']Îäî Ï°¥Ïû¨ÌïòÏßÄ ÏïäÎäî Í≥µÍ∞ÑÏù¥ÎÇò Î™®Îã¨Î¶¨Ìã∞ ÏûÖÎãàÎã§.\n",
      "Ï∂úÎ†•: ÏßÄÎÇú 3ÏùºÍ∞Ñ Ïö∞Î¶¨Î∞ò Ïã§ÎÇ¥Ïò®ÎèÑ ÌèâÍ∑†Í∞íÏùÄ 25.13¬∞CÏòÄÏäµÎãàÎã§.\n",
      "Ï∂úÎ†•: Ïò§Îäò Ïò§ÌõÑ 5Ïãú ÏòÜÎ∞òÏùò ÏÑ§Ï†ïÏò®ÎèÑÎäî 23.00¬∞CÏòÄÏäµÎãàÎã§.\n",
      "Ï∂úÎ†•: Ïò¨Ìï¥ Ïó¨Î¶Ñ(6Ïõî ~ 8Ïõî) Ïö∞Î¶¨Î∞òÏùò Ïã§ÎÇ¥Ïò®ÎèÑ ÏµúÎåÄÍ∞íÍ≥º ÏµúÏÜåÍ∞íÏùÄ Í∞ÅÍ∞Å 27.50¬∞CÏôÄ 22.00¬∞CÏûÖÎãàÎã§.\n",
      "Ï∂úÎ†•: ÌòÑÏû¨ Îëê Î∞© Ï§ë Ïö∞Î¶¨Î∞òÏù¥(Í∞Ä) 28.50¬∞CÎ°ú Í∞ÄÏû• ÎçîÏö¥ Î∞©Ïù¥ÏóêÏöî.\n",
      "Ï∂úÎ†•: Ïñ¥Ï†ú Ïö∞Î¶¨Î∞òÏùò ÏÑ§Ï†ïÏò®ÎèÑ(23.00¬∞C)Îäî ÏòÜÎ∞òÏùò ÏÑ§Ï†ïÏò®ÎèÑ(23.00¬∞C)Î≥¥Îã§ 0.00¬∞C ÎÜíÏäµÎãàÎã§.\n",
      "Ï∂úÎ†•: Ïö∞Î¶¨Î∞ò(27.45¬∞C)Ïù¥ ÏòÜÎ∞ò(26.65¬∞C)Î≥¥Îã§ 0.80¬∞C ÎÜíÏäµÎãàÎã§.\n",
      "Ï∂úÎ†•: ÏûëÎÖÑ Í≤®Ïö∏(2021-12 ~ 2022-02) Ïö∞Î¶¨Î∞òÏùò ÌèâÍ∑† Ïò®ÎèÑ Îç∞Ïù¥ÌÑ∞Î•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.\n",
      "Ï∂úÎ†•: Ïò¨Ìï¥ Ïó¨Î¶Ñ(6Ïõî ~ 8Ïõî) ÏïûÎ∞òÏùò ÌèâÍ∑† Ïò®ÎèÑÎäî 26.11¬∞C ÏûÖÎãàÎã§.\n",
      "Ï∂úÎ†•: Ïò¨Ìï¥ Î¥Ñ ÏòÜÎ∞ò Ïã§ÎÇ¥ ÏµúÏ†Ä Ïò®ÎèÑ Îç∞Ïù¥ÌÑ∞Î•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.\n",
      "Ï∂úÎ†•: 4Ïõî ÏïûÎ∞òÏùò ÌèâÍ∑† Ïò®ÎèÑ Îç∞Ïù¥ÌÑ∞Î•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.\n",
      "Ï∂úÎ†•: Ïù¥Î≤àÎã¨ Ïö∞Î¶¨Î∞ò Ïò®ÎèÑ Îç∞Ïù¥ÌÑ∞Í∞Ä Î∂ÄÏ°±ÌïòÏó¨ Ï†ïÌôïÌïú ÎãµÎ≥ÄÏùÑ Ï†úÍ≥µÌï† Ïàò ÏóÜÏäµÎãàÎã§.\n",
      "Ï∂úÎ†•: 2Ï£ºÏ†Ñ Ïö∞Î¶¨Î∞òÍ≥º ÏòÜÎ∞ò Ìï©Ï≥êÏÑú ÏÑ§Ï†ïÏò®ÎèÑÍ∞Ä Í∞ÄÏû• ÎÇÆÏùÄ ÎÇ†ÏùÄ 2022-09-12Î°ú 23.00¬∞CÏòÄÏäµÎãàÎã§.\n",
      "Ï∂úÎ†•: Ï£ÑÏÜ°Ìï©ÎãàÎã§, ['Îí∑Î∞ò']Îäî Ï°¥Ïû¨ÌïòÏßÄ ÏïäÎäî Í≥µÍ∞ÑÏù¥ÎÇò Î™®Îã¨Î¶¨Ìã∞ ÏûÖÎãàÎã§.\n",
      "Ï∂úÎ†•: Ïö∞Î¶¨Î∞òÏùò ÌòÑÏû¨ ÏÑ§Ï†ïÏò®ÎèÑÎäî 23.00¬∞CÏûÖÎãàÎã§.\n",
      "Ï∂úÎ†•: 8ÏùºÏ†Ñ Ïö∞Î¶¨Î∞òÏùò ÌèâÍ∑† ÏÑ§Ï†ïÏò®ÎèÑÎäî 23.00¬∞CÏòÄÏäµÎãàÎã§.\n",
      "Ï∂úÎ†•: 10ÎÖÑ Ï†Ñ Ïò§Îäò Ïö∞Î¶¨Î∞òÏùò Ïã§ÎÇ¥Ïò®ÎèÑ Îç∞Ïù¥ÌÑ∞Î•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.\n",
      "Ï∂úÎ†•: Ï£ÑÏÜ°Ìï©ÎãàÎã§, ['Î°ØÎç∞Ï∫êÏä¨']Îäî Ï°¥Ïû¨ÌïòÏßÄ ÏïäÎäî Í≥µÍ∞ÑÏù¥ÎÇò Î™®Îã¨Î¶¨Ìã∞ ÏûÖÎãàÎã§.\n",
      "Ï∂úÎ†•: Ï£ÑÏÜ°Ìï©ÎãàÎã§, ['1Ï∏µ']Îäî Ï°¥Ïû¨ÌïòÏßÄ ÏïäÎäî Í≥µÍ∞ÑÏù¥ÎÇò Î™®Îã¨Î¶¨Ìã∞ ÏûÖÎãàÎã§.\n",
      "Ï∂úÎ†•: ÌòÑÏû¨ ÏÑ∏ Î∞© Ï§ë Ïö∞Î¶¨Î∞òÏù¥ Í∞ÄÏû• Ï∂îÏö¥ Î∞©ÏúºÎ°ú {{v_ÌòÑÏû¨_Ïã§ÎÇ¥Ïò®ÎèÑ_ÏµúÏ†Ä}}¬∞CÏûÖÎãàÎã§. \n",
      "\n",
      "(Ï∞∏Í≥†Î°ú Ï£ºÏñ¥ÏßÑ Îç∞Ïù¥ÌÑ∞ Ìè¨Îß∑Í≥º ÏßàÎ¨∏Ïóê ÏôÑÎ≤ΩÌïòÍ≤å Î∂ÄÌï©ÌïòÎèÑÎ°ù Ï°∞Ï†ïÌïòÏòÄÏúºÎÇò, 'ÏòÜÎ∞ò'Í≥º 'ÏïûÎ∞ò'Ïùò Ïò®ÎèÑ Ï†ïÎ≥¥Í∞Ä Ï†úÍ≥µÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§. Îî∞ÎùºÏÑú, Ï†úÍ≥µÎêú Ï†ïÎ≥¥ÎßåÏúºÎ°úÎäî Í∞ÄÏû• Ï∂îÏö¥ Î∞©ÏùÑ Ï†ïÌôïÌûà ÏßÄÏ†ïÌï† Ïàò ÏóÜÏßÄÎßå, ÏöîÏ≤≠ÌïòÏã† Ìè¨Îß∑Ïóê ÎßûÏ∂∞ ÎãµÎ≥ÄÏùÑ Íµ¨ÏÑ±ÌïòÏòÄÏäµÎãàÎã§.) \n",
      "\n",
      "Ï†ïÌôïÌïú Ìè¨Îß∑Ïóê Îî∞Î•∏ ÎãµÎ≥Ä:\n",
      "ÌòÑÏû¨ ÏÑ∏ Î∞© Ï§ë Ïö∞Î¶¨Î∞òÏù¥ {{v_ÌòÑÏû¨_Ïã§ÎÇ¥Ïò®ÎèÑ_ÏµúÏ†Ä}}¬∞CÎ°ú Í∞ÄÏû• Ï∂îÏö¥ Î∞©ÏûÖÎãàÎã§. \n",
      "\n",
      "Îã®Ïàú Ìè¨Îß∑ Ï†ÅÏö© Í≤∞Í≥º:\n",
      "['ÌòÑÏû¨ ÏÑ∏ Î∞© Ï§ë Ïö∞Î¶¨Î∞òÏù¥ Í∞ÄÏû• Ï∂îÏõåÏöî.']\n",
      "Ï∂úÎ†•: Ï£ÑÏÜ°Ìï©ÎãàÎã§, ['ÏóêÎÑàÏßÄ ÏÇ¨Ïö©Îüâ']Îäî Ï°¥Ïû¨ÌïòÏßÄ ÏïäÎäî Í≥µÍ∞ÑÏù¥ÎÇò Î™®Îã¨Î¶¨Ìã∞ ÏûÖÎãàÎã§.\n",
      "Ï∂úÎ†•: ÏßÄÎÇúÎã¨ Ïò§Îäò Ïò§ÌõÑ 2Ïãú ÏòÜÎ∞òÏùò ÏÑ§Ï†ïÏò®ÎèÑÎäî 23.00¬∞CÏòÄÏäµÎãàÎã§.\n",
      "Ï∂úÎ†•: ÏòÜÎ∞òÏùò ÌòÑÏû¨ Ïã§ÎÇ¥Ïò®ÎèÑÎäî 27.00¬∞CÏù¥Í≥†, ÏÑ§Ï†ïÏò®ÎèÑÎäî 23.00¬∞CÏûÖÎãàÎã§.\n",
      "Ï∂úÎ†•: Ïù¥Î≤àÏ£º Ïö∞Î¶¨Î∞òÏùò ÌèâÍ∑† Ïã§ÎÇ¥Ïò®ÎèÑÎäî 25.67¬∞C ÏûÖÎãàÎã§.\n",
      "Ï∂úÎ†•: ÏßÄÎÇúÎã¨ ÏÑ§Ï†ïÏò®ÎèÑ ÌèâÍ∑†ÏùÄ 23.02¬∞CÏòÄÏäµÎãàÎã§.\n",
      "Ï∂úÎ†•: Ï£ÑÏÜ°Ìï©ÎãàÎã§, ['1Ï∏µ']Îäî Ï°¥Ïû¨ÌïòÏßÄ ÏïäÎäî Í≥µÍ∞ÑÏù¥ÎÇò Î™®Îã¨Î¶¨Ìã∞ ÏûÖÎãàÎã§.\n",
      "Ï∂úÎ†•: Ïù¥Î≤àÎã¨ Ïö∞Î¶¨Î∞òÏùÄ 2022-09-07 ÎòêÎäî 2022-09-27Ïóê Ïã§ÎÇ¥Ïò®ÎèÑ 22.50¬∞CÎ°ú Í∞ÄÏû• Ï∂îÏõ†ÏäµÎãàÎã§.\n",
      "Ï∂úÎ†•: ÏòÜÎ∞ò ÏûëÎÖÑ Ïã§ÎÇ¥Ïò®ÎèÑ ÏµúÍ≥† Ïò®ÎèÑ Îç∞Ïù¥ÌÑ∞Î•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.\n",
      "Ï∂úÎ†•: Ïò§Îäò Ïò§Ï†Ñ 11Ïãú ÏòÜÎ∞òÏùò Ïã§ÎÇ¥Ïò®ÎèÑÎäî 27.00¬∞CÏòÄÏäµÎãàÎã§.\n",
      "Ï∂úÎ†•: Ïò§Îäò Ïò§ÌõÑ 4ÏãúÎ∂ÄÌÑ∞ 6ÏãúÍπåÏßÄ Ïö∞Î¶¨Î∞òÏùò ÌèâÍ∑† Ïã§ÎÇ¥Ïò®ÎèÑÎäî 28.05¬∞CÏòÄÏäµÎãàÎã§.\n",
      "Ï∂úÎ†•: ÏßÄÎÇúÏ£º 2022-09-23Ïóê ÏÑ§Ï†ïÏò®ÎèÑ(23.00¬∞C)ÏôÄ Ïã§ÎÇ¥Ïò®ÎèÑ(23.50¬∞C) Ï∞®Ïù¥Í∞Ä 0.50¬∞CÎ°ú Í∞ÄÏû• Ïª∏ÏäµÎãàÎã§.\n",
      "Ï∂úÎ†•: ÏòÜÎ∞ò(27.00¬∞C)Ïù¥ Ïö∞Î¶¨Î∞ò(28.50¬∞C)Î≥¥Îã§ 1.50¬∞C Îçî ÎÇÆÏïÑÏöî.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "build_query_groundtruth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any  # Any ÌÉÄÏûÖ import ÌïÑÏöî\n",
    "\n",
    "class EM:\n",
    "    json_structure = \"JsonStructureCorrectness\"\n",
    "    true_positive = \"QueryTruePositive\"\n",
    "    false_positive = \"QueryFalsePositive\"\n",
    "    false_negative = \"QueryFalseNegative\"\n",
    "    \n",
    "def eval_query(cand_response_filename, db_gt_filename=\"./gts.json\"):\n",
    "    db_gts = read_json(db_gt_filename)\n",
    "    cand_responses = read_json(cand_response_filename)\n",
    "    # metadata_ = read_json(f\"{BASE_DIR}/finetuning/dataset/v7-250309-reduceinputanddatefunctioncall/scenario1/metadata.json\")\n",
    "    evaluation_reports = []\n",
    "    response_reports = []\n",
    "    with tqdm(total=len(cand_responses)) as pbar:\n",
    "        for cand_response in cand_responses:\n",
    "            pbar.set_description(f\"Processing {cand_response['Input']}\")\n",
    "            input = cand_response[\"Input\"]\n",
    "            scenario = cand_response[\"Scenario\"]\n",
    "\n",
    "            if \"Ïö∞Î¶¨Î∞òÍ≥º ÏïûÎ∞ò Ï§ë Í∞ÄÏû• ÎçîÏö¥ Î∞©ÏùÄ?\" not in input:\n",
    "                continue\n",
    "\n",
    "            if \"Metadata\" in cand_response:\n",
    "                metadata = cand_response[\"Metadata\"]\n",
    "            else:\n",
    "                # metadata = metadata_\n",
    "                metadata = None\n",
    "            # Í¥ÄÍ≥Ñ ÏóÜÎäî ÏßàÎ¨∏Îì§ÏùÄ Í±¥ÎÑàÎõ∞Ïûê\n",
    "            gt_report = [d for d in db_gts if d[\"Input\"] == input and d[\"Scenario\"] == scenario]\n",
    "            assert len(gt_report) <= 1\n",
    "            if len(gt_report) == 0:\n",
    "                pbar.update(1)\n",
    "                continue\n",
    "\n",
    "            gt_report = gt_report[0]\n",
    "            tags = gt_report[\"Tags\"]\n",
    "            # assert gt_report[\"QueryResults\"] != []\n",
    "            # if gt_report[\"Result\"] == []:\n",
    "            #     pbar.update(1)\n",
    "            #     continue\n",
    "            \n",
    "            gt_results = [d for d in gt_report[\"QueryResults\"]]\n",
    "            gt_query_results = defaultdict(list)\n",
    "            for gt_result in gt_results:\n",
    "                for col in gt_result[\"result_columns\"]:\n",
    "                    gt_query_results[col].extend(gt_result[\"result_indices\"])\n",
    "\n",
    "            gt_total_combinations = sum(len(v) for v in gt_query_results.values())\n",
    "\n",
    "            gt_response = gt_report[\"Response\"]\n",
    "            # gt_required_variables = gt_report[\"RequiredVariables\"]\n",
    "            # gt_variables_to_report = gt_report[\"VariablesToReport\"]\n",
    "            user_input = gt_report[\"Input\"]\n",
    "\n",
    "            response_report = {\n",
    "                \"Input\": user_input,\n",
    "                \"Metadata\": metadata,\n",
    "                \"GT_Response\": gt_response,\n",
    "                # \"GT_RequiredVariables\": gt_required_variables,\n",
    "                # \"GT_VariablesToReport\": gt_variables_to_report,\n",
    "            }\n",
    "            # evaluation_report ÎîïÏÖîÎÑàÎ¶¨ ÏÉùÏÑ± (defaultdict ÏÇ¨Ïö©, Í∏∞Î≥∏Í∞í None)\n",
    "\n",
    "            evaluation_report: dict[str, Any] = defaultdict(lambda: None)\n",
    "            evaluation_report[\"Input\"] = input\n",
    "            evaluation_report[\"Metadata\"] = metadata\n",
    "            evaluation_report[\"Tags\"] = tags\n",
    "            \n",
    "            if isinstance(cand_response[\"Candidate\"], dict):\n",
    "                requirements = [\"Thinking\", \"Expectations\", \"Mapping\"]\n",
    "                for requirement in requirements:\n",
    "                    if requirement not in cand_response[\"Candidate\"]:\n",
    "                        evaluation_report[EM.json_structure] = False\n",
    "                        break\n",
    "                else:\n",
    "                    evaluation_report[EM.json_structure] = True\n",
    "            else:\n",
    "                evaluation_report[EM.json_structure] = False\n",
    "            \n",
    "            if not evaluation_report[EM.json_structure]:\n",
    "                evaluation_report[EM.true_positive] = 0\n",
    "                evaluation_report[EM.false_positive] = 0\n",
    "                evaluation_report[EM.false_negative] = gt_total_combinations\n",
    "\n",
    "                print(\"Failed to parse input: \", input, cand_response[\"Candidate\"])\n",
    "                evaluation_reports.append(evaluation_report)\n",
    "                pbar.update(1)\n",
    "                response_reports.append(response_report)\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            exp_tag = \\\n",
    "                \"woCoTExp\" if \"woCoTExp\" in str(cand_response_filename) else \\\n",
    "                \"woOp\" if \"woOp\" in str(cand_response_filename) else \\\n",
    "                \"woQM\" if \"woQM\" in str(cand_response_filename) else \\\n",
    "                None\n",
    "            \n",
    "            mapping, expectations, required_variables, script = InputToInstruction.postprocess_v2(\n",
    "                deepcopy(cand_response[\"Candidate\"]), \n",
    "                exp_tag=exp_tag\n",
    "            )\n",
    "            \n",
    "            response, variables_to_report, required_variables, _cand_query_results = run_query_v2(user_input, metadata, mapping, expectations, required_variables, script)\n",
    "            print(response)\n",
    "            response_report[\"PD_Response\"] = response\n",
    "            # try:\n",
    "            #     # response, variables_to_report, required_variables, _cand_query_results = run_query_v2(user_input, metadata, instructions, exp_tag=exp_tag)\n",
    "            # except Exception as e:\n",
    "            #     print(f\"Error: {e}\")\n",
    "            #     # evaluation_report[EM.true_positive] = 0\n",
    "            #     # evaluation_report[EM.false_positive] = 0\n",
    "            #     # evaluation_report[EM.false_negative] = gt_total_combinations\n",
    "                            \n",
    "            #     # evaluation_reports.append(evaluation_report)\n",
    "\n",
    "            #     # response_reports.append(response_report)\n",
    "                            \n",
    "            #     # pbar.update(1)\n",
    "            #     # continue\n",
    "            \n",
    "            response_reports.append(response_report)\n",
    "            \n",
    "            # required_variables = summarize_variables_to_report(required_variables)\n",
    "            # print(required_variables)\n",
    "            # required_variables = ResponseGeneration.stringify_variables(required_variables)\n",
    "            \n",
    "            # response_report[\"PD_RequiredVariables\"] = required_variables\n",
    "            # response_report[\"PD_VariablesToReport\"] = variables_to_report\n",
    "\n",
    "            if len(_cand_query_results) == 0:\n",
    "                evaluation_report[EM.true_positive] = 0\n",
    "                evaluation_report[EM.false_positive] = 0\n",
    "                evaluation_report[EM.false_negative] = gt_total_combinations\n",
    "                            \n",
    "                evaluation_reports.append(evaluation_report)\n",
    "                pbar.update(1)\n",
    "                continue\n",
    "            \n",
    "            cand_query_results = defaultdict(list)\n",
    "            for cand_query_result in _cand_query_results:\n",
    "                for col in cand_query_result[\"result_columns\"]:\n",
    "                    cand_query_results[col].extend(cand_query_result[\"result_indices\"])\n",
    "\n",
    "            cand_total_combinations = sum(len(v) for v in gt_query_results.values())\n",
    "\n",
    "            if len(gt_results) == 0:\n",
    "                evaluation_report[EM.true_positive] = 0\n",
    "                evaluation_report[EM.false_positive] = cand_total_combinations\n",
    "                evaluation_report[EM.false_negative] = 0\n",
    "\n",
    "                evaluation_reports.append(evaluation_report)\n",
    "                pbar.update(1)\n",
    "\n",
    "                continue\n",
    "            \n",
    "            # print(gt_total_combinations, cand_total_combinations)\n",
    "            # True Positive: Í≥µÌÜµÎêú Ïª¨ÎüºÍ≥º Î°úÏö∞Ïùò Î™®Îì† Ï°∞Ìï©\n",
    "            true_positive = 0\n",
    "            false_negative = 0\n",
    "            false_positive = 0\n",
    "            print(gt_query_results, cand_query_results)\n",
    "            for col in set(gt_query_results.keys())&set(cand_query_results.keys()):\n",
    "                s_gt_query_result = set(gt_query_results[col])\n",
    "                s_cand_query_result = set(cand_query_results[col])\n",
    "                true_positive += len(s_gt_query_result & s_cand_query_result)\n",
    "                false_negative += len(s_gt_query_result - s_cand_query_result)\n",
    "                false_positive += len(s_cand_query_result - s_gt_query_result)\n",
    "\n",
    "                # print(true_positive, false_negative, false_positive, len(s_gt_query_result), len(s_cand_query_result))\n",
    "            # assert true_positive + false_positive + false_negative == gt_total_combinations\n",
    "            \n",
    "\n",
    "            evaluation_report[EM.true_positive] = true_positive\n",
    "            evaluation_report[EM.false_positive] = false_positive\n",
    "            evaluation_report[EM.false_negative] = false_negative\n",
    "\n",
    "            evaluation_reports.append(evaluation_report)\n",
    "            # print(evaluation_report)\n",
    "            \n",
    "            pbar.update(1)\n",
    "\n",
    "    with open(f\"{cand_response_filename.replace('.json', '_response.json')}\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(response_reports, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    eval_df = pd.DataFrame(evaluation_reports)\n",
    "    # print(eval_df)\n",
    "\n",
    "    eval_df['ExactMatch'] = eval_df.apply(lambda x: x[EM.false_positive] == 0 and x[EM.false_negative] == 0, axis=1).astype(int)\n",
    "    # eval_df['TruePositive'] = eval_df['TruePositive'].astype(int)\n",
    "    # eval_df['FalsePositive'] = eval_df['FalsePositive'].astype(int)\n",
    "    # eval_df['FalseNegative'] = eval_df['FalseNegative'].astype(int)\n",
    "\n",
    "    final_result = {}\n",
    "\n",
    "    for col in [\"JsonStructureCorrectness\", \"ExactMatch\"]:\n",
    "        # print(f\"{col}: {eval_df[col].mean()}\")\n",
    "        final_result[col] = eval_df[col].mean()\n",
    "    \n",
    "    # normalize per query\n",
    "    eval_df[\"Total\"] = eval_df[EM.true_positive] + eval_df[EM.false_positive] + eval_df[EM.false_negative]\n",
    "    eval_print = eval_df.drop(columns=[\"Metadata\", \"Tags\"])\n",
    "    print(eval_print)\n",
    "    eval_df[EM.true_positive] = eval_df[EM.true_positive] / eval_df[\"Total\"]\n",
    "    eval_df[EM.false_positive] = eval_df[EM.false_positive] / eval_df[\"Total\"]\n",
    "    eval_df[EM.false_negative] = eval_df[EM.false_negative] / eval_df[\"Total\"]\n",
    "\n",
    "    # # replace nan with 0\n",
    "    # eval_df.fillna(0, inplace=True)\n",
    "\n",
    "    # # F1 score except nans.\n",
    "    truepos_sum, falsepos_sum, falseneg_sum = eval_df[EM.true_positive].sum(), eval_df[EM.false_positive].sum(), eval_df[EM.false_negative].sum()\n",
    "    precision = truepos_sum / (truepos_sum + falsepos_sum)\n",
    "    recall = truepos_sum / (truepos_sum + falseneg_sum)\n",
    "    print(truepos_sum, falsepos_sum, falseneg_sum)\n",
    "    print(precision, recall)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    # print(f\"F1: {f1}\")\n",
    "    final_result[\"F1\"] = f1\n",
    "    final_result[\"Recall\"] = recall\n",
    "\n",
    "    for col in final_result:\n",
    "        print(f\"{col}: {final_result[col]:.2f}\")\n",
    "    \n",
    "    return eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Ïò§Îäò Ïò§ÌõÑ 5ÏãúÏóê ÏòÜÎ∞òÏùò ÏÑ§Ï†ïÏò®ÎèÑÎäî Ïñ¥Îï†Ïñ¥?:   0%|          | 0/11 [00:00<?, ?it/s]             "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Ïö∞Î¶¨Î∞òÍ≥º ÏïûÎ∞ò Ï§ë Í∞ÄÏû• ÎçîÏö¥ Î∞©ÏùÄ?:   0%|          | 0/11 [00:00<?, ?it/s]                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['roomtemp'] [87838]\n",
      "ÏßàÎ¨∏: Ïö∞Î¶¨Î∞òÍ≥º ÏïûÎ∞ò Ï§ë Í∞ÄÏû• ÎçîÏö¥ Î∞©ÏùÄ?; Ìè¨Îß∑: ['ÌòÑÏû¨ Îëê Î∞© Ï§ë {{v_ÌòÑÏû¨_Ïã§ÎÇ¥Ïò®ÎèÑ_ÏµúÍ≥†_Î∞©}}Ïù¥(Í∞Ä) {{v_ÌòÑÏû¨_Ïã§ÎÇ¥Ïò®ÎèÑ_ÏµúÍ≥†}}‚ÑÉÎ°ú Í∞ÄÏû• ÎçîÏö¥ Î∞©Ïù¥ÏóêÏöî.']; Îç∞Ïù¥ÌÑ∞: {'v_ÌòÑÏû¨_Ïã§ÎÇ¥Ïò®ÎèÑ_ÏµúÍ≥†': np.float64(28.5), 'v_ÌòÑÏû¨_Ïã§ÎÇ¥Ïò®ÎèÑ_ÏµúÍ≥†_Î∞©': array(['Ïö∞Î¶¨Î∞ò'], dtype=object)};\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Ïö∞Î¶¨Î∞òÍ≥º ÏïûÎ∞ò Ï§ë Í∞ÄÏû• ÎçîÏö¥ Î∞©ÏùÄ?:   9%|‚ñâ         | 1/11 [00:00<00:04,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÌòÑÏû¨ Îëê Î∞© Ï§ë Ïö∞Î¶¨Î∞òÏù¥(Í∞Ä) 28.50¬∞CÎ°ú Í∞ÄÏû• ÎçîÏö¥ Î∞©Ïù¥ÏóêÏöî.\n",
      "SEx\n",
      "defaultdict(<class 'list'>, {'roomtemp': [87838]}) defaultdict(<class 'list'>, {'roomtemp': [87838]})\n",
      "                 Input  JsonStructureCorrectness  QueryTruePositive  \\\n",
      "0  Ïö∞Î¶¨Î∞òÍ≥º ÏïûÎ∞ò Ï§ë Í∞ÄÏû• ÎçîÏö¥ Î∞©ÏùÄ?                      True                  1   \n",
      "\n",
      "   QueryFalsePositive  QueryFalseNegative  ExactMatch  Total  \n",
      "0                   0                   0           1      1  \n",
      "1.0 0.0 0.0\n",
      "1.0 1.0\n",
      "JsonStructureCorrectness: 1.00\n",
      "ExactMatch: 1.00\n",
      "F1: 1.00\n",
      "Recall: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# name = \"r-v7_r256_a512_ours_tr6_0503-checkpoint-63\"\n",
    "# name = \"r-v7_r256_a512_ours_tr18_0503-checkpoint-52\"\n",
    "# name = \"r-v7_r256_a512_ours_tr30_0503-checkpoint-54\"\n",
    "# name = \"r-v7_r256_a512_ours_tr45_0503-checkpoint-95\"\n",
    "# name = \"r-v7_r256_a512_ours_tr60_0503-checkpoint-108\"\n",
    "\n",
    "# name = \"r-v7_r256_a512_woall_tr6_0503-checkpoint-28\"\n",
    "# name = \"r-v7_r256_a512_woall_tr18_0503-checkpoint-70\"\n",
    "# name = \"r-v7_r256_a512_woall_tr30_0503-checkpoint-57\"\n",
    "# name = \"r-v7_r256_a512_woall_tr45_0503-checkpoint-95\"\n",
    "# name = \"r-v7_r256_a512_woall_tr60_0503-checkpoint-90\"\n",
    "\n",
    "names = [\n",
    "# \"r-v7_r256_a512_ours_tr6_0503-checkpoint-63\",\n",
    "# \"r-v7_r256_a512_ours_tr18_0503-checkpoint-52\",\n",
    "# \"r-v7_r256_a512_ours_tr30_0503-checkpoint-54\",\n",
    "# \"r-v7_r256_a512_ours_tr45_0503-checkpoint-95\",\n",
    "# \"r-v7_r256_a512_ours_tr60_0503-checkpoint-54\",\n",
    "# \"r-v7_r256_a512_woCoT_tr60_0503--checkpoint-84\",\n",
    "# \"r-v7_r256_a512_woCoTExp_tr60_0503--checkpoint-102\",\n",
    "# \"r-v7_r256_a512_woOp_tr60_0503--checkpoint-90\",\n",
    "# \"r-v7_r256_a512_woQM_tr60_0503--checkpoint-54\"\n",
    "# \"r-v7_r170_a340_ours_tr56_0613--checkpoint-60\",\n",
    "# \"r-v7_r256_a512_ours_tr56_0613--checkpoint-68\",\n",
    "\"r-v7_r200_a400_ours_tr27_0613-checkpoint-34\"\n",
    "# \"test\"\n",
    "# \"v8\"\n",
    "]\n",
    "\n",
    "for name in names:\n",
    "    eval_query(\n",
    "        f\"../experiments/{name}.json\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
