{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling, BitsAndBytesConfig\n",
    "import transformers\n",
    "from datasets import load_dataset, Dataset\n",
    "import pprint\n",
    "import json\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using flash_attention_2 for attention computation.\n",
      "==((====))==  Unsloth 2025.2.5: Fast Llama patching. Transformers: 4.48.3.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 3090. Max memory: 23.689 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post2. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b250b1c156ae4d4792da7abd1e23339f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sh2orc/Llama-3.1-Korean-8B-Instruct does not have a padding token! Will use pad_token = <|finetune_right_pad_id|>.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = f\"cuda\"\n",
    "from huggingface_hub import hf_hub_download\n",
    "import os\n",
    "\n",
    "\n",
    "if torch.cuda.get_device_capability()[0] >= 8:\n",
    "    attn_implementation = \"flash_attention_2\"\n",
    "    torch_dtype = torch.bfloat16\n",
    "else:\n",
    "    attn_implementation = \"eager\"\n",
    "    torch_dtype = torch.float16\n",
    "# attn_implementation = \"eager\"\n",
    "print(f\"Using {attn_implementation} for attention computation.\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "model_id = 'sh2orc/Llama-3.1-Korean-8B-Instruct'\n",
    "# model_id = 'Bllossom/llama-3.2-Korean-Bllossom-3B'\n",
    "# model_id = 'Saxo/Linkbricks-Horizon-AI-Korean-Gemma-2-sft-dpo-27B'\n",
    "# model_id = 'Bllossom/llama-3-Korean-Bllossom-70B'\n",
    "\n",
    "model_dir = f\"/model/{model_id.replace('/', '-')}\"\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = model_id,\n",
    "    # max_seq_length = max_seq_length,\n",
    "    dtype = torch_dtype,\n",
    "    load_in_4bit = False,\n",
    "    load_in_8bit = False,\n",
    "    # quantization_config=BitsAndBytesConfig(\n",
    "    #     load_in_4bit=True,\n",
    "    #     bnb_4bit_use_double_quant=True,\n",
    "    #     bnb_4bit_quant_type=\"nf4\",\n",
    "    #     bnb_4bit_compute_dtype=torch_dtype\n",
    "    #     # load_in_8bit=True,\n",
    "    #     # llm_int8_enable_fp32_cpu_offload=False if not \"27B\" in model_id else True,\n",
    "    # ),\n",
    "    # device_map=device,\n",
    "    cache_dir=f\"{model_dir}/cache\",\n",
    "    attn_implementation=attn_implementation,\n",
    "    local_files_only=True\n",
    ")\n",
    "FastLanguageModel.for_inference(model)\n",
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'scenario1': {'site_name': 'YongDongIllHighSchool', 'user_name': 'ÌôçÍ∏∏Îèô', 'user_role': 'customer', 'idu_name': '01_IB5', 'idu_mapping': {'01_IB5': ['Ïö∞Î¶¨Î∞ò'], '01_IB7': ['ÏòÜÎ∞ò'], '02_I81': ['ÏïûÎ∞ò']}, 'modality_mapping': {'roomtemp': ['Ïã§ÎÇ¥Ïò®ÎèÑ'], 'settemp': ['ÏÑ§Ï†ïÏò®ÎèÑ'], 'oper': ['Ï†ÑÏõê']}, 'current_datetime': '2022-09-30 12:00:00'}}\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path  # Import Path from pathlib\n",
    "import json\n",
    "dataset_name = \"v7-250309-reduceinputanddatefunctioncall\"\n",
    "dataset_dir = Path(f\"/workspace/finetuning/dataset/{dataset_name}\")\n",
    "\n",
    "metadatas = {}\n",
    "for directory in dataset_dir.iterdir():\n",
    "    if directory.is_dir() and \"scenario\" in directory.name:\n",
    "        with open(f\"{directory}/metadata.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "            metadatas[directory.name] = json.loads(f.read())\n",
    "\n",
    "print(metadatas)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"db_gt_v7.json\"\n",
    "file_path = f\"/workspace/experiments/{file_name}\"\n",
    "\n",
    "with open(file_path, \"r\") as f:\n",
    "    datas = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================\n",
      "\n",
      "ÏßàÎ¨∏: Ïñ¥Ï†ú Ïö∞Î¶¨Î∞òÍ≥º ÏòÜÎ∞òÏùò ÏÑ§Ï†ïÏò®ÎèÑ Ï∞®Ïù¥ ÏïåÎ†§Ï§ò\n",
      "Metadata: {'site_name': 'YongDongIllHighSchool', 'user_name': 'ÌôçÍ∏∏Îèô', 'user_role': 'customer', 'idu_name': '01_IB5', 'idu_mapping': {'01_IB5': ['Ïö∞Î¶¨Î∞ò'], '01_IB7': ['ÏòÜÎ∞ò'], '02_I81': ['ÏïûÎ∞ò']}, 'modality_mapping': {'roomtemp': ['Ïã§ÎÇ¥Ïò®ÎèÑ'], 'settemp': ['ÏÑ§Ï†ïÏò®ÎèÑ'], 'oper': ['Ï†ÑÏõê']}, 'current_datetime': '2022-09-30 12:00:00'}\n",
      "ÏòàÏãú: ['Ïñ¥Ï†ú Ïö∞Î¶¨Î∞òÏùò ÏÑ§Ï†ïÏò®ÎèÑ({{settemp_ours}}‚ÑÉ)Îäî ÏòÜÎ∞òÏùò ÏÑ§Ï†ïÏò®ÎèÑ({{settemp_beside}}‚ÑÉ)Î≥¥Îã§ {{settemp_diff}}‚ÑÉ ÎÜíÏäµÎãàÎã§.']\n",
      "Í≤∞Í≥º: {'settemp_ours': 23.0, 'settemp_beside': 23.0, 'settemp_diff': 0.0}\n",
      "\n",
      "ÎãµÎ≥Ä:\n",
      "Ïñ¥Ï†ú Ïö∞Î¶¨Î∞òÏùò ÏÑ§Ï†ïÏò®ÎèÑ(23.0‚ÑÉ)Îäî ÏòÜÎ∞òÏùò ÏÑ§Ï†ïÏò®ÎèÑ(23.0‚ÑÉ)Î≥¥Îã§ 0.0‚ÑÉ ÎÜíÏäµÎãàÎã§.\n",
      "Time elapsed: 1.4660255908966064\n",
      "====================================================\n",
      "\n",
      "ÏßàÎ¨∏: Ïò§Îäò Ïö∞Î¶¨Î∞òÍ≥º ÏòÜÎ∞òÏùò ÌèâÍ∑† Ïò®ÎèÑÏ∞®Ïù¥ ÏïåÎ†§Ï§ò\n",
      "Metadata: {'site_name': 'YongDongIllHighSchool', 'user_name': 'ÌôçÍ∏∏Îèô', 'user_role': 'customer', 'idu_name': '01_IB5', 'idu_mapping': {'01_IB5': ['Ïö∞Î¶¨Î∞ò'], '01_IB7': ['ÏòÜÎ∞ò'], '02_I81': ['ÏïûÎ∞ò']}, 'modality_mapping': {'roomtemp': ['Ïã§ÎÇ¥Ïò®ÎèÑ'], 'settemp': ['ÏÑ§Ï†ïÏò®ÎèÑ'], 'oper': ['Ï†ÑÏõê']}, 'current_datetime': '2022-09-30 12:00:00'}\n",
      "ÏòàÏãú: ['Ïö∞Î¶¨Î∞ò({{roomtemp_ours}}‚ÑÉ)Ïù¥ ÏòÜÎ∞ò({{roomtemp_beside}}‚ÑÉ)Î≥¥Îã§ {{roomtemp_diff}}‚ÑÉ ÎÜíÏäµÎãàÎã§.']\n",
      "Í≤∞Í≥º: {'roomtemp_ours': 27.447997189037245, 'roomtemp_beside': 26.646521433591005, 'roomtemp_diff': 0.8014757554462406}\n",
      "\n",
      "ÎãµÎ≥Ä:\n",
      "Ïò§Îäò Ïö∞Î¶¨Î∞òÍ≥º ÏòÜÎ∞òÏùò ÌèâÍ∑† Ïò®ÎèÑÏ∞®Ïù¥Îäî 0.8‚ÑÉÏûÖÎãàÎã§.\n",
      "Time elapsed: 0.9968817234039307\n",
      "====================================================\n",
      "\n",
      "ÏßàÎ¨∏: ÏûëÎÖÑ Í≤®Ïö∏ Ïö∞Î¶¨Î∞ò ÌèâÍ∑†Ïò®ÎèÑ ÏïåÎ†§Ï§ò\n",
      "Metadata: {'site_name': 'YongDongIllHighSchool', 'user_name': 'ÌôçÍ∏∏Îèô', 'user_role': 'customer', 'idu_name': '01_IB5', 'idu_mapping': {'01_IB5': ['Ïö∞Î¶¨Î∞ò'], '01_IB7': ['ÏòÜÎ∞ò'], '02_I81': ['ÏïûÎ∞ò']}, 'modality_mapping': {'roomtemp': ['Ïã§ÎÇ¥Ïò®ÎèÑ'], 'settemp': ['ÏÑ§Ï†ïÏò®ÎèÑ'], 'oper': ['Ï†ÑÏõê']}, 'current_datetime': '2022-09-30 12:00:00'}\n",
      "ÏòàÏãú: ['ÏûëÎÖÑ Í≤®Ïö∏(2021-12 ~ 2022-02) Ïö∞Î¶¨Î∞òÏùò ÌèâÍ∑† Ïò®ÎèÑÎäî {{roomtemp_avg}}‚ÑÉ ÏûÖÎãàÎã§.']\n",
      "Í≤∞Í≥º: {'roomtemp_avg': -1.0}\n",
      "\n",
      "ÎãµÎ≥Ä:\n",
      "ÏûëÎÖÑ Í≤®Ïö∏(2021-12 ~ 2022-02) Ïö∞Î¶¨Î∞òÏùò ÌèâÍ∑† Ïò®ÎèÑÎäî -1.0‚ÑÉ ÏûÖÎãàÎã§.\n",
      "Time elapsed: 1.2529222965240479\n",
      "====================================================\n",
      "\n",
      "ÏßàÎ¨∏: Ïò¨Ìï¥ Ïó¨Î¶Ñ ÏïûÎ∞ò ÌèâÍ∑†Ïò®ÎèÑ ÏïåÎ†§Ï§ò\n",
      "Metadata: {'site_name': 'YongDongIllHighSchool', 'user_name': 'ÌôçÍ∏∏Îèô', 'user_role': 'customer', 'idu_name': '01_IB5', 'idu_mapping': {'01_IB5': ['Ïö∞Î¶¨Î∞ò'], '01_IB7': ['ÏòÜÎ∞ò'], '02_I81': ['ÏïûÎ∞ò']}, 'modality_mapping': {'roomtemp': ['Ïã§ÎÇ¥Ïò®ÎèÑ'], 'settemp': ['ÏÑ§Ï†ïÏò®ÎèÑ'], 'oper': ['Ï†ÑÏõê']}, 'current_datetime': '2022-09-30 12:00:00'}\n",
      "ÏòàÏãú: ['Ïò¨Ìï¥ Ïó¨Î¶Ñ(6Ïõî ~ 8Ïõî) ÏïûÎ∞òÏùò ÌèâÍ∑† Ïò®ÎèÑÎäî {{roomtemp_avg}}‚ÑÉ ÏûÖÎãàÎã§.']\n",
      "Í≤∞Í≥º: {'roomtemp_avg': 26.108745462794918}\n",
      "\n",
      "ÎãµÎ≥Ä:\n",
      "Ïò¨Ìï¥ Ïó¨Î¶Ñ(6Ïõî ~ 8Ïõî) ÏïûÎ∞òÏùò ÌèâÍ∑† Ïò®ÎèÑÎäî 26.11‚ÑÉÏûÖÎãàÎã§.\n",
      "Time elapsed: 1.1461598873138428\n",
      "====================================================\n",
      "\n",
      "ÏßàÎ¨∏: Ïò¨Ïó¨Î¶Ñ Ï†úÏùº ÎçîÏõ†Îçò ÎÇ† ÏïåÎ†§Ï§ò\n",
      "Metadata: {'site_name': 'YongDongIllHighSchool', 'user_name': 'ÌôçÍ∏∏Îèô', 'user_role': 'customer', 'idu_name': '01_IB5', 'idu_mapping': {'01_IB5': ['Ïö∞Î¶¨Î∞ò'], '01_IB7': ['ÏòÜÎ∞ò'], '02_I81': ['ÏïûÎ∞ò']}, 'modality_mapping': {'roomtemp': ['Ïã§ÎÇ¥Ïò®ÎèÑ'], 'settemp': ['ÏÑ§Ï†ïÏò®ÎèÑ'], 'oper': ['Ï†ÑÏõê']}, 'current_datetime': '2022-09-30 12:00:00'}\n",
      "ÏòàÏãú: ['Ïò¨Ïó¨Î¶Ñ Ïö∞Î¶¨Î∞òÏùÄ {{hottest_dates}}Ïóê Ïã§ÎÇ¥Ïò®ÎèÑ {{hottest_temp}}‚ÑÉÎ°ú Í∞ÄÏû• ÎçîÏõ†ÏäµÎãàÎã§.']\n",
      "Í≤∞Í≥º: {'hottest_dates': ['2022-08-18', '2022-08-16'], 'hottest_temp': 27.5}\n",
      "\n",
      "ÎãµÎ≥Ä:\n",
      "Ïò¨Ïó¨Î¶Ñ Ïö∞Î¶¨Î∞òÏùÄ 2022-08-18, 2022-08-16Ïóê Ïã§ÎÇ¥Ïò®ÎèÑ 27.5‚ÑÉÎ°ú Í∞ÄÏû• ÎçîÏõ†ÏäµÎãàÎã§.\n",
      "Time elapsed: 1.4626200199127197\n",
      "====================================================\n",
      "\n",
      "ÏßàÎ¨∏: Ïò¨Ìï¥ Î¥Ñ ÏòÜÎ∞ò Ï†úÏùº Ï∂îÏõ†Îçò ÎÇ† ÏïåÎ†§Ï§ò\n",
      "Metadata: {'site_name': 'YongDongIllHighSchool', 'user_name': 'ÌôçÍ∏∏Îèô', 'user_role': 'customer', 'idu_name': '01_IB5', 'idu_mapping': {'01_IB5': ['Ïö∞Î¶¨Î∞ò'], '01_IB7': ['ÏòÜÎ∞ò'], '02_I81': ['ÏïûÎ∞ò']}, 'modality_mapping': {'roomtemp': ['Ïã§ÎÇ¥Ïò®ÎèÑ'], 'settemp': ['ÏÑ§Ï†ïÏò®ÎèÑ'], 'oper': ['Ï†ÑÏõê']}, 'current_datetime': '2022-09-30 12:00:00'}\n",
      "ÏòàÏãú: ['Ïò¨Ìï¥ Î¥Ñ ÏòÜÎ∞òÏùÄ {{coldest_dates}}Ïóê {{coldest_temp}}‚ÑÉÎ°ú Ï†úÏùº Ï∂îÏõ†ÏäµÎãàÎã§.']\n",
      "Í≤∞Í≥º: {'coldest_dates': ['2022-05-26', '2022-05-27', '2022-05-28', '2022-05-29', '2022-05-30', '2022-05-31', '2022-05-05', '2022-03-02', '2022-03-24', '2022-03-25', '2022-03-26', '2022-03-27', '2022-03-28', '2022-03-29', '2022-03-30', '2022-03-01', '2022-04-14', '2022-04-15', '2022-04-16', '2022-04-17', '2022-04-18', '2022-03-17', '2022-03-18', '2022-03-19', '2022-03-20', '2022-03-21', '2022-03-03', '2022-03-04', '2022-03-05', '2022-03-06', '2022-03-07', '2022-03-08', '2022-03-09', '2022-04-19', '2022-04-20', '2022-03-22', '2022-03-23', '2022-05-19', '2022-05-20', '2022-05-21', '2022-05-22', '2022-05-23', '2022-05-24', '2022-05-25', '2022-05-06', '2022-05-07', '2022-05-08', '2022-05-09', '2022-04-07', '2022-04-08', '2022-04-09', '2022-04-21', '2022-04-22', '2022-04-10', '2022-04-11', '2022-04-12', '2022-04-13', '2022-04-23', '2022-04-24', '2022-04-25', '2022-04-26', '2022-04-27', '2022-03-31', '2022-04-01', '2022-04-02', '2022-04-03', '2022-04-04', '2022-04-05', '2022-04-06', '2022-03-10', '2022-03-11', '2022-03-12', '2022-03-13', '2022-03-14', '2022-03-15', '2022-03-16', '2022-04-28', '2022-04-29', '2022-04-30', '2022-05-01', '2022-05-02', '2022-05-03', '2022-05-04', '2022-05-12', '2022-05-13', '2022-05-14', '2022-05-15', '2022-05-16', '2022-05-17', '2022-05-10', '2022-05-11', '2022-05-18'], 'coldest_temp': -1.0}\n",
      "\n",
      "ÎãµÎ≥Ä:\n",
      "None\n",
      "Time elapsed: 95.04972195625305\n",
      "====================================================\n",
      "\n",
      "ÏßàÎ¨∏: 4Ïõî ÏïûÎ∞ò ÌèâÍ∑†Ïò®ÎèÑ ÏïåÎ†§Ï§ò\n",
      "Metadata: {'site_name': 'YongDongIllHighSchool', 'user_name': 'ÌôçÍ∏∏Îèô', 'user_role': 'customer', 'idu_name': '01_IB5', 'idu_mapping': {'01_IB5': ['Ïö∞Î¶¨Î∞ò'], '01_IB7': ['ÏòÜÎ∞ò'], '02_I81': ['ÏïûÎ∞ò']}, 'modality_mapping': {'roomtemp': ['Ïã§ÎÇ¥Ïò®ÎèÑ'], 'settemp': ['ÏÑ§Ï†ïÏò®ÎèÑ'], 'oper': ['Ï†ÑÏõê']}, 'current_datetime': '2022-09-30 12:00:00'}\n",
      "ÏòàÏãú: ['4Ïõî ÏïûÎ∞òÏùò ÌèâÍ∑† Ïò®ÎèÑÎäî {{roomtemp_avg}}‚ÑÉ ÏûÖÎãàÎã§.']\n",
      "Í≤∞Í≥º: {'roomtemp_avg': -1.0}\n",
      "\n",
      "ÎãµÎ≥Ä:\n",
      "4Ïõî ÏïûÎ∞òÏùò ÌèâÍ∑† Ïò®ÎèÑÎäî -1.0‚ÑÉ ÏûÖÎãàÎã§.\n",
      "Time elapsed: 0.8864097595214844\n",
      "====================================================\n",
      "\n",
      "ÏßàÎ¨∏: Ïù¥Î≤àÎã¨ Ï§ë Ïö∞Î¶¨Î∞ò Ïò®ÎèÑÍ∞Ä Í∞ÄÏû• Îçú ÎçîÏö¥ÎÇ†Ïù¥ Ïñ∏Ï†úÏïº?\n",
      "Metadata: {'site_name': 'YongDongIllHighSchool', 'user_name': 'ÌôçÍ∏∏Îèô', 'user_role': 'customer', 'idu_name': '01_IB5', 'idu_mapping': {'01_IB5': ['Ïö∞Î¶¨Î∞ò'], '01_IB7': ['ÏòÜÎ∞ò'], '02_I81': ['ÏïûÎ∞ò']}, 'modality_mapping': {'roomtemp': ['Ïã§ÎÇ¥Ïò®ÎèÑ'], 'settemp': ['ÏÑ§Ï†ïÏò®ÎèÑ'], 'oper': ['Ï†ÑÏõê']}, 'current_datetime': '2022-09-30 12:00:00'}\n",
      "ÏòàÏãú: ['Ïù¥Î≤àÎã¨ Ïö∞Î¶¨Î∞òÏùÄ {{coldest_dates}}Ïóê {{coldest_temp}}‚ÑÉÎ°ú Í∞ÄÏû• Îçú ÎçîÏõ†ÏäµÎãàÎã§.']\n",
      "Í≤∞Í≥º: {'coldest_dates': ['2022-09-07', '2022-09-27'], 'coldest_temp': 22.5}\n",
      "\n",
      "ÎãµÎ≥Ä:\n",
      "Ïù¥Î≤àÎã¨ Ïö∞Î¶¨Î∞òÏùÄ 2022-09-07, 2022-09-27Ïóê 22.5‚ÑÉÎ°ú Í∞ÄÏû• Îçú ÎçîÏõ†ÏäµÎãàÎã§.\n",
      "Time elapsed: 1.4223082065582275\n",
      "====================================================\n",
      "\n",
      "ÏßàÎ¨∏: 2Ï£ºÏ†Ñ Ïö∞Î¶¨Î∞òÍ≥º ÏòÜÎ∞ò Ìï©Ï≥êÏÑú ÏÑ§Ï†ïÏò®ÎèÑÍ∞Ä Í∞ÄÏû• ÎÇÆÏùÄÎÇ†Ïù¥ Ïñ∏Ï†úÏïº?\n",
      "Metadata: {'site_name': 'YongDongIllHighSchool', 'user_name': 'ÌôçÍ∏∏Îèô', 'user_role': 'customer', 'idu_name': '01_IB5', 'idu_mapping': {'01_IB5': ['Ïö∞Î¶¨Î∞ò'], '01_IB7': ['ÏòÜÎ∞ò'], '02_I81': ['ÏïûÎ∞ò']}, 'modality_mapping': {'roomtemp': ['Ïã§ÎÇ¥Ïò®ÎèÑ'], 'settemp': ['ÏÑ§Ï†ïÏò®ÎèÑ'], 'oper': ['Ï†ÑÏõê']}, 'current_datetime': '2022-09-30 12:00:00'}\n",
      "ÏòàÏãú: ['2Ï£ºÏ†Ñ Ïö∞Î¶¨Î∞òÍ≥º ÏòÜÎ∞ò Ìï©Ï≥êÏÑú ÏÑ§Ï†ïÏò®ÎèÑÍ∞Ä Í∞ÄÏû• ÎÇÆÏùÄ ÎÇ†ÏùÄ {{coldest_dates}}Î°ú {{coldest_temp}}‚ÑÉÏòÄÏäµÎãàÎã§.']\n",
      "Í≤∞Í≥º: {'coldest_dates': ['2022-09-14', '2022-09-13', '2022-09-12', '2022-09-18', '2022-09-17', '2022-09-16', '2022-09-15'], 'coldest_temp': 23.0}\n",
      "\n",
      "ÎãµÎ≥Ä:\n",
      "2Ï£ºÏ†Ñ Ïö∞Î¶¨Î∞òÍ≥º ÏòÜÎ∞ò Ìï©Ï≥êÏÑú ÏÑ§Ï†ïÏò®ÎèÑÍ∞Ä Í∞ÄÏû• ÎÇÆÏùÄ ÎÇ†ÏùÄ 2022-09-14, 2022-09-13, 2022-09-12, 2022-09-18, 2022-09-17, 2022-09-16, 2022-09-15 Î°ú, 23.0‚ÑÉÏòÄÏäµÎãàÎã§.\n",
      "Time elapsed: 2.7742819786071777\n",
      "====================================================\n",
      "\n",
      "ÏßàÎ¨∏: Ïù¥Î≤àÎã¨ Ï§ë Îí∑Î∞ò Ïò®ÎèÑÍ∞Ä Í∞ÄÏû• ÎçîÏö¥ÎÇ†Ïù¥ Ïñ∏Ï†úÏïº?\n",
      "Metadata: {'site_name': 'YongDongIllHighSchool', 'user_name': 'ÌôçÍ∏∏Îèô', 'user_role': 'customer', 'idu_name': '01_IB5', 'idu_mapping': {'01_IB5': ['Ïö∞Î¶¨Î∞ò'], '01_IB7': ['ÏòÜÎ∞ò'], '02_I81': ['ÏïûÎ∞ò']}, 'modality_mapping': {'roomtemp': ['Ïã§ÎÇ¥Ïò®ÎèÑ'], 'settemp': ['ÏÑ§Ï†ïÏò®ÎèÑ'], 'oper': ['Ï†ÑÏõê']}, 'current_datetime': '2022-09-30 12:00:00'}\n",
      "ÏòàÏãú: ['Îí∑Î∞òÏù¥ Ïñ¥ÎîîÏù∏ÏßÄ ÏïåÎ†§Ï£ºÏÑ∏Ïöî.']\n",
      "Í≤∞Í≥º: {}\n",
      "\n",
      "ÎãµÎ≥Ä:\n",
      "Îí∑Î∞ò Ïò®ÎèÑÍ∞Ä Í∞ÄÏû• ÎçîÏö¥ÎÇ†Ïù¥ Ïñ∏Ï†úÏïº? ÎùºÎäî ÏßàÎ¨∏Ïóê ÎåÄÌïú ÎãµÎ≥ÄÏùÄ Îã§ÏùåÍ≥º Í∞ôÏäµÎãàÎã§.\n",
      "\n",
      "Îí∑Î∞ò Ïò®ÎèÑÍ∞Ä Í∞ÄÏû• ÎçîÏö¥ÎÇ†ÏùÄ ÌòÑÏû¨ Ï†ïÎ≥¥Í∞Ä ÏóÜÏúºÎØÄÎ°ú, Îí∑Î∞òÏùò ÏúÑÏπòÎ•º ÏïåÎ†§Ï£ºÏÑ∏Ïöî.\n",
      "Time elapsed: 1.839982032775879\n",
      "====================================================\n",
      "\n",
      "ÏßàÎ¨∏: Ïö∞Î¶¨Î∞òÏùò Í∞ÄÏû• ÏµúÍ∑º ÏÑ§Ï†ï Ïò®ÎèÑ ÏïåÎ†§Ï§ò\n",
      "Metadata: {'site_name': 'YongDongIllHighSchool', 'user_name': 'ÌôçÍ∏∏Îèô', 'user_role': 'customer', 'idu_name': '01_IB5', 'idu_mapping': {'01_IB5': ['Ïö∞Î¶¨Î∞ò'], '01_IB7': ['ÏòÜÎ∞ò'], '02_I81': ['ÏïûÎ∞ò']}, 'modality_mapping': {'roomtemp': ['Ïã§ÎÇ¥Ïò®ÎèÑ'], 'settemp': ['ÏÑ§Ï†ïÏò®ÎèÑ'], 'oper': ['Ï†ÑÏõê']}, 'current_datetime': '2022-09-30 12:00:00'}\n",
      "ÏòàÏãú: ['Ïö∞Î¶¨Î∞òÏùò Í∞ÄÏû• ÏµúÍ∑º ÏÑ§Ï†ïÏò®ÎèÑÎäî {{settemp_recent_time}}Ïóê ÏÑ§Ï†ïÎêú {{settemp_recent}}‚ÑÉÏûÖÎãàÎã§.']\n",
      "Í≤∞Í≥º: {'settemp_recent': 23.0, 'settemp_recent_time': '2022-09-30 12:00:00'}\n",
      "\n",
      "ÎãµÎ≥Ä:\n",
      "Ïö∞Î¶¨Î∞òÏùò Í∞ÄÏû• ÏµúÍ∑º ÏÑ§Ï†ï Ïò®ÎèÑÎäî 2022-09-30 12:00:00Ïóê ÏÑ§Ï†ïÎêú 23.0‚ÑÉÏûÖÎãàÎã§.\n",
      "Time elapsed: 1.3382329940795898\n",
      "====================================================\n",
      "\n",
      "ÏßàÎ¨∏: ÏòÜÎ∞òÏùò Í∞ÄÏû• ÏµúÍ∑º Ïò®ÎèÑÎûë ÏÑ§Ï†ïÏò®ÎèÑ ÏïåÎ†§Ï§ò\n",
      "Metadata: {'site_name': 'YongDongIllHighSchool', 'user_name': 'ÌôçÍ∏∏Îèô', 'user_role': 'customer', 'idu_name': '01_IB5', 'idu_mapping': {'01_IB5': ['Ïö∞Î¶¨Î∞ò'], '01_IB7': ['ÏòÜÎ∞ò'], '02_I81': ['ÏïûÎ∞ò']}, 'modality_mapping': {'roomtemp': ['Ïã§ÎÇ¥Ïò®ÎèÑ'], 'settemp': ['ÏÑ§Ï†ïÏò®ÎèÑ'], 'oper': ['Ï†ÑÏõê']}, 'current_datetime': '2022-09-30 12:00:00'}\n",
      "ÏòàÏãú: ['ÏòÜÎ∞òÏùò Í∞ÄÏû• ÏµúÍ∑º Ïã§ÎÇ¥Ïò®ÎèÑÎäî {{recent_time}}Ïóê Ï∏°Ï†ïÎêú {{roomtemp_recent}}‚ÑÉÏù¥Í≥†, ÏÑ§Ï†ïÏò®ÎèÑÎäî {{recent_time}}Ïóê ÏÑ§Ï†ïÎêú {{settemp_recent}}‚ÑÉÏûÖÎãàÎã§.']\n",
      "Í≤∞Í≥º: {'roomtemp_recent': 27.0, 'settemp_recent': 23.0, 'recent_time': '2022-09-30 12:00:00'}\n",
      "\n",
      "ÎãµÎ≥Ä:\n",
      "ÏòÜÎ∞òÏùò Í∞ÄÏû• ÏµúÍ∑º Ïã§ÎÇ¥Ïò®ÎèÑÎäî 2022-09-30 12:00:00Ïóê Ï∏°Ï†ïÎêú 27.0‚ÑÉÏù¥Í≥†, ÏÑ§Ï†ïÏò®ÎèÑÎäî 2022-09-30 12:00:00Ïóê ÏÑ§Ï†ïÎêú 23.0‚ÑÉÏûÖÎãàÎã§.\n",
      "Time elapsed: 2.16961932182312\n",
      "====================================================\n",
      "\n",
      "ÏßàÎ¨∏: Ïö∞Î¶¨Î∞ò ÏôúÏù¥Î¶¨ Îç•ÎÖ∏\n",
      "Metadata: {'site_name': 'YongDongIllHighSchool', 'user_name': 'ÌôçÍ∏∏Îèô', 'user_role': 'customer', 'idu_name': '01_IB5', 'idu_mapping': {'01_IB5': ['Ïö∞Î¶¨Î∞ò'], '01_IB7': ['ÏòÜÎ∞ò'], '02_I81': ['ÏïûÎ∞ò']}, 'modality_mapping': {'roomtemp': ['Ïã§ÎÇ¥Ïò®ÎèÑ'], 'settemp': ['ÏÑ§Ï†ïÏò®ÎèÑ'], 'oper': ['Ï†ÑÏõê']}, 'current_datetime': '2022-09-30 12:00:00'}\n",
      "ÏòàÏãú: ['ÏßÄÍ∏à Ïö∞Î¶¨Î∞òÏùÄ 27.3‚ÑÉÏù∏Îç∞ ÏóêÏñ¥Ïª® ÏÑ§Ï†ïÏò®ÎèÑÎäî 28‚ÑÉÎ°ú Ïã§ÎÇ¥Ïò®ÎèÑÎ≥¥Îã§ ÎÜíÎÑ§Ïöî. ÏÑ§Ï†ïÏò®ÎèÑÎ•º ÎÇÆÏ∂îÎ©¥ ÏãúÏõêÌï¥Ïßà Í±∞ÏóêÏöî.', 'ÏßÄÍ∏à Ïö∞Î¶¨Î∞òÏùÄ 30.6‚ÑÉÎ°ú ÎçîÏö¥Îç∞ ÏóêÏñ¥Ïª®Ïù¥ Í∫ºÏ†∏ÏûàÎÑ§Ïöî. ÏóêÏñ¥Ïª®ÏùÑ ÏºúÎ©¥ ÏãúÏõêÌï¥Ïßà Í±∞ÏóêÏöî.', 'ÏßÄÍ∏à Ïö∞Î¶¨Î∞òÏùÄ 30.6‚ÑÉÏù∏Îç∞Ïöî, ÏóêÏñ¥Ïª®Ïù¥ ÏºúÏßÑÏßÄ 5Î∂ÑÎ∞ñÏóê ÏïàÎêòÏóàÍ∏∞ ÎïåÎ¨∏ÏûÖÎãàÎã§.']\n",
      "Í≤∞Í≥º: {'qr':      roomtemp  settemp   oper     id            timestamp     idu\n",
      "0        28.0     23.0  False  86940  2022-09-30 09:00:00  01_IB5\n",
      "1        28.0     23.0  False  86941  2022-09-30 09:01:00  01_IB5\n",
      "2        28.0     23.0  False  86942  2022-09-30 09:02:00  01_IB5\n",
      "3        28.0     23.0  False  86943  2022-09-30 09:03:00  01_IB5\n",
      "4        28.0     23.0  False  86944  2022-09-30 09:04:00  01_IB5\n",
      "..        ...      ...    ...    ...                  ...     ...\n",
      "173      28.0     23.0  False  87116  2022-09-30 11:56:00  01_IB5\n",
      "174      28.0     23.0  False  87117  2022-09-30 11:57:00  01_IB5\n",
      "175      28.0     23.0  False  87118  2022-09-30 11:58:00  01_IB5\n",
      "176      28.0     23.0  False  87119  2022-09-30 11:59:00  01_IB5\n",
      "177      28.0     23.0  False  87120  2022-09-30 12:00:00  01_IB5\n",
      "\n",
      "[178 rows x 6 columns]}\n",
      "\n",
      "ÎãµÎ≥Ä:\n",
      "ÏßÄÍ∏à Ïö∞Î¶¨Î∞òÏùÄ 27.3‚ÑÉÏù∏Îç∞ ÏóêÏñ¥Ïª® ÏÑ§Ï†ïÏò®ÎèÑÎäî 28‚ÑÉÎ°ú Ïã§ÎÇ¥Ïò®ÎèÑÎ≥¥Îã§ ÎÜíÎÑ§Ïöî. ÏÑ§Ï†ïÏò®ÎèÑÎ•º ÎÇÆÏ∂îÎ©¥ ÏãúÏõêÌï¥Ïßà Í±∞ÏóêÏöî.\n",
      "Time elapsed: 1.7995264530181885\n",
      "====================================================\n",
      "\n",
      "ÏßàÎ¨∏: What time is it now?\n",
      "Metadata: {'site_name': 'YongDongIllHighSchool', 'user_name': 'ÌôçÍ∏∏Îèô', 'user_role': 'customer', 'idu_name': '01_IB5', 'idu_mapping': {'01_IB5': ['Ïö∞Î¶¨Î∞ò'], '01_IB7': ['ÏòÜÎ∞ò'], '02_I81': ['ÏïûÎ∞ò']}, 'modality_mapping': {'roomtemp': ['Ïã§ÎÇ¥Ïò®ÎèÑ'], 'settemp': ['ÏÑ§Ï†ïÏò®ÎèÑ'], 'oper': ['Ï†ÑÏõê']}, 'current_datetime': '2022-09-30 12:00:00'}\n",
      "ÏòàÏãú: [\"ÌòÑÏû¨ ÏãúÍ∞ÑÏùÄ {{Metadata['current_datetime']}}ÏûÖÎãàÎã§.\"]\n",
      "Í≤∞Í≥º: {}\n",
      "\n",
      "ÎãµÎ≥Ä:\n",
      "ÌòÑÏû¨ ÏãúÍ∞ÑÏùÄ 2022-09-30 12:00:00ÏûÖÎãàÎã§.\n",
      "Time elapsed: 0.9649507999420166\n",
      "====================================================\n",
      "\n",
      "ÏßàÎ¨∏: 8ÏùºÏ†Ñ ÏÑ§Ï†ïÏò®ÎèÑÎäî?\n",
      "Metadata: {'site_name': 'YongDongIllHighSchool', 'user_name': 'ÌôçÍ∏∏Îèô', 'user_role': 'customer', 'idu_name': '01_IB5', 'idu_mapping': {'01_IB5': ['Ïö∞Î¶¨Î∞ò'], '01_IB7': ['ÏòÜÎ∞ò'], '02_I81': ['ÏïûÎ∞ò']}, 'modality_mapping': {'roomtemp': ['Ïã§ÎÇ¥Ïò®ÎèÑ'], 'settemp': ['ÏÑ§Ï†ïÏò®ÎèÑ'], 'oper': ['Ï†ÑÏõê']}, 'current_datetime': '2022-09-30 12:00:00'}\n",
      "ÏòàÏãú: ['8ÏùºÏ†Ñ Ïö∞Î¶¨Î∞òÏùò ÌèâÍ∑† ÏÑ§Ï†ïÏò®ÎèÑÎäî {{settemp_avg}}‚ÑÉÏòÄÏäµÎãàÎã§.']\n",
      "Í≤∞Í≥º: {'settemp_avg': 23.0}\n",
      "\n",
      "ÎãµÎ≥Ä:\n",
      "8ÏùºÏ†Ñ Ïö∞Î¶¨Î∞òÏùò ÌèâÍ∑† ÏÑ§Ï†ïÏò®ÎèÑÎäî 23.0‚ÑÉÏòÄÏäµÎãàÎã§.\n",
      "Time elapsed: 0.9691576957702637\n",
      "====================================================\n",
      "\n",
      "ÏßàÎ¨∏: 10ÎÖÑ Ï†Ñ Ïò§Îäò Ïö∞Î¶¨Î∞ò Ïò®ÎèÑÎäî?\n",
      "Metadata: {'site_name': 'YongDongIllHighSchool', 'user_name': 'ÌôçÍ∏∏Îèô', 'user_role': 'customer', 'idu_name': '01_IB5', 'idu_mapping': {'01_IB5': ['Ïö∞Î¶¨Î∞ò'], '01_IB7': ['ÏòÜÎ∞ò'], '02_I81': ['ÏïûÎ∞ò']}, 'modality_mapping': {'roomtemp': ['Ïã§ÎÇ¥Ïò®ÎèÑ'], 'settemp': ['ÏÑ§Ï†ïÏò®ÎèÑ'], 'oper': ['Ï†ÑÏõê']}, 'current_datetime': '2022-09-30 12:00:00'}\n",
      "ÏòàÏãú: ['10ÎÖÑ Ï†Ñ Ïò§Îäò Ïö∞Î¶¨Î∞òÏùò Ïã§ÎÇ¥Ïò®ÎèÑÎäî {{roomtemp_avg}}‚ÑÉÏòÄÏäµÎãàÎã§.']\n",
      "Í≤∞Í≥º: {'roomtemp_avg': nan}\n",
      "\n",
      "ÎãµÎ≥Ä:\n",
      "10ÎÖÑ Ï†Ñ Ïò§Îäò Ïö∞Î¶¨Î∞òÏùò Ïã§ÎÇ¥Ïò®ÎèÑÎäî ÏóÜÏäµÎãàÎã§.\n",
      "Time elapsed: 0.8324754238128662\n",
      "====================================================\n",
      "\n",
      "ÏßàÎ¨∏: Î°ØÎç∞Ï∫êÏä¨Ïùò ÌòÑÏû¨ Ïò®ÎèÑ ÏïåÎ†§Ï§ò\n",
      "Metadata: {'site_name': 'YongDongIllHighSchool', 'user_name': 'ÌôçÍ∏∏Îèô', 'user_role': 'customer', 'idu_name': '01_IB5', 'idu_mapping': {'01_IB5': ['Ïö∞Î¶¨Î∞ò'], '01_IB7': ['ÏòÜÎ∞ò'], '02_I81': ['ÏïûÎ∞ò']}, 'modality_mapping': {'roomtemp': ['Ïã§ÎÇ¥Ïò®ÎèÑ'], 'settemp': ['ÏÑ§Ï†ïÏò®ÎèÑ'], 'oper': ['Ï†ÑÏõê']}, 'current_datetime': '2022-09-30 12:00:00'}\n",
      "ÏòàÏãú: ['Î°ØÎç∞Ï∫êÏä¨Ïù¥ Ïñ¥Îñ§ Í≥≥Ïù∏ÏßÄ ÏïåÎ†§Ï£ºÏÑ∏Ïöî.']\n",
      "Í≤∞Í≥º: {}\n",
      "\n",
      "ÎãµÎ≥Ä:\n",
      "Î°ØÎç∞Ï∫êÏä¨Ïù¥ Ïñ¥Îñ§ Í≥≥Ïù∏ÏßÄ ÏïåÎ†§Ï£ºÏÑ∏Ïöî.\n",
      "Time elapsed: 0.7473015785217285\n",
      "====================================================\n",
      "\n",
      "ÏßàÎ¨∏: Îã§Ïùå ÎåÄÌÜµÎ†π ÏÑ†Í±∞Îäî Ïñ∏Ï†úÏù∏Í∞ÄÏöî?\n",
      "Metadata: {'site_name': 'YongDongIllHighSchool', 'user_name': 'ÌôçÍ∏∏Îèô', 'user_role': 'customer', 'idu_name': '01_IB5', 'idu_mapping': {'01_IB5': ['Ïö∞Î¶¨Î∞ò'], '01_IB7': ['ÏòÜÎ∞ò'], '02_I81': ['ÏïûÎ∞ò']}, 'modality_mapping': {'roomtemp': ['Ïã§ÎÇ¥Ïò®ÎèÑ'], 'settemp': ['ÏÑ§Ï†ïÏò®ÎèÑ'], 'oper': ['Ï†ÑÏõê']}, 'current_datetime': '2022-09-30 12:00:00'}\n",
      "ÏòàÏãú: ['HVAC ÏãúÏä§ÌÖúÍ≥º Í¥ÄÎ†® ÏóÜÎäî ÏßàÎ¨∏ÏûÖÎãàÎã§.']\n",
      "Í≤∞Í≥º: {}\n",
      "\n",
      "ÎãµÎ≥Ä:\n",
      "HVAC ÏãúÏä§ÌÖúÍ≥º Í¥ÄÎ†® ÏóÜÎäî ÏßàÎ¨∏ÏûÖÎãàÎã§.\n",
      "Time elapsed: 0.6906821727752686\n",
      "====================================================\n",
      "\n",
      "ÏßàÎ¨∏: 1Ï∏µ ÌèâÍ∑† Ïã§ÎÇ¥Ïò®ÎèÑ ÏïåÎ†§Ï§ò\n",
      "Metadata: {'site_name': 'YongDongIllHighSchool', 'user_name': 'ÌôçÍ∏∏Îèô', 'user_role': 'customer', 'idu_name': '01_IB5', 'idu_mapping': {'01_IB5': ['Ïö∞Î¶¨Î∞ò'], '01_IB7': ['ÏòÜÎ∞ò'], '02_I81': ['ÏïûÎ∞ò']}, 'modality_mapping': {'roomtemp': ['Ïã§ÎÇ¥Ïò®ÎèÑ'], 'settemp': ['ÏÑ§Ï†ïÏò®ÎèÑ'], 'oper': ['Ï†ÑÏõê']}, 'current_datetime': '2022-09-30 12:00:00'}\n",
      "ÏòàÏãú: ['1Ï∏µÏù¥ Ïñ¥Îñ§ Í≥≥Ïù∏ÏßÄ ÏïåÎ†§Ï£ºÏÑ∏Ïöî.']\n",
      "Í≤∞Í≥º: {}\n",
      "\n",
      "ÎãµÎ≥Ä:\n",
      "1Ï∏µÏù¥ Ïñ¥Îñ§ Í≥≥Ïù∏ÏßÄ ÏïåÎ†§Ï£ºÏÑ∏Ïöî.\n",
      "Time elapsed: 0.6943297386169434\n",
      "====================================================\n",
      "\n",
      "ÏßàÎ¨∏: ÏóêÏñ¥Ïª® Í∫ºÏßÑ Î∞©Îì§ ÏïåÎ†§Ï§ò\n",
      "Metadata: {'site_name': 'YongDongIllHighSchool', 'user_name': 'ÌôçÍ∏∏Îèô', 'user_role': 'customer', 'idu_name': '01_IB5', 'idu_mapping': {'01_IB5': ['Ïö∞Î¶¨Î∞ò'], '01_IB7': ['ÏòÜÎ∞ò'], '02_I81': ['ÏïûÎ∞ò']}, 'modality_mapping': {'roomtemp': ['Ïã§ÎÇ¥Ïò®ÎèÑ'], 'settemp': ['ÏÑ§Ï†ïÏò®ÎèÑ'], 'oper': ['Ï†ÑÏõê']}, 'current_datetime': '2022-09-30 12:00:00'}\n",
      "ÏòàÏãú: ['ÌòÑÏû¨ ÏóêÏñ¥Ïª®Ïù¥ Í∫ºÏ†∏ÏûàÎäî Î∞©ÏùÄ {{off_names}}ÏûÖÎãàÎã§.']\n",
      "Í≤∞Í≥º: {'off_names': ['01_IB5', '01_IB7', '02_I81']}\n",
      "\n",
      "ÎãµÎ≥Ä:\n",
      "ÌòÑÏû¨ ÏóêÏñ¥Ïª®Ïù¥ Í∫ºÏ†∏ÏûàÎäî Î∞©ÏùÄ 01_IB5, 01_IB7, 02_I81ÏûÖÎãàÎã§.\n",
      "Time elapsed: 1.2139787673950195\n",
      "====================================================\n",
      "\n",
      "ÏßàÎ¨∏: ÏßÄÎÇúÏ£º ÏÑ§Ï†ïÏò®ÎèÑÍ∞Ä Ïã§ÎÇ¥Ïò®ÎèÑÎ≥¥Îã§ Îçî ÎÜíÏïòÎçò ÎÇ†ÏùÄ?\n",
      "Metadata: {'site_name': 'YongDongIllHighSchool', 'user_name': 'ÌôçÍ∏∏Îèô', 'user_role': 'customer', 'idu_name': '01_IB5', 'idu_mapping': {'01_IB5': ['Ïö∞Î¶¨Î∞ò'], '01_IB7': ['ÏòÜÎ∞ò'], '02_I81': ['ÏïûÎ∞ò']}, 'modality_mapping': {'roomtemp': ['Ïã§ÎÇ¥Ïò®ÎèÑ'], 'settemp': ['ÏÑ§Ï†ïÏò®ÎèÑ'], 'oper': ['Ï†ÑÏõê']}, 'current_datetime': '2022-09-30 12:00:00'}\n",
      "ÏòàÏãú: ['ÏßÄÎÇúÏ£º Ïö∞Î¶¨Î∞òÏùÄ {{dates}}Ïóê ÏùºÌèâÍ∑† ÏÑ§Ï†ïÏò®ÎèÑ {{settemp_avg}}‚ÑÉÎ°ú Ïã§ÎÇ¥Ïò®ÎèÑ {{roomtemp_avg}}‚ÑÉÎ≥¥Îã§ ÎÜíÏïòÏäµÎãàÎã§.']\n",
      "Í≤∞Í≥º: {'dates': []}\n",
      "\n",
      "ÎãµÎ≥Ä:\n",
      "ÏßÄÎÇúÏ£º Ïö∞Î¶¨Î∞òÏùÄ ÏÑ§Ï†ïÏò®ÎèÑÍ∞Ä Ïã§ÎÇ¥Ïò®ÎèÑÎ≥¥Îã§ Îçî ÎÜíÏïòÎçò ÎÇ†ÏùÄ ÏóÜÏäµÎãàÎã§.\n",
      "Time elapsed: 1.0522291660308838\n",
      "====================================================\n",
      "\n",
      "ÏßàÎ¨∏: Ïö∞Î¶¨Î∞ò Ïù¥Î≤àÎã¨ Ï†úÏùº Ï∂îÏõ†Îçò ÎÇ†ÏùÄ Ïñ∏Ï†úÎÉê?\n",
      "Metadata: {'site_name': 'YongDongIllHighSchool', 'user_name': 'ÌôçÍ∏∏Îèô', 'user_role': 'customer', 'idu_name': '01_IB5', 'idu_mapping': {'01_IB5': ['Ïö∞Î¶¨Î∞ò'], '01_IB7': ['ÏòÜÎ∞ò'], '02_I81': ['ÏïûÎ∞ò']}, 'modality_mapping': {'roomtemp': ['Ïã§ÎÇ¥Ïò®ÎèÑ'], 'settemp': ['ÏÑ§Ï†ïÏò®ÎèÑ'], 'oper': ['Ï†ÑÏõê']}, 'current_datetime': '2022-09-30 12:00:00'}\n",
      "ÏòàÏãú: ['Ïù¥Î≤àÎã¨ Ïö∞Î¶¨Î∞òÏùÄ {{coldest_dates}}Ïóê {{coldest_temp}}‚ÑÉÎ°ú Í∞ÄÏû• Ï∂îÏõ†ÏäµÎãàÎã§.']\n",
      "Í≤∞Í≥º: {'coldest_dates': ['2022-09-27', '2022-09-07'], 'coldest_temp': 22.5}\n",
      "\n",
      "ÎãµÎ≥Ä:\n",
      "Ïù¥Î≤àÎã¨ Ïö∞Î¶¨Î∞òÏùÄ 2022-09-27, 2022-09-07Ïóê 22.5‚ÑÉÎ°ú Í∞ÄÏû• Ï∂îÏõ†ÏäµÎãàÎã§.\n",
      "Time elapsed: 1.3740651607513428\n",
      "====================================================\n",
      "\n",
      "ÏßàÎ¨∏: Ïñ¥Ï†ú Ïö∞Î¶¨Î∞ò ÏóêÏñ¥Ïª® ÏûëÎèô ÏãúÍ∞Ñ ÏïåÎ†§Ï§ò\n",
      "Metadata: {'site_name': 'YongDongIllHighSchool', 'user_name': 'ÌôçÍ∏∏Îèô', 'user_role': 'customer', 'idu_name': '01_IB5', 'idu_mapping': {'01_IB5': ['Ïö∞Î¶¨Î∞ò'], '01_IB7': ['ÏòÜÎ∞ò'], '02_I81': ['ÏïûÎ∞ò']}, 'modality_mapping': {'roomtemp': ['Ïã§ÎÇ¥Ïò®ÎèÑ'], 'settemp': ['ÏÑ§Ï†ïÏò®ÎèÑ'], 'oper': ['Ï†ÑÏõê']}, 'current_datetime': '2022-09-30 12:00:00'}\n",
      "ÏòàÏãú: ['Ïñ¥Ï†ú Ïö∞Î¶¨Î∞òÏùÄ Ï¥ù 5ÏãúÍ∞Ñ 14Î∂Ñ ÎèôÏïà ÏóêÏñ¥Ïª®ÏùÑ ÏûëÎèôÌñàÏäµÎãàÎã§.']\n",
      "Í≤∞Í≥º: {'total_time': -56640.0}\n",
      "\n",
      "ÎãµÎ≥Ä:\n",
      "Ïñ¥Ï†ú Ïö∞Î¶¨Î∞òÏùÄ Ï¥ù 5ÏãúÍ∞Ñ 14Î∂Ñ ÎèôÏïà ÏóêÏñ¥Ïª®ÏùÑ ÏûëÎèôÌñàÏäµÎãàÎã§.\n",
      "Time elapsed: 1.02634596824646\n",
      "====================================================\n",
      "\n",
      "ÏßàÎ¨∏: Ïö∞Î¶¨Î∞ò, ÏòÜÎ∞ò, ÏïûÎ∞ò Ï§ë Í∞ÄÏû• Ï∂îÏö¥ Î∞©ÏùÄ?\n",
      "Metadata: {'site_name': 'YongDongIllHighSchool', 'user_name': 'ÌôçÍ∏∏Îèô', 'user_role': 'customer', 'idu_name': '01_IB5', 'idu_mapping': {'01_IB5': ['Ïö∞Î¶¨Î∞ò'], '01_IB7': ['ÏòÜÎ∞ò'], '02_I81': ['ÏïûÎ∞ò']}, 'modality_mapping': {'roomtemp': ['Ïã§ÎÇ¥Ïò®ÎèÑ'], 'settemp': ['ÏÑ§Ï†ïÏò®ÎèÑ'], 'oper': ['Ï†ÑÏõê']}, 'current_datetime': '2022-09-30 12:00:00'}\n",
      "ÏòàÏãú: ['ÏßÄÍ∏à ÏÑ∏ Î∞© Ï§ë {{coldest_rooms}}Ïù¥(Í∞Ä) {{coldest_temp}}‚ÑÉÎ°ú Í∞ÄÏû• Ï∂îÏõåÏöî.']\n",
      "Í≤∞Í≥º: {'coldest_rooms': ['02_I81'], 'coldest_temp': 26.0}\n",
      "\n",
      "ÎãµÎ≥Ä:\n",
      "ÏßÄÍ∏à ÏÑ∏ Î∞© Ï§ë ÏïûÎ∞ò(02_I81)Ïù¥ 26.0‚ÑÉÎ°ú Í∞ÄÏû• Ï∂îÏõåÏöî.\n",
      "Time elapsed: 1.0811412334442139\n",
      "====================================================\n",
      "\n",
      "ÏßàÎ¨∏: ÎÜçÎã¥ Ï¢Ä Ìï¥Ï§ò\n",
      "Metadata: {'site_name': 'YongDongIllHighSchool', 'user_name': 'ÌôçÍ∏∏Îèô', 'user_role': 'customer', 'idu_name': '01_IB5', 'idu_mapping': {'01_IB5': ['Ïö∞Î¶¨Î∞ò'], '01_IB7': ['ÏòÜÎ∞ò'], '02_I81': ['ÏïûÎ∞ò']}, 'modality_mapping': {'roomtemp': ['Ïã§ÎÇ¥Ïò®ÎèÑ'], 'settemp': ['ÏÑ§Ï†ïÏò®ÎèÑ'], 'oper': ['Ï†ÑÏõê']}, 'current_datetime': '2022-09-30 12:00:00'}\n",
      "ÏòàÏãú: ['HVAC ÏãúÏä§ÌÖúÍ≥º Í¥ÄÎ†® ÏóÜÎäî ÏßàÎ¨∏ÏûÖÎãàÎã§.']\n",
      "Í≤∞Í≥º: {}\n",
      "\n",
      "ÎãµÎ≥Ä:\n",
      "HVAC ÏãúÏä§ÌÖúÍ≥º Í¥ÄÎ†® ÏóÜÎäî ÏßàÎ¨∏ÏûÖÎãàÎã§.\n",
      "Time elapsed: 0.695850133895874\n",
      "====================================================\n",
      "\n",
      "ÏßàÎ¨∏: ÏóêÏñ¥Ïº† Ï†úÏùº ÏÑ∏Í≤å ÌÇ® Î∞© 3Í∞ú ÏïåÎ†§Ï§ò\n",
      "Metadata: {'site_name': 'YongDongIllHighSchool', 'user_name': 'ÌôçÍ∏∏Îèô', 'user_role': 'customer', 'idu_name': '01_IB5', 'idu_mapping': {'01_IB5': ['Ïö∞Î¶¨Î∞ò'], '01_IB7': ['ÏòÜÎ∞ò'], '02_I81': ['ÏïûÎ∞ò']}, 'modality_mapping': {'roomtemp': ['Ïã§ÎÇ¥Ïò®ÎèÑ'], 'settemp': ['ÏÑ§Ï†ïÏò®ÎèÑ'], 'oper': ['Ï†ÑÏõê']}, 'current_datetime': '2022-09-30 12:00:00'}\n",
      "ÏòàÏãú: ['ÏóêÏñ¥Ïª®ÏùÑ Ï†úÏùº ÏÑ∏Í≤å ÌÇ® Î∞©ÏùÄ ÏàúÏÑúÎåÄÎ°ú {{top3_rooms}}ÏûÖÎãàÎã§.', 'ÏóêÏñ¥Ïª®ÏùÑ Ï†úÏùº ÏÑ∏Í≤å ÌÇ® Î∞©ÏùÄ ÏàúÏÑúÎåÄÎ°ú {{top3_rooms[0]}}({{top3_temps[0]}}‚ÑÉ), {{top3_rooms[1]}}({{top3_temps[1]}}‚ÑÉ), {{top3_rooms[2]}}({{top3_temps[2]}}‚ÑÉ)ÏûÖÎãàÎã§.']\n",
      "Í≤∞Í≥º: {'top3_rooms': [], 'top3_temps': []}\n",
      "\n",
      "ÎãµÎ≥Ä:\n",
      "ÏóêÏñ¥Ïª®ÏùÑ Ï†úÏùº ÏÑ∏Í≤å ÌÇ® Î∞©ÏùÄ ÏàúÏÑúÎåÄÎ°ú ÏóÜÏäµÎãàÎã§.\n",
      "Time elapsed: 0.9306678771972656\n",
      "====================================================\n",
      "\n",
      "ÏßàÎ¨∏: ÏûëÎÖÑ ÏòÜÎ∞ò Í∞ÄÏû• ÎçîÏõ†Îçò Îã¨ÏùÄ?\n",
      "Metadata: {'site_name': 'YongDongIllHighSchool', 'user_name': 'ÌôçÍ∏∏Îèô', 'user_role': 'customer', 'idu_name': '01_IB5', 'idu_mapping': {'01_IB5': ['Ïö∞Î¶¨Î∞ò'], '01_IB7': ['ÏòÜÎ∞ò'], '02_I81': ['ÏïûÎ∞ò']}, 'modality_mapping': {'roomtemp': ['Ïã§ÎÇ¥Ïò®ÎèÑ'], 'settemp': ['ÏÑ§Ï†ïÏò®ÎèÑ'], 'oper': ['Ï†ÑÏõê']}, 'current_datetime': '2022-09-30 12:00:00'}\n",
      "ÏòàÏãú: ['ÏûëÎÖÑ {{hottest_dates}}Ïóê {{hottest_temp}}‚ÑÉÎ°ú Í∞ÄÏû• ÎçîÏõ†ÏäµÎãàÎã§.']\n",
      "Í≤∞Í≥º: {'hottest_dates': ['2021-12-30', '2021-12-31', '2021-01-14', '2021-01-15', '2021-01-16', '2021-01-17', '2021-01-18', '2021-01-19', '2021-01-20', '2021-09-30', '2021-06-17', '2021-06-18', '2021-06-10', '2021-08-19', '2021-08-20', '2021-09-02', '2021-09-03', '2021-08-05', '2021-08-06', '2021-03-11', '2021-03-12', '2021-02-04', '2021-02-05', '2021-06-19', '2021-06-20', '2021-06-11', '2021-06-12', '2021-08-21', '2021-08-22', '2021-09-04', '2021-09-05', '2021-08-07', '2021-03-13', '2021-03-14', '2021-02-06', '2021-02-07', '2021-06-21', '2021-06-13', '2021-06-14', '2021-08-23', '2021-09-06', '2021-08-08', '2021-08-09', '2021-03-15', '2021-02-08', '2021-06-22', '2021-06-23', '2021-06-15', '2021-08-24', '2021-09-07', '2021-09-08', '2021-08-10', '2021-03-16', '2021-02-09', '2021-06-16', '2021-08-25', '2021-08-11', '2021-03-17', '2021-02-10', '2021-10-01', '2021-10-02', '2021-10-03', '2021-10-04', '2021-10-05', '2021-10-06', '2021-07-29', '2021-03-25', '2021-03-26', '2021-10-14', '2021-10-15', '2021-01-07', '2021-01-08', '2021-04-01', '2021-04-02', '2021-11-04', '2021-11-05', '2021-03-18', '2021-03-19', '2021-06-24', '2021-06-25', '2021-03-27', '2021-10-16', '2021-01-09', '2021-04-03', '2021-11-06', '2021-03-20', '2021-06-26', '2021-03-28', '2021-10-17', '2021-10-18', '2021-01-10', '2021-01-11', '2021-04-04', '2021-04-05', '2021-11-07', '2021-11-08', '2021-03-21', '2021-03-22', '2021-06-27', '2021-03-29', '2021-03-30', '2021-10-19', '2021-10-20', '2021-01-12', '2021-01-13', '2021-04-06', '2021-11-09', '2021-03-23', '2021-03-24', '2021-06-28', '2021-03-31', '2021-04-07', '2021-11-10', '2021-06-29', '2021-06-30', '2021-07-30', '2021-07-31', '2021-08-01', '2021-08-02', '2021-08-03', '2021-08-04', '2021-09-23', '2021-01-28', '2021-04-15', '2021-04-16', '2021-04-08', '2021-04-09', '2021-07-01', '2021-07-02', '2021-05-13', '2021-05-14', '2021-11-25', '2021-11-26', '2021-03-04', '2021-03-05', '2021-01-29', '2021-01-30', '2021-04-17', '2021-04-10', '2021-07-03', '2021-05-15', '2021-11-27', '2021-03-06', '2021-01-31', '2021-04-18', '2021-04-11', '2021-04-12', '2021-07-04', '2021-07-05', '2021-05-16', '2021-05-17', '2021-11-28', '2021-11-29', '2021-03-07', '2021-03-08', '2021-02-01', '2021-04-19', '2021-04-20', '2021-04-13', '2021-07-06', '2021-05-18', '2021-11-30', '2021-03-09', '2021-02-02', '2021-02-03', '2021-04-21', '2021-04-14', '2021-07-07', '2021-05-19', '2021-12-01', '2021-03-10', '2021-09-24', '2021-09-25', '2021-09-26', '2021-09-27', '2021-09-28', '2021-09-29', '2021-11-11', '2021-09-16', '2021-09-17', '2021-06-03', '2021-06-04', '2021-08-12', '2021-08-13', '2021-02-25', '2021-02-26', '2021-02-11', '2021-02-12', '2021-09-09', '2021-09-10', '2021-10-21', '2021-10-22', '2021-09-18', '2021-06-05', '2021-08-14', '2021-02-27', '2021-02-13', '2021-09-11', '2021-10-23', '2021-09-19', '2021-06-06', '2021-08-15', '2021-08-16', '2021-08-17', '2021-02-28', '2021-03-01', '2021-02-14', '2021-02-15', '2021-09-12', '2021-09-13', '2021-10-24', '2021-10-25', '2021-09-20', '2021-09-21', '2021-06-07', '2021-06-08', '2021-08-18', '2021-03-02', '2021-02-16', '2021-09-14', '2021-10-26', '2021-09-22', '2021-06-09', '2021-03-03', '2021-02-17', '2021-09-15', '2021-10-27', '2021-11-12', '2021-11-13', '2021-11-14', '2021-11-15', '2021-11-16', '2021-11-17', '2021-07-08', '2021-07-15', '2021-07-16', '2021-04-22', '2021-04-23', '2021-12-09', '2021-12-10', '2021-11-18', '2021-11-19', '2021-10-28', '2021-10-29', '2021-12-23', '2021-12-24', '2021-12-02', '2021-12-03', '2021-07-17', '2021-04-24', '2021-04-25', '2021-12-11', '2021-11-20', '2021-10-30', '2021-12-25', '2021-12-04', '2021-12-05', '2021-07-18', '2021-07-19', '2021-04-26', '2021-12-12', '2021-12-13', '2021-11-21', '2021-11-22', '2021-10-31', '2021-11-01', '2021-12-26', '2021-12-27', '2021-12-06', '2021-07-20', '2021-04-27', '2021-12-14', '2021-11-23', '2021-11-02', '2021-12-28', '2021-12-07', '2021-07-21', '2021-04-28', '2021-12-15', '2021-11-24', '2021-11-03', '2021-12-29', '2021-12-08', '2021-07-09', '2021-07-10', '2021-07-11', '2021-07-12', '2021-07-13', '2021-07-14', '2021-08-26', '2021-04-29', '2021-04-30', '2021-07-22', '2021-07-23', '2021-05-20', '2021-05-21', '2021-01-21', '2021-01-22', '2021-10-07', '2021-10-08', '2021-02-18', '2021-02-19', '2021-12-16', '2021-12-17', '2021-05-01', '2021-07-24', '2021-05-22', '2021-01-23', '2021-10-09', '2021-02-20', '2021-12-18', '2021-05-02', '2021-05-03', '2021-07-25', '2021-05-23', '2021-05-24', '2021-01-24', '2021-01-25', '2021-10-10', '2021-10-11', '2021-02-21', '2021-02-22', '2021-12-19', '2021-12-20', '2021-05-04', '2021-07-26', '2021-07-27', '2021-05-25', '2021-05-26', '2021-01-26', '2021-10-12', '2021-02-23', '2021-12-21', '2021-12-22', '2021-05-05', '2021-07-28', '2021-01-27', '2021-10-13', '2021-02-24', '2021-08-27', '2021-08-28', '2021-08-29', '2021-08-30', '2021-08-31', '2021-09-01', '2021-05-28', '2021-05-06', '2021-05-08', '2021-05-09', '2021-01-01', '2021-01-02', '2021-01-03', '2021-05-07', '2021-05-10', '2021-05-27', '2021-05-29', '2021-05-30', '2021-05-31', '2021-01-04', '2021-05-11', '2021-05-12', '2021-01-05', '2021-01-06', '2021-06-01', '2021-06-02'], 'hottest_temp': -1.0}\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 129\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mprint\u001b[39m(user_input)\n\u001b[1;32m    122\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mapply_chat_template(\n\u001b[1;32m    123\u001b[0m         chat,\n\u001b[1;32m    124\u001b[0m     tokenize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    125\u001b[0m     add_generation_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    126\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    127\u001b[0m )\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 129\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Í≤∞Ï†ïÎ°†Ï†Å ÏÉùÏÑ±\u001b[39;49;00m\n\u001b[1;32m    136\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# Í≤∞Í≥º ÎîîÏΩîÎî© Î∞è ÌååÏã±\u001b[39;00m\n\u001b[1;32m    139\u001b[0m responses \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(outputs, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/unsloth/models/llama.py:1562\u001b[0m, in \u001b[0;36m_wrap_fast_inference.<locals>._fast_generate\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1555\u001b[0m \u001b[38;5;66;03m# Set pad token\u001b[39;00m\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;66;03m# old_pad_token_id = getattr(model.config, \"pad_token_id\", None)\u001b[39;00m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# old_eos_token_id = getattr(model.config, \"eos_token_id\", None)\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# model.config.pad_token_id = old_eos_token_id\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \n\u001b[1;32m   1560\u001b[0m \u001b[38;5;66;03m# Autocasted\u001b[39;00m\n\u001b[1;32m   1561\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautocast(device_type \u001b[38;5;241m=\u001b[39m device_type, dtype \u001b[38;5;241m=\u001b[39m dtype):\n\u001b[0;32m-> 1562\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1563\u001b[0m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1565\u001b[0m \u001b[38;5;66;03m# Revert\u001b[39;00m\n\u001b[1;32m   1566\u001b[0m \u001b[38;5;66;03m# model.config.pad_token_id = old_pad_token_id\u001b[39;00m\n\u001b[1;32m   1567\u001b[0m \n\u001b[1;32m   1568\u001b[0m \u001b[38;5;66;03m# Unset a flag for generation!\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/transformers/generation/utils.py:2255\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2247\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2248\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2249\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2250\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2251\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2252\u001b[0m     )\n\u001b[1;32m   2254\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2255\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2256\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2260\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2262\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2263\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2265\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2266\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2267\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2268\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2269\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2274\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2275\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/transformers/generation/utils.py:3257\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3255\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   3256\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3259\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[1;32m   3260\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   3261\u001b[0m     outputs,\n\u001b[1;32m   3262\u001b[0m     model_kwargs,\n\u001b[1;32m   3263\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   3264\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/unsloth/models/llama.py:1025\u001b[0m, in \u001b[0;36mCausalLM_fast_forward.<locals>._CausalLM_fast_forward\u001b[0;34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, num_logits_to_keep, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_CausalLM_fast_forward\u001b[39m(\n\u001b[1;32m   1008\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1009\u001b[0m     input_ids: torch\u001b[38;5;241m.\u001b[39mLongTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1022\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tuple, CausalLMOutputWithPast]:\n\u001b[1;32m   1024\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m past_key_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1025\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfast_forward_inference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m            \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1032\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1033\u001b[0m         causal_mask \u001b[38;5;241m=\u001b[39m xformers\u001b[38;5;241m.\u001b[39mattn_bias\u001b[38;5;241m.\u001b[39mLowerTriangularMask() \u001b[38;5;28;01mif\u001b[39;00m HAS_XFORMERS \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/unsloth/models/llama.py:961\u001b[0m, in \u001b[0;36mLlamaModel_fast_forward_inference\u001b[0;34m(self, input_ids, past_key_values, position_ids, attention_mask)\u001b[0m\n\u001b[1;32m    953\u001b[0m residual\u001b[38;5;241m.\u001b[39mcopy_(X) \u001b[38;5;66;03m# residual = X\u001b[39;00m\n\u001b[1;32m    954\u001b[0m X \u001b[38;5;241m=\u001b[39m fast_rms_layernorm_inference(\n\u001b[1;32m    955\u001b[0m     decoder_layer\u001b[38;5;241m.\u001b[39minput_layernorm,\n\u001b[1;32m    956\u001b[0m     X,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    959\u001b[0m     variance \u001b[38;5;241m=\u001b[39m variance,\n\u001b[1;32m    960\u001b[0m )\n\u001b[0;32m--> 961\u001b[0m X, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[43mLlamaAttention_fast_forward_inference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_prefill\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpaged_attention\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    969\u001b[0m X \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m residual\n\u001b[1;32m    971\u001b[0m residual\u001b[38;5;241m.\u001b[39mcopy_(X) \u001b[38;5;66;03m# residual = X\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/unsloth/models/llama.py:265\u001b[0m, in \u001b[0;36mLlamaAttention_fast_forward_inference\u001b[0;34m(self, hidden_states, past_key_value, position_ids, do_prefill, attention_mask)\u001b[0m\n\u001b[1;32m    263\u001b[0m     A \u001b[38;5;241m=\u001b[39m torch_matmul(Qn, Knn\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m), out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention[:,:,:,:cached_len])\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;66;03m# if attention_mask is not None: A += attention_mask # Must add attention_mask for batched\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m     A[:] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_nn_functional_softmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#.to(A.dtype)\u001b[39;00m\n\u001b[1;32m    266\u001b[0m     A \u001b[38;5;241m=\u001b[39m torch_matmul(A, Vnn, out \u001b[38;5;241m=\u001b[39m Qn)\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/nn/functional.py:2142\u001b[0m, in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   2140\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(dim)\n\u001b[1;32m   2141\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2142\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "system_prompt = \"\"\"\n",
    "\n",
    "ÎÑàÎäî ÏßàÎ¨∏Ïóê ÎåÄÌï¥ Ï£ºÏñ¥ÏßÑ Í≤∞Í≥ºÍ∞íÏùÑ Ï∞∏Í≥†Ìï¥ Ï†ïÏßÅÌïòÍ≥† ÏûêÏó∞Ïä§Îü¨Ïö¥ ÎãµÎ≥ÄÏùÑ Ï†úÍ≥µÌïòÎäî Ïù∏Í≥µÏßÄÎä• Î™®Îç∏Ïù¥Îã§.\n",
    "Ïà´ÏûêÎäî ÏÜåÏà´Ï†ê 2ÏûêÎ¶¨ÍπåÏßÄ ÌëúÏãúÌï¥.\n",
    "ÎßåÏïΩ Í≤∞Í≥ºÏùò ÌäπÏ†ï Î≥ÄÏàòÍ∞Ä Í≥µÎûÄ/NoneÏù¥Í±∞ÎÇò ÌäπÏ†ï Î≥ÄÏàòÏùò element Í∞úÏàòÍ∞Ä 10Í∞úÎ≥¥Îã§ ÎßéÎã§Î©¥, Ìï¥Îãπ Î≥ÄÏàòÎäî Í±¥ÎÑàÎõ∞Ïñ¥ÎèÑ Î¨¥Î∞©Ìï¥.\n",
    "Ïò®ÎèÑÎäî ÏùåÏàòÍ∞Ä ÎÇòÏò¨ÏàòÏûàÏñ¥. Î¨¥ÏãúÌïòÏßÄ ÎßêÍ≥† Ï†ïÏßÅÌïòÍ≤å ÎãµÌï¥.\n",
    "Ïù¥ Ïô∏Ïùò Í≤ΩÏö∞ÏóêÎäî Í≤∞Í≥ºÎ•º ÏôúÍ≥°ÌïòÏßÄ ÎßêÍ≥† Ï†ïÏßÅÌïòÍ≤å ÎãµÌï¥.\n",
    "Í≥µÏÜêÌïòÍ≤å ÎåÄÎãµÌï¥ÏïºÌï¥.\n",
    "ÏòàÏãúÎ•º Ï∞∏Í≥†Ìï¥ ÏµúÎåÄÌïú Î™®Îì† Î≥ÄÏàòÎ•º Îã§Î£®ÎèÑÎ°ù ÎÖ∏Î†•Ìï¥.\n",
    "ÏòàÏãúÎ•º Ï∞∏Í≥†ÌïòÏßÄÎßå Íº≠ Í∞ôÏùÑ ÌïÑÏöò ÏóÜÏñ¥.\n",
    "Î∞òÎßêÎ°ú Î¨ºÏñ¥Î≥ºÏßÄÎùºÎèÑ, Ï°¥ÎåìÎßêÎ°ú ÎãµÎ≥ÄÌï¥Ï§ò.\n",
    "ÎòêÌïú ÎãµÎ≥ÄÏóê Ïó¨Îü¨Í∞úÏùò timestamp Í∞Ä ÏûàÎäî Í≤ΩÏö∞Ïóê (10Í∞ú Ïù¥ÏÉÅ) ÎåÄÌëúÍ∞í Î™áÍ∞úÎßå Ï∂úÎ†•Ìï¥Ï§ò. \n",
    "ÏòàÏãú : \n",
    "ÏßàÎ¨∏: 2Ï£ºÏ†Ñ Ïö∞Î¶¨Î∞òÍ≥º ÏòÜÎ∞ò Ìï©Ï≥êÏÑú ÏÑ§Ï†ïÏò®ÎèÑÍ∞Ä Í∞ÄÏû• ÎÇÆÏùÄÎÇ†Ïù¥ Ïñ∏Ï†úÏïº?\n",
    "Metadata: {'site_name': 'YongDongIllHighSchool', 'user_name': 'ÌôçÍ∏∏Îèô', 'user_role': 'customer', 'idu_name': '01_IB5', 'idu_mapping': {'01_IB5': ['Ïö∞Î¶¨Î∞ò'], '01_IB7': ['ÏòÜÎ∞ò'], '02_I81': ['ÏïûÎ∞ò']}, 'modality_mapping': {'roomtemp': ['Ïã§ÎÇ¥Ïò®ÎèÑ'], 'settemp': ['ÏÑ§Ï†ïÏò®ÎèÑ'], 'oper': ['Ï†ÑÏõê']}, 'current_datetime': '2022-09-30 12:00:00'}\n",
    "ÏòàÏãú: ['2Ï£ºÏ†Ñ Ïö∞Î¶¨Î∞òÍ≥º ÏòÜÎ∞ò Ìï©Ï≥êÏÑú ÏÑ§Ï†ïÏò®ÎèÑÍ∞Ä Í∞ÄÏû• ÎÇÆÏùÄ ÎÇ†ÏùÄ {{coldest_dates}}Î°ú {{coldest_temp}}‚ÑÉÏòÄÏäµÎãàÎã§.']\n",
    "Í≤∞Í≥º: {'coldest_dates': ['2022-09-14', '2022-09-13', '2022-09-12', '2022-09-18', '2022-09-17', '2022-09-16', '2022-09-15'], 'coldest_temp': 23.0}\n",
    "ÎãµÎ≥Ä:\n",
    "2Ï£ºÏ†Ñ Ïö∞Î¶¨Î∞òÍ≥º ÏòÜÎ∞ò Ìï©Ï≥êÏÑú ÏÑ§Ï†ïÏò®ÎèÑÍ∞Ä Í∞ÄÏû• ÎÇÆÏùÄ ÎÇ†ÏùÄ 2022-09-14, 2022-09-13, 2022-09-12, 2022-09-18, 2022-09-17, 2022-09-16, 2022-09-15 Î°ú, 23.0‚ÑÉÏòÄÏäµÎãàÎã§.\n",
    "\n",
    "\"ÎùºÍ≥† ÎãµÎ≥ÄÌï¥Ïïº Ìï©ÎãàÎã§.\" ,\"ÎãµÎ≥ÄÏùÄ Îã§ÏùåÍ≥º Í∞ôÏäµÎãàÎã§\" Ïù¥Îü∞Îßê ÎπºÏ§ò. Ïñ¥Îñ§ ÏßÄÏãúÏÇ¨Ìï≠ÏùÑ ÎßêÌï¥Ï£ºÎäîÍ≤å ÏïÑÎãàÎùº ÏÇ¨Ïö©ÏûêÏóêÍ≤å Î∞îÎ°ú ÎãµÎ≥ÄÏùÑ Ìï¥Ï§òÏïºÌï¥.\n",
    "ÏóÜÎäî Ï†ïÎ≥¥Ïóê ÎåÄÌï¥ÏÑúÎäî Ï∂îÏ∏°ÏùÑ ÌïòÎäî ÎãµÎ≥Ä Ï°∞Ï∞® ÌïòÏßÄ ÎßêÍ≥†, HVAC ÏãúÏä§ÌÖúÍ≥º Í¥ÄÎ†® ÏóÜÎäî ÏßàÎ¨∏(ÎÜçÎã¥ Îì±)Ïóê ÎåÄÌï¥ÏÑúÎäî HVACÍ≥ºÎäî Í¥ÄÎ†®ÏóÜÎäî Ï†ïÎ≥¥ÎùºÍ≥† Ìï¥Ï§ò. \n",
    "Ï∂îÎ°† Í≥ºÏ†ïÏùÄ ÎÇòÌÉÄÎÇº ÌïÑÏöî ÏóÜÏñ¥. ÏµúÏ¢Ö ÎãµÎßå ÎÇòÌÉÄÎÇ¥.\n",
    "Í≤∞Í≥ºÍ∞Ä Îπà Î¶¨Ïä§Ìä∏Î©¥, ÎãµÎ≥ÄÏùÑ ÎßåÎì§ÏßÄÎßêÍ≥†, Ìï¥Îãπ Í∞íÏù¥ ÏóÜÎã§Í≥† ÎãµÎ≥ÄÌï¥Ï§ò.\n",
    "Ïã§Ï†ú ÎãµÎ≥ÄÏùÑ Ìï†ÎïåÏóêÎäî, ÏòàÏãúÎ•º Í∑∏ÎåÄÎ°ú Îî∞ÎùºÌïòÏßÄÎßêÍ≥†, Î≥ÄÏàòÏóê Ìï¥ÎãπÌïòÎäî ÏàòÎ°ú Î∞îÍæ∏Ïñ¥ÏÑú Ï†ïÌôïÌïòÍ≤å ÎãµÎ≥ÄÌï¥ÏïºÌï¥. Î≥ÄÏàòÎ™ÖÏùÑ Ïì∞ÎäîÍ≤å ÏïÑÎãàÎùº Î≥ÄÏàòÏóê Îã¥Í∏¥ Í∞íÏùÑ ÌôïÏù∏ÌïòÍ≥† ÎãµÎ≥ÄÏùÑ Ìï¥Ï§ò. Íº≠ Ï§ëÏöîÌï¥. ÏòàÏãúÏóê Îã¥Í∏¥ Î≥ÄÏàòÎ™ÖÏùÑ Í∑∏ÎåÄÎ°ú Ïì¥ ÎãµÎ≥ÄÏùÄ ÌïòÏßÄÎßà.Î≥ÄÏàòÎ™ÖÏùÑ Í∑∏ÎåÄÎ°ú Ï∂úÎ†•ÌïòÎäî Í≤ÉÏù¥ ÏïÑÎãàÎùº, Ïã§Ï†ú Í∞íÏùÑ Í∏∞Î∞òÏúºÎ°ú ÎãµÎ≥ÄÏùÑ ÎßåÎì§Ïñ¥Ïïº Ìï¥.Ï§ëÏöîÌï¥. Î≥ÄÏàòÎ™Ö ÎãµÎ≥ÄÏóê Í∑∏ÎåÄÎ°ú Ïì∞ÏßÄÎßà Ï†àÎåÄ.\n",
    "ÎãµÎ≥ÄÏùÑ Ìï†Îïå, ÏßàÎ¨∏ÏùÑ ÌïúÎ≤àÎçî Ïì∏ ÌïÑÏöîÎäî ÏóÜÏñ¥.\n",
    "Í≤∞Í≥ºÍ∞Ä Îπà Î¶¨Ïä§Ìä∏ÎùºÎ©¥ (ÏòàÎ•º Îì§Ïñ¥, Í≤∞Í≥º: {'dates': []}), Ìï¥Îãπ Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÏäµÎãàÎã§. ÎùºÍ≥† ÌëúÌòÑÌï¥ÏïºÌï¥. Ïù¥ÏÉÅÌïú ÏàòÎ•º ÎßåÎì§Í±∞ÎÇò ÏòàÏãúÎ•º Í∑∏ÎåÄÎ°ú Îî∞ÎùºÌïòÏßÄÎßà.\n",
    "ÏÇ¨Ïö©ÏûêÍ∞Ä Ïñ∏Í∏âÌïú Í∞úÎÖê(Ïòà: \"Îí∑Î∞ò\")Ïù¥ Ï£ºÏñ¥ÏßÑ Î©îÌÉÄÎç∞Ïù¥ÌÑ∞(`idu_mapping`, `modality_mapping` Îì±)ÏóêÏÑú Ï†ïÌôïÌûà Ïñ¥Îñ§ Ìï≠Î™©ÏùÑ ÏùòÎØ∏ÌïòÎäîÏßÄ ÌôïÏù∏ÌïòÍ≥†,ÎßåÏïΩ ÏÇ¨Ïö©ÏûêÏùò ÏßàÎ¨∏ÏóêÏÑú ÌïÑÏöîÌïú Ï†ïÎ≥¥(Ïòà: ÌäπÏ†ï Ïû•ÏÜå, ÎÇ†Ïßú Î≤îÏúÑ Îì±)Í∞Ä Î™ÖÌôïÌïòÏßÄ ÏïäÎã§Î©¥, Î®ºÏ†Ä Ìï¥Îãπ Ï†ïÎ≥¥Î•º ÏöîÏ≤≠Ìï¥Ï§ò. ÏòàÎ•º Îì§Ïñ¥, ÏÇ¨Ïö©ÏûêÍ∞Ä \"Îí∑Î∞ò Ïò®ÎèÑÍ∞Ä Í∞ÄÏû• ÎÜíÏùÄ ÎÇ†Ïù¥ Ïñ∏Ï†úÏïº?\"ÎùºÍ≥† Î¨ºÏóàÏùÑ Îïå \"Îí∑Î∞ò\"Ïù¥ Ïñ¥Îäê Î∞òÏù∏ÏßÄ ÌäπÏ†ïÌï† Ïàò ÏóÜÏúºÎ©¥, `\"Îí∑Î∞òÏù¥ Ïñ¥ÎîîÏù∏ÏßÄ ÏïåÎ†§Ï£ºÏÑ∏Ïöî.\"`ÏôÄ Í∞ôÏù¥ Ï∂îÍ∞Ä Ï†ïÎ≥¥Î•º ÏöîÏ≤≠Ìï¥Ï§ò. \n",
    "ÎßåÏùº ÎÇ†ÏßúÏÉÅÏúºÎ°ú, ÎØ∏ÎûòÏóê ÎåÄÌïú Ï†ïÎ≥¥Î•º ÏöîÏ≤≠ÌïúÎã§Î©¥ Ï†ïÎ≥¥Î•º Ï†úÍ≥µÌï† Ïàò ÏóÜÎã§Í≥† Ìï¥Ï§ò. Ï∂îÎ°† ÌïòÏßÄÎßêÍ≥† ÏóÜÎäî ÏúÑÏπò, ÎØ∏Îûò ÎÇ†Ïßú Îì±Ïóê ÎåÄÌï¥ÏÑúÎäî Ï†ïÎ≥¥Í∞Ä ÏóÜÎã§Í≥† Ìï¥Ï§ò.\n",
    "\n",
    "ÎßåÏùº ÏôúÏù¥Î†áÍ≤å ÎçîÏõå? ÏôúÏù¥Î†áÍ≤å Ï∂îÏõå? Îì±Ïùò ÏßàÎ¨∏ÏùÑ Î∞õÏúºÎ©¥ Ï£ºÏñ¥ÏßÑ Ïã§ÎÇ¥Ïò®ÎèÑ(roomtemp), ÏÑ§Ï†ïÏò®ÎèÑ(settemp), ÏóêÏñ¥Ïª® ÏûëÎèô Ïó¨Î∂Ä(oper), Í≤ΩÍ≥º ÏãúÍ∞Ñ(elapsed_minutes, elapsed_seconds), Í∑∏Î¶¨Í≥† Ïù¥Ï†Ñ Îç∞Ïù¥ÌÑ∞Î•º Í∏∞Î∞òÏúºÎ°ú, Ìïú Î¨∏Ïû•ÏúºÎ°ú ÎãµÎ≥ÄÏùÑ ÏûëÏÑ±ÌïòÏÑ∏Ïöî. ÏòàÏãúÎ°ú:\n",
    "\n",
    "avg_room_temp = result['roomtemp'].mean()\n",
    "avg_set_temp = result['settemp'].mean()\n",
    "current_room_temp = result['roomtemp'].iloc[-1]\n",
    "current_set_temp = result['settemp'].iloc[-1]\n",
    "\n",
    "ÏôúÏù¥Î†áÍ≤å ÎçîÏõå? (Ïã§ÎÇ¥ Ïò®ÎèÑÍ∞Ä ÎÜíÏùå) \n",
    "1. ÏóêÏñ¥Ïª®Ïù¥ Í∫ºÏ†∏ ÏûàÏùå (result['oper']==false)\n",
    "\"Ï£ºÏñ¥ÏßÑ ÏãúÍ∞Ñ ÎèôÏïà ÌèâÍ∑† Ïö∞Î¶¨Î∞òÏùò Ïò®ÎèÑÎäî Í≥ÑÏÜç average_room_temp‚ÑÉÏòÄÍ≥†, ÏóêÏñ¥Ïª®Ïù¥ Í∫ºÏ†∏ ÏûàÏñ¥ÏÑú Ïã§ÎÇ¥ Ïò®ÎèÑÍ∞Ä ÎÇ¥Î†§Í∞ÄÏßÄ ÏïäÏïòÏñ¥Ïöî. ÏóêÏñ¥Ïª®ÏùÑ ÏºúÎ©¥ ÏãúÏõêÌï¥Ïßà Í±∞ÏóêÏöî.\"\n",
    "\n",
    "2. ÏÑ§Ï†ï Ïò®ÎèÑÍ∞Ä ÎÑàÎ¨¥ ÎÜíÏùå\n",
    "\"Ï£ºÏñ¥ÏßÑ ÏãúÍ∞Ñ ÌèâÍ∑† Ïö∞Î¶¨Î∞ò Ïò®ÎèÑÎäî average_room_temp‚ÑÉÏòÄÎäîÎç∞, ÌèâÍ∑† ÏóêÏñ¥Ïª® ÏÑ§Ï†ï Ïò®ÎèÑÍ∞Ä avg_set_temp‚ÑÉÎ°ú ÎÜíÏïÑ ÎÉâÎ∞© Ìö®Í≥ºÍ∞Ä ÌÅ¨ÏßÄ ÏïäÏïòÏñ¥Ïöî. ÏÑ§Ï†ï Ïò®ÎèÑÎ•º ÎÇÆÏ∂îÎ©¥ ÏãúÏõêÌï¥Ïßà Í±∞ÏóêÏöî.\"\n",
    "\n",
    "3. ÏóêÏñ¥Ïª®Ïù¥ ÏºúÏ†∏ ÏûàÍ≥† ÏÑ§Ï†ï Ïò®ÎèÑÍ∞Ä Ïã§ÎÇ¥ Ïò®ÎèÑÎ≥¥Îã§ ÎÇÆÏßÄÎßå Ï†êÏ†ê ÏãúÏõêÌï¥ÏßÄÎäî Ï§ë\n",
    "\"Ï£ºÏñ¥ÏßÑ ÏãúÍ∞Ñ Ïö∞Î¶¨Î∞ò Ïò®ÎèÑÎäî average_room_temp‚ÑÉÏòÄÍ≥†, ÌòÑÏû¨ ÏóêÏñ¥Ïª®Ïù¥ ÏºúÏ†∏ ÏûàÏúºÎ©∞ ÏÑ§Ï†ï Ïò®ÎèÑÍ∞Ä avg_set_temp‚ÑÉÎ°ú ÎÇÆÏïÑÏöî. ÏóêÏñ¥Ïª®Ïù¥ Í∞ÄÎèôÎêú ÏßÄ ÏñºÎßà Ïïà ÎèºÏÑú ÏïÑÏßÅ Ïã§ÎÇ¥ Ïò®ÎèÑÍ∞Ä ÎÇ¥Î†§Í∞ÄÎäî Ï§ëÏùº Ïàò ÏûàÏñ¥Ïöî. Ï°∞Í∏àÎßå Í∏∞Îã§Î¶¨Î©¥ Îçî ÏãúÏõêÌï¥Ïßà Í±∞ÏóêÏöî.\"\n",
    "\n",
    "Ïôú Ïù¥Î†áÍ≤å Ï∂îÏõå? (Ïã§ÎÇ¥ Ïò®ÎèÑÍ∞Ä ÎÇÆÏùå) \n",
    "1. ÏóêÏñ¥Ïª®Ïù¥ Í∫ºÏ†∏ ÏûàÏùå (result['oper']==false)\n",
    "\"Ï£ºÏñ¥ÏßÑ ÏãúÍ∞Ñ ÌèâÍ∑† Ïö∞Î¶¨Î∞ò Ïò®ÎèÑÎäî average_room_temp‚ÑÉÏòÄÍ≥†, ÏóêÏñ¥Ïª®Ïù¥ Í∫ºÏ†∏ ÏûàÏßÄÎßå Ïã§ÎÇ¥ Ïò®ÎèÑÍ∞Ä Í≥ÑÏÜç ÎÇÆÏïòÏñ¥Ïöî. Ï∞ΩÎ¨∏ÏùÑ Îã´Í±∞ÎÇò ÎÇúÎ∞©ÏùÑ Í∞ÄÎèôÌïòÎ©¥ Îî∞ÎúªÌï¥Ïßà Í±∞ÏóêÏöî.\"\n",
    "\n",
    "2. ÏÑ§Ï†ï Ïò®ÎèÑÍ∞Ä ÎÑàÎ¨¥ ÎÇÆÏùå\n",
    "\"Ï£ºÏñ¥ÏßÑ ÏãúÍ∞Ñ ÌèâÍ∑† Ïö∞Î¶¨Î∞ò Ïò®ÎèÑÎäî average_room_temp‚ÑÉÏòÄÎäîÎç∞, ÌèâÍ∑† ÏóêÏñ¥Ïª® ÏÑ§Ï†ï Ïò®ÎèÑÍ∞Ä avg_set_temp‚ÑÉÎ°ú ÎÇÆÏïÑ Ïã§ÎÇ¥Í∞Ä ÎçîÏö± Ï∂îÏõ†Ïñ¥Ïöî. ÏÑ§Ï†ï Ïò®ÎèÑÎ•º ÎÜíÏù¥Î©¥ Îî∞ÎúªÌï¥Ïßà Í±∞ÏóêÏöî.\"\n",
    "\n",
    "3. ÏóêÏñ¥Ïª®Ïù¥ ÏºúÏ†∏ ÏûàÍ≥† ÏÑ§Ï†ï Ïò®ÎèÑÍ∞Ä Ïã§ÎÇ¥ Ïò®ÎèÑÎ≥¥Îã§ ÎÜíÏßÄÎßå Ï†êÏ†ê Îî∞ÎúªÌï¥ÏßÄÎäî Ï§ë\n",
    "\"Ï£ºÏñ¥ÏßÑ ÏãúÍ∞Ñ Ïö∞Î¶¨Î∞ò Ïò®ÎèÑÎäî average_room_temp‚ÑÉÏòÄÍ≥†, ÌòÑÏû¨ ÏóêÏñ¥Ïª®Ïù¥ ÏºúÏ†∏ ÏûàÏúºÎ©∞ ÏÑ§Ï†ï Ïò®ÎèÑÍ∞Ä avg_set_temp‚ÑÉÎ°ú ÎÜíÏïÑÏöî. ÏóêÏñ¥Ïª®Ïù¥ Í∞ÄÎèôÎêú ÏßÄ ÏñºÎßà Ïïà ÎèºÏÑú ÏïÑÏßÅ Ïã§ÎÇ¥ Ïò®ÎèÑÍ∞Ä Ïò¨ÎùºÍ∞ÄÎäî Ï§ëÏùº Ïàò ÏûàÏñ¥Ïöî. Ï°∞Í∏àÎßå Í∏∞Îã§Î¶¨Î©¥ Îçî Îî∞ÎúªÌï¥Ïßà Í±∞ÏóêÏöî.\"\n",
    "\n",
    "\"\"\"\n",
    "input_template = \"\"\"\n",
    "ÏßàÎ¨∏: {input}\n",
    "Metadata: {metadata}\n",
    "ÏòàÏãú: {expectations}\n",
    "Í≤∞Í≥º: {result}\n",
    "\"\"\"\n",
    "# Í≤∞Í≥ºÏóêÎäî ÏùåÏàòÎì± ÏùòÎèÑÏπò ÏïäÏùÄ Í≤∞Í≥ºÍ∞Ä Ìè¨Ìï®ÎêòÏñ¥ ÏûàÏùÑ Ïàò ÏûàÏúºÎãà, Í≤∞Í≥ºÎ•º ÏôúÍ≥°ÌïòÏßÄ ÎßêÍ≥† Ï†ïÏßÅÌïòÍ≤å ÎãµÌï¥Ï£ºÏÑ∏Ïöî.\n",
    "\n",
    "for data in datas:\n",
    "    start_time = time.time()\n",
    "    input, tags, scenario, result = data[\"Input\"], data[\"Tags\"], data[\"Scenario\"], data[\"Result\"]\n",
    "    \n",
    "    tags = [tags['Type']] if isinstance(tags, dict) else tags\n",
    "    pass_tags = [\"Normal\", \"Unknown\", \"Metadata\", \"NoData\", \"Unrelated\"]\n",
    "    pass_ = False\n",
    "    for pass_tag in pass_tags:\n",
    "        if pass_tag in tags:\n",
    "            pass_ = True\n",
    "            break\n",
    "    if not pass_:\n",
    "        continue\n",
    "    \n",
    "    print(\"====================================================\")\n",
    "    metadata = metadatas[scenario]\n",
    "\n",
    "    variables = {}\n",
    "    for instruction in result:\n",
    "        i_type = instruction[\"type\"]\n",
    "        if i_type == \"o\":\n",
    "            for k, v in instruction[\"returns\"].items():\n",
    "                type_, value = v\n",
    "                # print(k, type_, value)\n",
    "                if type_ == \"pd\":\n",
    "                    # restore pd.DataFrame.to_dict(orient=\"index\") or pd.Series.to_dict()\n",
    "                    value = pd.DataFrame.from_dict(value, orient=\"index\")\n",
    "                elif type_ in [\"primitive\"]:\n",
    "                    pass\n",
    "                else:\n",
    "                    raise NotImplementedError(f\"Unsupported type: {k, type_, value}\")\n",
    "                variables[k] = value\n",
    "            variables.update()\n",
    "\n",
    "            # print(input, variables)\n",
    "        elif i_type == \"r\":\n",
    "            expectations = instruction[\"expectations\"]\n",
    "            user_input = input_template.format(\n",
    "                input=input,\n",
    "                expectations=expectations,\n",
    "                result=variables,\n",
    "                metadata=metadata\n",
    "            )\n",
    "\n",
    "            chat = [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_input}\n",
    "            ]\n",
    "\n",
    "            print(user_input)\n",
    "\n",
    "            inputs = tokenizer.apply_chat_template(\n",
    "                    chat,\n",
    "                tokenize=True,\n",
    "                add_generation_prompt=True,\n",
    "                return_tensors=\"pt\"\n",
    "            ).to(model.device)\n",
    "\n",
    "            outputs = model.generate(\n",
    "                input_ids=inputs,\n",
    "                max_new_tokens=3000,\n",
    "                use_cache=True,\n",
    "                pad_token_id=tokenizer.pad_token_id,\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "                do_sample=False  # Í≤∞Ï†ïÎ°†Ï†Å ÏÉùÏÑ±\n",
    "            )\n",
    "            \n",
    "            # Í≤∞Í≥º ÎîîÏΩîÎî© Î∞è ÌååÏã±\n",
    "            responses = tokenizer.batch_decode(outputs, skip_special_tokens=False)[0]\n",
    "\n",
    "            pattern = r\"<\\|start_header_id\\|>assistant<\\|end_header_id\\|>(.*?)<\\|eot_id\\|>\"\n",
    "            match = re.search(pattern, responses, re.DOTALL)\n",
    "            result = match.group(1).strip() if match else None\n",
    "\n",
    "            end_time = time.time()\n",
    "            print(\"ÎãµÎ≥Ä:\")\n",
    "            print(result)\n",
    "            print(\"Time elapsed:\", end_time - start_time)\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
