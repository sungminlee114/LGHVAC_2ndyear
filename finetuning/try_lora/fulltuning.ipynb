{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective: Finetune I2I LLM w/ LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# device_num = 0\n",
    "\n",
    "# !export CUDA_VISIBLE_DEVICES=device_num\n",
    "import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=f\"{device_num}\"\n",
    "\n",
    "#utf-8\n",
    "os.environ['PYTHONIOENCODING'] = 'utf-8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "device = f\"cuda:2\"\n",
    "torch.cuda.set_device(2)\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling, BitsAndBytesConfig\n",
    "from datasets import load_dataset, Dataset\n",
    "# from peft import get_peft_model, LoraConfig, TaskType, PeftModel\n",
    "# from unsloth import FastLanguageModel\n",
    "import pprint\n",
    "import json\n",
    "from pathlib import Path\n",
    "import transformers\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using flash_attention_2 for attention computation.\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 0     # Unsloth auto supports RoPE Scaling internally!\n",
    "dtype = None              # None for auto detection\n",
    "load_in_4bit = False      # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "\n",
    "\n",
    "if torch.cuda.get_device_capability()[0] >= 8:\n",
    "    attn_implementation = \"flash_attention_2\"\n",
    "    torch_dtype = torch.bfloat16\n",
    "else:\n",
    "    attn_implementation = \"eager\"\n",
    "    torch_dtype = torch.float16\n",
    "# attn_implementation = \"eager\"\n",
    "print(f\"Using {attn_implementation} for attention computation.\")\n",
    "# QLora?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë‚˜ëŠ” í›Œë£¡í•œ HVAC ê´€ë ¨ ì§ˆë¬¸ ë‹µë³€ì„ ì œê³µí•˜ëŠ” ì¸ê³µì§€ëŠ¥ì´ë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë°›ì•„ë“¤ì—¬ì„œ, ê·¸ì— ë§ëŠ” ë‹µë³€ì„ ì œê³µí•˜ëŠ” ê²ƒì´ ë‚´ ì„ë¬´ì´ë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë°›ì•„ë“¤ì¼ ë•Œ, ë‹¤ìŒê³¼ ê°™ì€ ì ˆì°¨ë¥¼ ë”°ë¼ì•¼ í•œë‹¤.\n",
      "<ì¶œë ¥ ë‚´ìš©>\n",
      "1. 'Formalized Input': ì‚¬ìš©ìì˜ ì¶”ìƒì  ì§ˆë¬¸ì„ êµ¬ì²´í™” ë° ì •ê·œí™”í•œ ê²°ê³¼. ë‹¤ì–‘í•œ í˜•íƒœì˜ ì§ˆë¬¸ë“¤ì„ ê°€ì¥ í•µì‹¬ì ì´ê³  ê·¼ë³¸ì ì¸ ì§ˆë¬¸ìœ¼ë¡œ ë³€í™˜í•œ ê²°ê³¼.\n",
      "2. 'Input Semantic Parsing': Input Semantic Parsing ê²°ê³¼. dict í˜•íƒœë¡œ êµ¬ì„±ë˜ë©°, Temporal, Spatial, Modalityë¥¼ ê°€ì§.\n",
      "3. 'Strategy': ì§ˆë¬¸ì„ í•´ê²°í•˜ê¸° ìœ„í•œ ì „ëµì„ ë‹µë³€ ì „ ê³ ë¯¼. Objective: ì§ˆë¬¸ì˜ ê·¼ë³¸ì  ì˜ë„ ë° ë‹µë³€ì˜ ëª©ì . Expected Output: ë‹µë³€ì˜ ì˜ˆìƒ ê²°ê³¼. Step: ë‹µë³€ì„ ìœ„í•œ êµ¬ì²´ìœ¼ë¡œ ìª¼ê°œì§„ ë‹¨ê³„.\n",
      "4. 'Instruction Set': ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ ë‚˜ì˜ ì‹¤ì œ í–‰ë™.\n",
      "Input - Expected Outputs - templates ë¼ë¦¬ëŠ” ë¬¸ë§¥ì ìœ¼ë¡œ ìœ ì‚¬í•´ì•¼í•¨.\n",
      "\n",
      "<DDL statement>\n",
      "CREATE TABLE IF NOT EXISTS data_t\n",
      "(\n",
      "    id integer NOT NULL DEFAULT nextval('data_t_id_seq'::regclass),\n",
      "    idu_id integer,\n",
      "    roomtemp double precision,\n",
      "    settemp double precision,\n",
      "    oper boolean,\n",
      "    \"timestamp\" timestamp without time zone NOT NULL\n",
      ")\n",
      "    \n",
      "CREATE TABLE IF NOT EXISTS idu_t\n",
      "(\n",
      "    id integer NOT NULL DEFAULT nextval('idu_t_id_seq'::regclass),\n",
      "    name character varying(50) COLLATE pg_catalog.\"default\",\n",
      "    metadata character varying(255) COLLATE pg_catalog.\"default\",\n",
      "    CONSTRAINT idu_t_pkey PRIMARY KEY (id)\n",
      ")\n",
      "\n",
      "jsoní˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ë©°, eval() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ espace ë¬¸ì ì—†ì´, ê´„í˜¸ì˜ ë‹«í˜ì„ ì‹ ê²½ì¨ì„œ ì¶œë ¥í•´ì•¼í•¨.\n",
      "ì¶œë ¥ í˜•ì‹ì€ ë‹¤ìŒê³¼ ê°™ìŒ:\n",
      "{\n",
      "\"Formalized Input\": \"<Fill>\",\n",
      "\"Input Semantic Parsing\": {\n",
      "    \"<Dynamic keys>\": \"<Dynamic values>\"\n",
      "},\n",
      "\"Strategy\": {\n",
      "    \"Objective\": \"<Fill>\",\n",
      "    \"Expected Outputs\": [\n",
      "        \"<Fill>\",...\n",
      "    ],\n",
      "    \"Step\": [\n",
      "        \"<Fill>\",...\n",
      "    ]\n",
      "},\n",
      "\"Instruction Set\": [\n",
      "{\n",
      "\"type\": \"q\",\n",
      "\"args\": {\n",
      "\"table_name\": \"data_t\",\n",
      "\"columns\": [\n",
      "\"<Fill>\",...\n",
      "],\n",
      "\"conditions\": [\n",
      "\"<Fill>\",...\n",
      "],\n",
      "\"subquery\": \"<Fill>\"\n",
      "},\n",
      "\"result_name\": \"<Fill>\"\n",
      "},...]\n",
      "}\n",
      "\n",
      "\n",
      "ë‹¤ìŒ ì˜ˆì‹œë¥¼ ì°¸ê³ í•´.\n",
      "ì…ë ¥: \"ì˜¬í•´ ì—¬ë¦„ ìš°ë¦¬ë°˜ í‰ê· ì˜¨ë„ ì•Œë ¤ì¤˜\",\n",
      "ì¶œë ¥:{\n",
      "\"Formalized Input\": \"ì˜¬í•´ ì—¬ë¦„ ìš°ë¦¬ë°˜ì˜ í‰ê·  ì‹¤ë‚´ì˜¨ë„ ì•Œë ¤ì¤˜.\",\n",
      "\"Input Semantic Parsing\": {\n",
      "\"Temporal\": {\n",
      "\"ì˜¬í•´ ì—¬ë¦„\": \"2022-06-01 00:00:00 ~ 2022-08-31 23:59:59\"\n",
      "},\n",
      "\"Spatial\": {\n",
      "\"ìš°ë¦¬ë°˜\": \"01_IB5\"\n",
      "},\n",
      "\"Modality\": {\n",
      "\"ì‹¤ë‚´ì˜¨ë„\": \"roomtemp\"\n",
      "}\n",
      "},\n",
      "\"Strategy\": {\n",
      "\"Objective\": \"ìš°ë¦¬ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ ë°ì´í„° ì¤‘ ì˜¬í•´ ì—¬ë¦„ ë°ì´í„°ë§Œ ì¿¼ë¦¬ í›„, í‰ê· ê°’ ê³„ì‚°.\",\n",
      "\"Expected Outputs\": [\n",
      "\"ì˜¬í•´ ì—¬ë¦„ ìš°ë¦¬ë°˜ì˜ í‰ê·  ì˜¨ë„ëŠ” 26â„ƒ ì…ë‹ˆë‹¤.\"\n",
      "],\n",
      "\"Step\": [\n",
      "\"ìš°ë¦¬ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ ë°ì´í„° ì¤‘ ì˜¬í•´ ì—¬ë¦„ ë°ì´í„°ë§Œ ì¿¼ë¦¬ê²°ê³¼ qr_roomtemp_summerì— ì €ì¥\",\n",
      "\"qr_roomtemp_summerì—ì„œ roomtempì˜ í‰ê· ê°’ ë°˜í™˜\"\n",
      "]\n",
      "},\n",
      "\"Instruction Set\": [\n",
      "{\n",
      "\"type\": \"q\",\n",
      "\"args\": {\n",
      "\"table_name\": \"data_t\",\n",
      "\"columns\": [\n",
      "\"roomtemp\"\n",
      "],\n",
      "\"conditions\": [\n",
      "\"timestamp BETWEEN '2022-06-01 00:00:00' AND '2022-08-31 23:59:59'\"\n",
      "],\n",
      "\"subquery\": \"idu_id = (SELECT id FROM idu_t WHERE name = '01_IB5')\"\n",
      "}\n",
      "},\n",
      "\"result_name\": \"qr_roomtemp_summer\"\n",
      "]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "current_metadata = json.load(open(\"metadata.json\", \"r\"))\n",
    "\n",
    "common_prompt = open(\"prompt.txt\", \"r\").read()\n",
    "print(common_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'sh2orc/Llama-3.1-Korean-8B-Instruct'\n",
    "model_id = 'Bllossom/llama-3.2-Korean-Bllossom-3B'\n",
    "# model_id = 'Saxo/Linkbricks-Horizon-AI-Korean-Gemma-2-sft-dpo-27B'\n",
    "\n",
    "model_dir = f\"/model/{model_id.replace('/', '-')}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load tokenizer and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c30f5ab1d47e4897832fb0bbd740fac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenizer initialization\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,  \n",
    "    cache_dir=f\"{model_dir}/cache\",\n",
    "    local_files_only=True,\n",
    "    \n",
    "    torch_dtype=torch_dtype,\n",
    "    attn_implementation=attn_implementation,\n",
    "    # quantization_config=BitsAndBytesConfig(\n",
    "    #     # load_in_4bit=True,\n",
    "    #     # bnb_4bit_use_double_quant=True,\n",
    "    #     # bnb_4bit_quant_type=\"nf4\",\n",
    "    #     # bnb_4bit_compute_dtype=torch_dtype\n",
    "    #     load_in_8bit=False if not \"27B\" in model_id else True,\n",
    "    #     llm_int8_enable_fp32_cpu_offload=False if not \"27B\" in model_id else True,\n",
    "    # ),\n",
    "    device_map={'': device}\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    cache_dir=f\"{model_dir}/cache\",\n",
    "    # local_files_only=True\n",
    ")\n",
    "\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    model.save_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad Token id: None and Pad Token: None\n",
      "EOS Token id: 128009 and EOS Token: <|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer.padding_side = \"left\"\n",
    "print(f\"Pad Token id: {tokenizer.pad_token_id} and Pad Token: {tokenizer.pad_token}\")\n",
    "print(f\"EOS Token id: {tokenizer.eos_token_id} and EOS Token: {tokenizer.eos_token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d208b5910d9b4baf96c06a3d7d17be42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/36 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Formalized Input\": \"ì˜¤ëŠ˜ ìš°ë¦¬ë°˜ê³¼ ì˜†ë°˜ì˜ í‰ê·  ì‹¤ë‚´ì˜¨ë„ ì°¨ì´ ì•Œë ¤ì¤˜.\", \"Input Semantic Parsing\": {\"Temporal\": {\"ì˜¤ëŠ˜\": \"2022-09-30 00:00:00 ~ 2022-09-30 23:59:59\"}, \"Spatial\": {\"ìš°ë¦¬ë°˜\": \"01_IB5\", \"ì˜†ë°˜\": \"01_IB7\"}, \"Modality\": {\"ì‹¤ë‚´ì˜¨ë„\": \"roomtemp\"}}, \"Strategy\": {\"Objective\": \"ì˜¤ëŠ˜ ìš°ë¦¬ë°˜ê³¼ ì˜†ë°˜ ê°ê°ì˜ í‰ê·  ì‹¤ë‚´ì˜¨ë„ ì¿¼ë¦¬ í›„, ë‘ ê°’ì˜ ì°¨ì´ë¥¼ ê³„ì‚°í•¨.\", \"Expected Outputs\": [\"ìš°ë¦¬ë°˜(19.3â„ƒ)ì´ ì˜†ë°˜(17.0â„ƒ)ë³´ë‹¤ 2.3â„ƒ ë†’ìŠµë‹ˆë‹¤.\"], \"Step\": [\"ìš°ë¦¬ë°˜ì˜ ì˜¤ëŠ˜ ì‹¤ë‚´ì˜¨ë„ ì¿¼ë¦¬ê²°ê³¼ qr_roomtemp_ours ì— ì €ì¥\", \"ì˜†ë°˜ì˜ ì˜¤ëŠ˜ ì‹¤ë‚´ì˜¨ë„ ì¿¼ë¦¬ê²°ê³¼ qr_roomtemp_beside ì— ì €ì¥\", \"ê° ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ í‰ê·  ê³„ì‚°\", \"ê° ë°˜ì˜ í‰ê·  ì‹¤ë‚´ì˜¨ë„ì™€ ì°¨ì´ ë°˜í™˜\"]}, \"Instruction Set\": [{\"type\": \"q\", \"args\": {\"table_name\": \"data_t\", \"columns\": [\"roomtemp\"], \"conditions\": [\"timestamp BETWEEN '2022-09-30 00:00:00' AND '2022-09-30 23:59:59'\"], \"subquery\": \"idu_id IN (SELECT id FROM idu_t WHERE name IN ('01_IB5'))\"}, \"result_name\": \"qr_roomtemp_ours\"}, {\"type\": \"q\", \"args\": {\"table_name\": \"data_t\", \"columns\": [\"roomtemp\"], \"conditions\": [\"timestamp BETWEEN '2022-09-30 00:00:00' AND '2022-09-30 23:59:59'\"], \"subquery\": \"idu_id IN (SELECT id FROM idu_t WHERE name IN ('01_IB7'))\"}, \"result_name\": \"qr_roomtemp_beside\"}]}\n",
      "{\"Formalized Input\": \"ì´ë²ˆì£¼ ìš°ë¦¬ë°˜ê³¼ ì˜†ë°˜ì˜ ì„¤ì •ì˜¨ë„ ì°¨ì´ ì‹œê°í™” í•´ì¤˜.\", \"Input Semantic Parsing\": {\"Temporal\": {\"ì´ë²ˆì£¼\": \"2022-09-26 00:00:00 ~ 2022-10-02 23:59:59\"}, \"Spatial\": {\"ìš°ë¦¬ë°˜\": \"01_IB5\", \"ì˜†ë°˜\": \"01_IB7\"}, \"Modality\": {\"ì„¤ì •ì˜¨ë„\": \"settemp\"}}, \"Strategy\": {\"Objective\": \"ì´ë²ˆì£¼ ìš°ë¦¬ë°˜ê³¼ ì˜†ë°˜ì˜ ì„¤ì •ì˜¨ë„ì˜ ì°¨ì´ì˜ ì¶”ì´ë¥¼ ì‹œê°í™”\", \"Expected Outputs\": [\"(ê·¸ë˜í”„) Xì¶•: ë‚ ì§œ, Yì¶•: ì„¤ì •ì˜¨ë„ ì°¨ì´, ì°¨ì´ ì¶”ì´ ê·¸ë˜í”„\", \"ì´ë²ˆì£¼ ìš°ë¦¬ë°˜ì˜ í‰ê·  ì„¤ì •ì˜¨ë„ëŠ” 25â„ƒì´ê³ , ì˜†ë°˜ì€ 26â„ƒë¡œ 1â„ƒ ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤.\"], \"Step\": [\"ìš°ë¦¬ë°˜ê³¼ ì˜†ë°˜ì˜ ì´ë²ˆì£¼ ì„¤ì •ì˜¨ë„ ë°ì´í„°ë¥¼ ê°ê° ì¿¼ë¦¬ê²°ê³¼ qr_settemp_oursì™€ qr_settemp_besideì— ì €ì¥\", \"qr_settemp_oursì™€ qr_settemp_besideë¥¼ ì‹œê°í™”í•˜ì—¬ ì„¤ì •ì˜¨ë„ ì°¨ì´ ì¶”ì´ ê·¸ë˜í”„ ìƒì„±\", \"qr_settemp_oursì™€ qr_settemp_besideì—ì„œ ì„¤ì •ì˜¨ë„ì˜ í‰ê· ê°’ ê³„ì‚°\", \"ê·¸ë˜í”„, ì„¤ì •ì˜¨ë„ì˜ í‰ê· ê°’ë“¤ ë° ì°¨ì´ ë°˜í™˜\"]}, \"Instruction Set\": [{\"type\": \"q\", \"args\": {\"table_name\": \"data_t\", \"columns\": [\"settemp\"], \"conditions\": [\"timestamp BETWEEN '2022-09-26 00:00:00' AND '2022-10-02 23:59:59'\"], \"subquery\": \"idu_id = (SELECT id FROM idu_t WHERE name = '01_IB5')\"}, \"result_name\": \"qr_settemp_ours\"}, {\"type\": \"q\", \"args\": {\"table_name\": \"data_t\", \"columns\": [\"settemp\"], \"conditions\": [\"timestamp BETWEEN '2022-09-26 00:00:00' AND '2022-10-02 23:59:59'\"], \"subquery\": \"idu_id = (SELECT id FROM idu_t WHERE name = '01_IB7')\"}, \"result_name\": \"qr_settemp_beside\"}]}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54a1f7d2b4aa46c8b61e28b21ffe6677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Formalized Input\": \"ìš°ë¦¬ë°˜ ì˜¤ëŠ˜ ì•„ì¹¨ê³¼ ì €ë…ì˜ ì‹¤ë‚´ì˜¨ë„ ì°¨ì´ ì•Œë ¤ì¤˜.\", \"Input Semantic Parsing\": {\"Temporal\": {\"ì˜¤ëŠ˜ ì•„ì¹¨\": \"2022-09-30 06:00:00 ~ 2022-09-30 09:00:00\", \"ì˜¤ëŠ˜ ì €ë…\": \"2022-09-30 18:00:00 ~ 2022-09-30 21:00:00\"}, \"Spatial\": {\"ìš°ë¦¬ë°˜\": \"01_IB5\"}, \"Modality\": {\"ì‹¤ë‚´ì˜¨ë„\": \"roomtemp\"}}, \"Strategy\": {\"Objective\": \"ìš°ë¦¬ë°˜ ì˜¤ëŠ˜ ì•„ì¹¨ê³¼ ì €ë…ì˜ ì‹¤ë‚´ì˜¨ë„ ë°ì´í„° ì¿¼ë¦¬ í›„ í‰ê· ê°’ì„ ê³„ì‚°í•˜ì—¬ ì°¨ì´ë¥¼ ë°˜í™˜í•¨.\", \"Expected Outputs\": [\"ì˜¤ëŠ˜ ì•„ì¹¨(06:00 ~ 09:00, 24.5â„ƒ)ê³¼ ì €ë…(18:00 ~ 21:00, 27.3â„ƒ)ì˜ ì˜¨ë„ ì°¨ì´ëŠ” 2.8â„ƒ ì…ë‹ˆë‹¤.\"], \"Step\": [\"2022-09-30 06:00 ~ 09:00 ì‹œê°„ëŒ€ì˜ roomtemp ë°ì´í„° ì¡°íšŒí•´ qr_morning_tempì— ì €ì¥\", \"2022-09-30 18:00 ~ 21:00 ì‹œê°„ëŒ€ì˜ roomtemp ë°ì´í„° ì¡°íšŒí•´ qr_evening_tempì— ì €ì¥\", \"qr_morning_tempê³¼ qr_evening_tempì˜ í‰ê· ê°’ ë° ì°¨ì´ ë°˜í™˜\"]}, \"Instruction Set\": [{\"type\": \"q\", \"args\": {\"table_name\": \"data_t\", \"columns\": [\"timestamp\", \"roomtemp\"], \"conditions\": [\"timestamp BETWEEN '2022-09-30 06:00:00' AND '2022-09-30 09:00:00'\"], \"subquery\": \"idu_id = (SELECT id FROM idu_t WHERE name = '01_IB5')\"}, \"result_name\": \"qr_morning_temp\"}, {\"type\": \"q\", \"args\": {\"table_name\": \"data_t\", \"columns\": [\"timestamp\", \"roomtemp\"], \"conditions\": [\"timestamp BETWEEN '2022-09-30 18:00:00' AND '2022-09-30 21:00:00'\"], \"subquery\": \"idu_id = (SELECT id FROM idu_t WHERE name = '01_IB5')\"}, \"result_name\": \"qr_evening_temp\"}]}\n",
      "{\"Formalized Input\": \"ì´ë²ˆì£¼ ìš°ë¦¬ë°˜ê³¼ ì˜†ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ ë³€í™” ì¶”ì´ ë¹„êµí•´ì¤˜.\", \"Input Semantic Parsing\": {\"Temporal\": {\"ì´ë²ˆì£¼\": \"2022-09-26 00:00:00 ~ 2022-10-02 23:59:59\"}, \"Spatial\": {\"ìš°ë¦¬ë°˜\": \"01_IB5\", \"ì˜†ë°˜\": \"01_IB7\"}, \"Modality\": {\"ì‹¤ë‚´ì˜¨ë„\": \"roomtemp\"}, \"Operation\": [\"ë³€í™” ì¶”ì´\", \"ë¹„êµ\"]}, \"Strategy\": {\"Objective\": \"ì´ë²ˆì£¼ ìš°ë¦¬ë°˜ê³¼ ì˜†ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ ë°ì´í„°ë¥¼ ì¿¼ë¦¬ í›„, ê° ë°˜ì˜ ë³€í™” ì¶”ì´ë¥¼ ì‹œê°í™”í•˜ê³  ì£¼ìš” í†µê³„ ì •ë³´ë¥¼ ë¹„êµí•¨.\", \"Expected Outputs\": [\"(ê·¸ë˜í”„) Xì¶•: ë‚ ì§œ, Yì¶•: ì‹¤ë‚´ì˜¨ë„, ë‘ ë°˜ì˜ ë³€í™” ì¶”ì´ ê·¸ë˜í”„\", \"ì´ë²ˆì£¼ ìš°ë¦¬ë°˜ì˜ í‰ê·  ì‹¤ë‚´ì˜¨ë„ëŠ” 24â„ƒ, ìµœì € 22â„ƒ, ìµœê³  26â„ƒì…ë‹ˆë‹¤.\", \"ì´ë²ˆì£¼ ì˜†ë°˜ì˜ í‰ê·  ì‹¤ë‚´ì˜¨ë„ëŠ” 25â„ƒ, ìµœì € 23â„ƒ, ìµœê³  28â„ƒì…ë‹ˆë‹¤.\"], \"Step\": [\"ìš°ë¦¬ë°˜ê³¼ ì˜†ë°˜ì˜ ì´ë²ˆì£¼ ì‹¤ë‚´ì˜¨ë„ ë°ì´í„°ë¥¼ ê°ê° ì¿¼ë¦¬í•´ qr_roomtemp_oursì™€ qr_roomtemp_besideì— ì €ì¥\", \"ë‘ ë°˜ì˜ ë°ì´í„°ë¥¼ ì‹œê°í™”í•˜ì—¬ ë³€í™” ì¶”ì´ ë¹„êµ ê·¸ë˜í”„ ìƒì„±\", \"ê° ë°˜ì˜ í‰ê· , ìµœì €, ìµœê³ ê°’ ê³„ì‚°\", \"ê·¸ë˜í”„ì™€ í†µê³„ì  ë¹„êµ ì •ë³´ ë°˜í™˜\"]}, \"Instruction Set\": [{\"type\": \"q\", \"args\": {\"table_name\": \"data_t\", \"columns\": [\"timestamp\", \"roomtemp\"], \"conditions\": [\"timestamp BETWEEN '2022-09-26 00:00:00' AND '2022-10-02 23:59:59'\"], \"subquery\": \"idu_id = (SELECT id FROM idu_t WHERE name = '01_IB5')\"}, \"result_name\": \"qr_roomtemp_ours\"}, {\"type\": \"q\", \"args\": {\"table_name\": \"data_t\", \"columns\": [\"timestamp\", \"roomtemp\"], \"conditions\": [\"timestamp BETWEEN '2022-09-26 00:00:00' AND '2022-10-02 23:59:59'\"], \"subquery\": \"idu_id = (SELECT id FROM idu_t WHERE name = '01_IB7')\"}, \"result_name\": \"qr_roomtemp_beside\"}]}\n",
      "1290\n"
     ]
    }
   ],
   "source": [
    "def read_dataset(path):\n",
    "    # the file is originally json-list format\n",
    "    # we want every first-level elements to be a string itself\n",
    "    # for example, [{\"Hi\": \"a'b'\"}, {\"Hi\": \"c'd'\"}] -> [\"\"\"{\"Hi\": \"a'b'\"}\"\"\", \"\"\"{\"Hi\": \"c'd'\"}\"\"\"]\n",
    "    \n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.loads(f.read())\n",
    "    \n",
    "    result = [{\"Input\": d[\"Input\"], \"Response\": json.dumps(d[\"Response\"], ensure_ascii=False)} for d in data]\n",
    "    # print(f\"Read {len(result)} examples from {path}\")\n",
    "    # print(f\"Type of result: {type(result)}\")\n",
    "    # print(f\"Type of result[0]: {type(result[0])}\")\n",
    "    # print(f\"Type of result[0]['Input']: {type(result[0]['Input'])}\")\n",
    "    # print(f\"Type of result[0]['Response']: {type(result[0]['Response'])}\")\n",
    "    return result\n",
    "\n",
    "import re\n",
    "\n",
    "# dataset_tr = Dataset.from_list(read_dataset(\"training_dataset_v2_directsql_tr.json\"))\n",
    "# dataset_ts = Dataset.from_list(read_dataset(\"training_dataset_v2_directsql_ts.json\"))\n",
    "dataset_tr = Dataset.from_list(read_dataset(\"training_dataset_v4_onlyq_tr.json\"))\n",
    "dataset_ts = Dataset.from_list(read_dataset(\"training_dataset_v4_onlyq_ts.json\"))\n",
    "\n",
    "# dataset = load_dataset(\"json\", data_files=\"training_dataset_v2_directsql.json\")\n",
    "max_seq_length = 0\n",
    "def formatting_prompts_func(examples):\n",
    "    convos = []\n",
    "    # Iterate through each item in the batch (examples are structured as lists of values)\n",
    "    for input, response in zip(examples['Input'], examples['Response']):\n",
    "        global max_seq_length\n",
    "        response.replace(\"    \", \"\")\n",
    "        answer = {\n",
    "            \"content\": f\"{response}\",\n",
    "            \"role\": \"assistant\"\n",
    "        }\n",
    "        if \"llama\" in model_id.lower():\n",
    "            prompt = {\n",
    "                \"content\": common_prompt,\n",
    "                \"role\": \"system\"\n",
    "            }\n",
    "            user_input = {\n",
    "                \"content\": f\"{current_metadata};{input}\",\n",
    "                \"role\": \"user\"\n",
    "            }\n",
    "            convos.append([prompt, user_input, answer])\n",
    "        elif \"gemma\" in model_id.lower():\n",
    "            user_input = {\n",
    "                \"content\": f\"{common_prompt};{current_metadata};{input}\",\n",
    "                \"role\": \"user\"\n",
    "            }\n",
    "            convos.append([user_input, answer])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # print(\"Answer length: \", len(response))\n",
    "        # convos.append([prompt, user_input, answer])\n",
    "        \n",
    "        if len(response) + 50 > max_seq_length:\n",
    "            max_seq_length = len(response) + 50\n",
    "            print(response)\n",
    "    \n",
    "    texts = [\n",
    "        tokenizer.apply_chat_template(convo, tokenize=False, add_generation_prompt=False)\n",
    "        for convo in convos]\n",
    "    # remove \\n\\nCutting Knowledge Date: BLAH BLAH \\nToday Date: BLAH BLAH\\n\\n using regex\n",
    "    texts = [re.sub(r'(\\nCutting Knowledge Date:.*?\\nToday Date:.*?\\n\\n)', '', text) for text in texts]\n",
    "    \n",
    "    return {\"text\": texts}\n",
    "\n",
    "dataset_tr = dataset_tr.map(formatting_prompts_func, batched=True)\n",
    "dataset_ts = dataset_ts.map(formatting_prompts_func, batched=True)\n",
    "\n",
    "# print(dataset_tr[0][\"text\"])\n",
    "print(max_seq_length)\n",
    "# print(f\"seq length: {len(tokenizer.encode(dataset_tr[0]['text']))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "\n",
    "torch.cuda.empty_cache()\n",
    "model = model.to(device)\n",
    "print(len(dataset_tr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Accumulation Steps: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "874a238819f2470bab67b8bc473c78c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/36 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c6be4f44fa8428fbb50f25cd882c5db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/15 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a processing_class with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `processing_class.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer, SFTConfig\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "per_device_train_batch_size, epochs = 18, 1000 # 8\n",
    "gradient_accumulation_steps = int(np.ceil(len(dataset_tr) / per_device_train_batch_size))\n",
    "print(f\"Gradient Accumulation Steps: {gradient_accumulation_steps}\")\n",
    "\n",
    "# clear all checkpoints\n",
    "import shutil\n",
    "shutil.rmtree(f\"{model_dir}/chkpts/full-tuning\", ignore_errors=True)\n",
    "\n",
    "args = SFTConfig(\n",
    "    # num_train_epochs = 1,\n",
    "    per_device_train_batch_size = per_device_train_batch_size,  # Controls the batch size per device\n",
    "    per_device_eval_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps = gradient_accumulation_steps,  # Accumulates gradients to simulate a larger batch\n",
    "    max_steps=gradient_accumulation_steps * epochs,\n",
    "    # ë¦¬ì†ŒìŠ¤ ì œì•½ë•Œë¬¸ì— batch sizeë¥¼ íƒ€í˜‘í•´ì•¼í•˜ëŠ” ê²½ìš°ê°€ ë°œìƒ -> micro batch sizeë¥¼ ì¤„ì´ê³ ,\n",
    " \t# accumulated stepì„ ëŠ˜ë ¤, ì ì ˆí•œ sizeë¡œ gradientë¥¼ êµ¬í•´ weight update\n",
    "    # https://www.youtube.com/watch?v=ptlmj9Y9iwE\n",
    "    warmup_steps = gradient_accumulation_steps,\n",
    "    learning_rate = 1e-4,             # Sets the learning rate for optimization\n",
    "    fp16 = not torch.cuda.is_bf16_supported(),\n",
    "    bf16 = torch.cuda.is_bf16_supported(),\n",
    "    optim = \"adamw_8bit\",\n",
    "    weight_decay = 0.01,              # Regularization term for preventing overfitting\n",
    "    lr_scheduler_type = \"cosine\",  # Sets the learning rate scheduler\n",
    "    seed = 3407,                        \n",
    "    output_dir = f\"{model_dir}/chkpts/full-tuning\",  # Output directory for checkpoints and predictions     \n",
    "    report_to = \"none\",              # Enables Weights & Biases (W&B) logging\n",
    "    logging_steps = gradient_accumulation_steps,                # Sets frequency of logging to W&B\n",
    "    logging_strategy = \"steps\",       # Logs metrics at each specified step\n",
    "    evaluation_strategy=\"steps\",  # enable evaluation during training\n",
    "    eval_steps=gradient_accumulation_steps,\n",
    "    # eval_accumulation_steps=1, # ë‚®ì„ìˆ˜ë¡ evalì‹œ ì‚¬ìš©í•˜ëŠ” ë©”ëª¨ë¦¬ ì¤„ì–´ë“¦\n",
    "    save_steps=gradient_accumulation_steps,\n",
    "    save_strategy = \"steps\",               \n",
    "    load_best_model_at_end = True,    # Loads the best model at the end\n",
    "    save_only_model = False,           # Saves entire model, not only weights\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False, \n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "# training_args = SFTConfig(\n",
    "    \n",
    "#     output_dir = \"/tmp\"\n",
    "# )\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    processing_class = tokenizer,\n",
    "    train_dataset = dataset_tr,\n",
    "    eval_dataset = dataset_ts,\n",
    "    args = args,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 47.41 GiB of which 8.94 MiB is free. Process 1188235 has 42.59 GiB memory in use. Process 1211765 has 4.78 GiB memory in use. Of the allocated memory 4.48 GiB is allocated by PyTorch, and 41.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# from unsloth import unsloth_train\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# trainer_stats = unsloth_train(trainer)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# print(trainer_stats)\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/transformers/trainer.py:2171\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2169\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2172\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/transformers/trainer.py:2330\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2328\u001b[0m         model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mprepare(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[1;32m   2329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2330\u001b[0m         model, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2331\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2332\u001b[0m     \u001b[38;5;66;03m# to handle cases wherein we pass \"DummyScheduler\" such as when it is specified in DeepSpeed config.\u001b[39;00m\n\u001b[1;32m   2333\u001b[0m     model, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mprepare(\n\u001b[1;32m   2334\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler\n\u001b[1;32m   2335\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/accelerate/accelerator.py:1339\u001b[0m, in \u001b[0;36mAccelerator.prepare\u001b[0;34m(self, device_placement, *args)\u001b[0m\n\u001b[1;32m   1337\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp8_backend \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMSAMP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1338\u001b[0m         args, device_placement \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_msamp(\u001b[38;5;241m*\u001b[39margs, device_placement\u001b[38;5;241m=\u001b[39mdevice_placement)\n\u001b[0;32m-> 1339\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1340\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirst_pass\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_placement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_placement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1341\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1342\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_one(obj, device_placement\u001b[38;5;241m=\u001b[39md) \u001b[38;5;28;01mfor\u001b[39;00m obj, d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(result, device_placement))\n\u001b[1;32m   1343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tpu_should_fix_optimizer:\n\u001b[1;32m   1344\u001b[0m     \u001b[38;5;66;03m# 2. grabbing new model parameters\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/accelerate/accelerator.py:1340\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1337\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp8_backend \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMSAMP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1338\u001b[0m         args, device_placement \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_msamp(\u001b[38;5;241m*\u001b[39margs, device_placement\u001b[38;5;241m=\u001b[39mdevice_placement)\n\u001b[1;32m   1339\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[0;32m-> 1340\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirst_pass\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_placement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m obj, d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(args, device_placement)\n\u001b[1;32m   1341\u001b[0m     )\n\u001b[1;32m   1342\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_one(obj, device_placement\u001b[38;5;241m=\u001b[39md) \u001b[38;5;28;01mfor\u001b[39;00m obj, d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(result, device_placement))\n\u001b[1;32m   1343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tpu_should_fix_optimizer:\n\u001b[1;32m   1344\u001b[0m     \u001b[38;5;66;03m# 2. grabbing new model parameters\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/accelerate/accelerator.py:1215\u001b[0m, in \u001b[0;36mAccelerator._prepare_one\u001b[0;34m(self, obj, first_pass, device_placement)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_data_loader(obj, device_placement\u001b[38;5;241m=\u001b[39mdevice_placement)\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[0;32m-> 1215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_placement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_placement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer):\n\u001b[1;32m   1217\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_optimizer(obj, device_placement\u001b[38;5;241m=\u001b[39mdevice_placement)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/accelerate/accelerator.py:1452\u001b[0m, in \u001b[0;36mAccelerator.prepare_model\u001b[0;34m(self, model, device_placement, evaluation_mode)\u001b[0m\n\u001b[1;32m   1447\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1448\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt train a model that has been loaded in 8-bit or 4-bit precision with CPU or disk offload. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1449\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you want train the 8-bit or 4-bit model in CPU, please install bitsandbytes with multi-backend, see https://huggingface.co/docs/bitsandbytes/main/en/installation#multi-backend\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1450\u001b[0m         )\n\u001b[1;32m   1451\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m device_placement \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_device_map(model):\n\u001b[0;32m-> 1452\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evaluation_mode:\n\u001b[1;32m   1454\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1455\u001b[0m         DistributedType\u001b[38;5;241m.\u001b[39mMULTI_GPU,\n\u001b[1;32m   1456\u001b[0m         DistributedType\u001b[38;5;241m.\u001b[39mMULTI_MLU,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1459\u001b[0m         DistributedType\u001b[38;5;241m.\u001b[39mMULTI_XPU,\n\u001b[1;32m   1460\u001b[0m     ):\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/transformers/modeling_utils.py:3110\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3105\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[1;32m   3106\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3107\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3108\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3109\u001b[0m         )\n\u001b[0;32m-> 3110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1343\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1340\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1341\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1343\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:903\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 903\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    907\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    908\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    914\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:903\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 903\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    907\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    908\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    914\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 903 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:903\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 903\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    907\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    908\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    913\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    914\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:930\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 930\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    931\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    933\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1329\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1323\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1324\u001b[0m             device,\n\u001b[1;32m   1325\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1326\u001b[0m             non_blocking,\n\u001b[1;32m   1327\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1328\u001b[0m         )\n\u001b[0;32m-> 1329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1333\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1334\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1335\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 47.41 GiB of which 8.94 MiB is free. Process 1188235 has 42.59 GiB memory in use. Process 1211765 has 4.78 GiB memory in use. Of the allocated memory 4.48 GiB is allocated by PyTorch, and 41.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# from unsloth import unsloth_train\n",
    "\n",
    "# trainer_stats = unsloth_train(trainer)\n",
    "# print(trainer_stats)\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/model/sh2orc-Llama-3.1-Korean-8B-Instruct/chkpts/r256_a512/checkpoint-12\n",
      "==((====))==  Unsloth 2025.2.5: Fast Llama patching. Transformers: 4.48.3.\n",
      "   \\\\   /|    GPU: NVIDIA RTX A6000. Max memory: 47.413 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post2. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f8f136469e4758bec80846f6196261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad Token id: 128004 and Pad Token: <|finetune_right_pad_id|>\n",
      "EOS Token id: 128009 and EOS Token: <|eot_id|>\n",
      "Padding side: left\n"
     ]
    }
   ],
   "source": [
    "# del base_model\n",
    "# del peft_model\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Specify the checkpoint directory\n",
    "checkpoint_dir = f\"{model_dir}/chkpts/full-tuning/checkpoint-{12}\"\n",
    "# checkpoint_dir = \"/model/Bllossom-llama-3.2-Korean-Bllossom-3B/chkpts/r1700_a1500/checkpoint-12\"\n",
    "print(checkpoint_dir)\n",
    "# Load the tokenizer (ensure it's the same tokenizer used for training)\n",
    "\n",
    "# Load the base model\n",
    "peft_model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    checkpoint_dir,\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    quantization_config=BitsAndBytesConfig(\n",
    "        # load_in_4bit=True,\n",
    "        # bnb_4bit_use_double_quant=True,\n",
    "        # bnb_4bit_quant_type=\"nf4\",\n",
    "        # bnb_4bit_compute_dtype=torch_dtype\n",
    "        load_in_8bit=True,\n",
    "        llm_int8_enable_fp32_cpu_offload=True\n",
    "    ),\n",
    "    device_map=device,\n",
    "    # cache_dir=\"/model\",\n",
    "    attn_implementation=attn_implementation,\n",
    "    cache_dir=f\"{model_dir}/cache\",\n",
    "    local_files_only=True\n",
    ")\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "# tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.padding_side = \"left\"\n",
    "# tokenizer.truncation_side = \"left\"\n",
    "\n",
    "print(f\"Pad Token id: {tokenizer.pad_token_id} and Pad Token: {tokenizer.pad_token}\")\n",
    "print(f\"EOS Token id: {tokenizer.eos_token_id} and EOS Token: {tokenizer.eos_token}\")\n",
    "print(f\"Padding side: {tokenizer.padding_side}\")\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "# \n",
    "\n",
    "\n",
    "# Make sure the tokenizer is ready\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # Local saving\n",
    "    peft_model.save_pretrained(\"lora_i2i\") \n",
    "    tokenizer.save_pretrained(\"lora_i2i\")\n",
    "\n",
    "    # For merging the LoRA adapters with the base model and save the model to 16-bit precision for optimized performance with vLLM, use:\n",
    "    # # Merge to 16bit\n",
    "    peft_model.save_pretrained_merged(\"i2i_merged_16bit\", tokenizer, save_method = \"merged_16bit\",)\n",
    "    peft_model.save_pretrained_merged(\"i2i_merged_4bit\", tokenizer, save_method = \"merged_4bit_forced\",)\n",
    "    # model.push_to_hub_merged(\"<hf_username/model_name>\", tokenizer, save_method = \"merged_16bit\", token = hf_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tryout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 4096, padding_idx=128004)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=256, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=256, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=256, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=256, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=256, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=256, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=256, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=256, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=256, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=256, out_features=14336, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=256, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=256, out_features=14336, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=14336, out_features=256, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=256, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "from transformers import TextStreamer\n",
    "if False:\n",
    "    # del peft_model\n",
    "    torch.cuda.empty_cache()\n",
    "    peft_model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name = \"i2i_merged_16bit\",        # Trained model either locally or from huggingface\n",
    "        max_seq_length = max_seq_length,\n",
    "        dtype = dtype,\n",
    "        load_in_4bit = False,\n",
    "        attn_implementation=attn_implementation,\n",
    "        # device_map=[device],\n",
    "        local_files_only=True\n",
    "    )\n",
    "FastLanguageModel.for_inference(peft_model)  # Enable native 2x faster inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Instruction(['q', 'ì´ë²ˆë‹¬ ìš°ë¦¬ë°˜ ì‹¤ë‚´ì˜¨ë„ê°€ ìµœê³ ì¸ ë‚ ì§œ ì•Œë ¤ì¤˜.', 'ì´ë²ˆë‹¬ ìš°ë¦¬ë°˜ ì‹¤ë‚´ì˜¨ë„ê°€ ìµœê³ ì¸ ë‚ ì§œ', 'ê°’', Semantic(Temporal=[('ì´ë²ˆë‹¬', '2022-09-01 00:00:00 ~ 2022-09-30 23:59:59')], Spatial=['ìš°ë¦¬ë°˜'], Modality=['ì‹¤ë‚´ì˜¨ë„'], Operation=['ìµœê³ ì¸'], Target=['ë‚ ì§œ'])]), Instruction(['r', \"ì˜ˆ) 'ì´ë²ˆë‹¬ ìš°ë¦¬ë°˜ì˜ ì‹¤ë‚´ ì˜¨ë„ê°€ ê°€ì¥ ë”ì› ë˜ ë‚ ì€ 2022ë…„ 9ì›” 15ì¼ì…ë‹ˆë‹¤.'\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, time\n",
    "\n",
    "def extract_content(text):\n",
    "    # Define the regex pattern to extract the content\n",
    "    pattern = r\"<\\|start_header_id\\|>assistant<\\|end_header_id\\|>(.*?)<\\|eot_id\\|>\"\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return None\n",
    "\n",
    "def run(query):\n",
    "    start_time = time.time()\n",
    "    chat = [\n",
    "        {\"role\": \"system\", \"content\": f\"{common_prompt}\"},\n",
    "        # {\"role\": \"metadata\", \"content\": f\"{current_metadata}\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{current_metadata};{query}\"},\n",
    "    ]\n",
    "    \n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        chat,\n",
    "        tokenize = True,\n",
    "        add_generation_prompt = True, # Must add for generation\n",
    "        return_tensors = \"pt\",\n",
    "    ).to(\"cuda\")\n",
    "    \n",
    "    outputs = peft_model.generate(\n",
    "        input_ids = inputs,\n",
    "        max_new_tokens = max_seq_length,\n",
    "        use_cache = True,\n",
    "        pad_token_id = tokenizer.eos_token_id,\n",
    "        eos_token_id = tokenizer.eos_token_id,\n",
    "    )\n",
    "    \n",
    "    response = tokenizer.batch_decode(outputs)[0]\n",
    "    # print(response)\n",
    "    # print(\"Extracting..\")\n",
    "    parsed_response = extract_content(response)\n",
    "    pprint.pprint(f\"Query: {query}, Time: {time.time() - start_time}\")\n",
    "    print(parsed_response)\n",
    "    \n",
    "    parsed_response_dict = eval(parsed_response)\n",
    "    \n",
    "    return parsed_response, parsed_response_dict\n",
    "    \n",
    "    # text_streamer = transformers.TextStreamer(\n",
    "    #     tokenizer, \n",
    "    # skip_prompt = True\n",
    "    # )\n",
    "    # _ = peft_model.generate(\n",
    "    #     input_ids = inputs, \n",
    "    #     streamer = text_streamer, \n",
    "    #     max_new_tokens = max_seq_length, \n",
    "    #     use_cache = True,\n",
    "    #     pad_token_id = tokenizer.eos_token_id,\n",
    "    #     eos_token_id = tokenizer.eos_token_id,\n",
    "    # )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Query: ì˜¤ëŠ˜ ìš°ë¦¬ë°˜ê³¼ ì˜†ë°˜ì˜ í‰ê·  ì˜¨ë„ì°¨ì´ ì•Œë ¤ì¤˜, Time: 76.17268538475037'\n",
      "None\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "eval() arg 1 must be a string, bytes or code object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mì˜¤ëŠ˜ ìš°ë¦¬ë°˜ê³¼ ì˜†ë°˜ì˜ í‰ê·  ì˜¨ë„ì°¨ì´ ì•Œë ¤ì¤˜\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# parsed_response_dict = eval(result)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# print(parsed_response_dict)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[23], line 41\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m     38\u001b[0m pprint\u001b[38;5;241m.\u001b[39mpprint(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuery: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(parsed_response)\n\u001b[0;32m---> 41\u001b[0m parsed_response_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparsed_response\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response, parsed_response_dict\n",
      "\u001b[0;31mTypeError\u001b[0m: eval() arg 1 must be a string, bytes or code object"
     ]
    }
   ],
   "source": [
    "result = run(\"ì˜¤ëŠ˜ ìš°ë¦¬ë°˜ê³¼ ì˜†ë°˜ì˜ í‰ê·  ì˜¨ë„ì°¨ì´ ì•Œë ¤ì¤˜\")\n",
    "# parsed_response_dict = eval(result)\n",
    "\n",
    "# print(parsed_response_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Query: ì˜¤ëŠ˜ ìš°ë¦¬ë°˜ í‰ê· ì˜¨ë„ ì•Œë ¤ì¤˜, Time: 11.774609327316284'\n",
      "{\"Formalized Input\": \"ì˜¤ëŠ˜ ìš°ë¦¬ë°˜(01_IB5) í‰ê·  ì‹¤ë‚´ì˜¨ë„ë¥¼ ì•Œë ¤ì¤˜.\", \"Input Semantic Parsing\": {\"Temporal\": {\"ì˜¤ëŠ˜\": \"2022-09-30 00:00:00 ~ 2022-09-30 23:59:59\"}, \"Spatial\": {\"ìš°ë¦¬ë°˜\": \"01_IB5\"}, \"Modality\": {\"ì‹¤ë‚´ì˜¨ë„\": \"roomtemp\"}}, \"Strategy\": {\"Objective\": \"ì˜¤ëŠ˜ ìš°ë¦¬ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ ë°ì´í„°ë¥¼ ì¿¼ë¦¬ í›„ í‰ê· ê°’ ê³„ì‚°\", \"Expected Outputs\": [\"ì˜¤ëŠ˜ ìš°ë¦¬ë°˜ì˜ í‰ê·  ì‹¤ë‚´ì˜¨ë„ëŠ” 25.5â„ƒì…ë‹ˆë‹¤.\"], \"Step\": [\"ì˜¤ëŠ˜ ìš°ë¦¬ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ ë°ì´í„°ë¥¼ ì¿¼ë¦¬ê²°ê³¼ qr_roomtemp_todayì— ì €ì¥\", \"qr_roomtemp_todayì—ì„œ ì‹¤ë‚´ì˜¨ë„ì˜ í‰ê· ê°’ ê³„ì‚°\", \"ì‹¤ë‚´ì˜¨ë„ì˜ í‰ê· ê°’ ë°˜í™˜\"]}, \"Instruction Set\": [{\"type\": \"q\", \"run\": {\"args\": {\"table_name\": \"data_t\", \"columns\": [\"roomtemp\"], \"conditions\": [\"timestamp BETWEEN '2022-09-30 00:00:00' AND '2022-09-30 23:59:59'\"], \"subquery\": \"idu_id = (SELECT id FROM idu_t WHERE name = '01_IB5')\"}}, \"result\": {\"name\": \"qr_roomtemp_today\"}}, {\"type\": \"o\", \"python_script_to_process\": \"avg_roomtemp = qr_roomtemp_today['roomtemp'].mean()\", \"return\": [\"avg_roomtemp\"]}, {\"type\": \"r\", \"templates\": [\"ì˜¤ëŠ˜ ìš°ë¦¬ë°˜ì˜ í‰ê·  ì‹¤ë‚´ì˜¨ë„ëŠ” {avg_roomtemp}â„ƒì…ë‹ˆë‹¤.\"]}]}\n",
      "'Query: ì–´ì œ ì˜†ë°˜ ì˜¨ë„ í‰ê·  ì•Œë ¤ì¤˜, Time: 11.723241329193115'\n",
      "{\"Formalized Input\": \"ì–´ì œ ì˜†ë°˜ ì‹¤ë‚´ì˜¨ë„ì˜ í‰ê· ê°’ì„ ì•Œë ¤ì¤˜.\", \"Input Semantic Parsing\": {\"Temporal\": {\"ì–´ì œ\": \"2022-09-29 00:00:00 ~ 2022-09-29 23:59:59\"}, \"Spatial\": {\"ì˜†ë°˜\": \"01_IB7\"}, \"Modality\": {\"ì‹¤ë‚´ì˜¨ë„\": \"roomtemp\"}}, \"Strategy\": {\"Objective\": \"ì–´ì œ ì˜†ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ ë°ì´í„°ë¥¼ ì¿¼ë¦¬ í›„ í‰ê· ê°’ ê³„ì‚°\", \"Expected Outputs\": [\"ì–´ì œ ì˜†ë°˜ì˜ í‰ê·  ì‹¤ë‚´ì˜¨ë„ëŠ” 25â„ƒì˜€ìŠµë‹ˆë‹¤.\"], \"Step\": [\"ì–´ì œ ì˜†ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ ë°ì´í„°ë¥¼ ì¿¼ë¦¬í•´ qr_roomtemp_yesterdayì— ì €ì¥\", \"qr_roomtemp_yesterdayì—ì„œ roomtempì˜ í‰ê· ê°’ ê³„ì‚°\", \"í‰ê· ê°’ ë°˜í™˜\"]}, \"Instruction Set\": [{\"type\": \"q\", \"run\": {\"args\": {\"table_name\": \"data_t\", \"columns\": [\"roomtemp\"], \"conditions\": [\"timestamp BETWEEN '2022-09-29 00:00:00' AND '2022-09-29 23:59:59'\"], \"subquery\": \"idu_id = (SELECT id FROM idu_t WHERE name = '01_IB7')\"}}, \"result\": {\"name\": \"qr_roomtemp_yesterday\"}}, {\"type\": \"o\", \"python_script_to_process\": \"avg_roomtemp = qr_roomtemp_yesterday['roomtemp'].mean()\", \"return\": [\"avg_roomtemp\"]}, {\"type\": \"r\", \"templates\": [\"ì–´ì œ ì˜†ë°˜ì˜ í‰ê·  ì‹¤ë‚´ì˜¨ë„ëŠ” {avg_roomtemp}â„ƒì˜€ìŠµë‹ˆë‹¤.\"]}]}\n",
      "'Query: í˜„ì¬ ìš°ë¦¬ë°˜ ì‹¤ë‚´ì˜¨ë„ ì•Œë ¤ì¤˜, Time: 10.658740758895874'\n",
      "{\"Formalized Input\": \"í˜„ì¬ 01_IB5 ì‹¤ë‚´ì˜¨ë„ ì•Œë ¤ì¤˜.\", \"Input Semantic Parsing\": {\"Temporal\": {\"í˜„ì¬\": \"2022-09-30 12:00:00\"}, \"Spatial\": {\"01_IB5\": \"ìš°ë¦¬ë°˜\"}, \"Modality\": {\"ì‹¤ë‚´ì˜¨ë„\": \"roomtemp\"}}, \"Strategy\": {\"Objective\": \"01_IB5ì˜ ì‹¤ë‚´ì˜¨ë„ ë°ì´í„°ë¥¼ í˜„ì¬ ì‹œì ìœ¼ë¡œ ì¿¼ë¦¬ í›„ ë°˜í™˜\", \"Expected Outputs\": [\"01_IB5ì˜ ì‹¤ë‚´ì˜¨ë„ëŠ” 24â„ƒì…ë‹ˆë‹¤.\"], \"Step\": [\"01_IB5ì˜ ì‹¤ë‚´ì˜¨ë„ ë°ì´í„°ë¥¼ í˜„ì¬ ì‹œì ìœ¼ë¡œ ì¿¼ë¦¬ê²°ê³¼ qr_roomtemp_01_IB5ì— ì €ì¥\", \"qr_roomtemp_01_IB5ì—ì„œ ì‹¤ë‚´ì˜¨ë„ ë°˜í™˜\"]}, \"Instruction Set\": [{\"type\": \"q\", \"run\": {\"args\": {\"table_name\": \"data_t\", \"columns\": [\"roomtemp\"], \"conditions\": [\"timestamp = '2022-09-30 12:00:00'\"], \"subquery\": \"idu_id = (SELECT id FROM idu_t WHERE name = '01_IB5')\"}}, \"result\": {\"name\": \"qr_roomtemp_01_IB5\"}}, {\"type\": \"r\", \"python_script_to_process\": \"roomtemp = qr_roomtemp_01_IB5['roomtemp'].values[0]\", \"return\": [\"roomtemp\"]}, {\"type\": \"o\", \"templates\": [\"01_IB5ì˜ ì‹¤ë‚´ì˜¨ë„ëŠ” {roomtemp}â„ƒì…ë‹ˆë‹¤.\"]}]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('{\"Formalized Input\": \"í˜„ì¬ 01_IB5 ì‹¤ë‚´ì˜¨ë„ ì•Œë ¤ì¤˜.\", \"Input Semantic Parsing\": {\"Temporal\": {\"í˜„ì¬\": \"2022-09-30 12:00:00\"}, \"Spatial\": {\"01_IB5\": \"ìš°ë¦¬ë°˜\"}, \"Modality\": {\"ì‹¤ë‚´ì˜¨ë„\": \"roomtemp\"}}, \"Strategy\": {\"Objective\": \"01_IB5ì˜ ì‹¤ë‚´ì˜¨ë„ ë°ì´í„°ë¥¼ í˜„ì¬ ì‹œì ìœ¼ë¡œ ì¿¼ë¦¬ í›„ ë°˜í™˜\", \"Expected Outputs\": [\"01_IB5ì˜ ì‹¤ë‚´ì˜¨ë„ëŠ” 24â„ƒì…ë‹ˆë‹¤.\"], \"Step\": [\"01_IB5ì˜ ì‹¤ë‚´ì˜¨ë„ ë°ì´í„°ë¥¼ í˜„ì¬ ì‹œì ìœ¼ë¡œ ì¿¼ë¦¬ê²°ê³¼ qr_roomtemp_01_IB5ì— ì €ì¥\", \"qr_roomtemp_01_IB5ì—ì„œ ì‹¤ë‚´ì˜¨ë„ ë°˜í™˜\"]}, \"Instruction Set\": [{\"type\": \"q\", \"run\": {\"args\": {\"table_name\": \"data_t\", \"columns\": [\"roomtemp\"], \"conditions\": [\"timestamp = \\'2022-09-30 12:00:00\\'\"], \"subquery\": \"idu_id = (SELECT id FROM idu_t WHERE name = \\'01_IB5\\')\"}}, \"result\": {\"name\": \"qr_roomtemp_01_IB5\"}}, {\"type\": \"r\", \"python_script_to_process\": \"roomtemp = qr_roomtemp_01_IB5[\\'roomtemp\\'].values[0]\", \"return\": [\"roomtemp\"]}, {\"type\": \"o\", \"templates\": [\"01_IB5ì˜ ì‹¤ë‚´ì˜¨ë„ëŠ” {roomtemp}â„ƒì…ë‹ˆë‹¤.\"]}]}',\n",
       " {'Formalized Input': 'í˜„ì¬ 01_IB5 ì‹¤ë‚´ì˜¨ë„ ì•Œë ¤ì¤˜.',\n",
       "  'Input Semantic Parsing': {'Temporal': {'í˜„ì¬': '2022-09-30 12:00:00'},\n",
       "   'Spatial': {'01_IB5': 'ìš°ë¦¬ë°˜'},\n",
       "   'Modality': {'ì‹¤ë‚´ì˜¨ë„': 'roomtemp'}},\n",
       "  'Strategy': {'Objective': '01_IB5ì˜ ì‹¤ë‚´ì˜¨ë„ ë°ì´í„°ë¥¼ í˜„ì¬ ì‹œì ìœ¼ë¡œ ì¿¼ë¦¬ í›„ ë°˜í™˜',\n",
       "   'Expected Outputs': ['01_IB5ì˜ ì‹¤ë‚´ì˜¨ë„ëŠ” 24â„ƒì…ë‹ˆë‹¤.'],\n",
       "   'Step': ['01_IB5ì˜ ì‹¤ë‚´ì˜¨ë„ ë°ì´í„°ë¥¼ í˜„ì¬ ì‹œì ìœ¼ë¡œ ì¿¼ë¦¬ê²°ê³¼ qr_roomtemp_01_IB5ì— ì €ì¥',\n",
       "    'qr_roomtemp_01_IB5ì—ì„œ ì‹¤ë‚´ì˜¨ë„ ë°˜í™˜']},\n",
       "  'Instruction Set': [{'type': 'q',\n",
       "    'run': {'args': {'table_name': 'data_t',\n",
       "      'columns': ['roomtemp'],\n",
       "      'conditions': [\"timestamp = '2022-09-30 12:00:00'\"],\n",
       "      'subquery': \"idu_id = (SELECT id FROM idu_t WHERE name = '01_IB5')\"}},\n",
       "    'result': {'name': 'qr_roomtemp_01_IB5'}},\n",
       "   {'type': 'r',\n",
       "    'python_script_to_process': \"roomtemp = qr_roomtemp_01_IB5['roomtemp'].values[0]\",\n",
       "    'return': ['roomtemp']},\n",
       "   {'type': 'o', 'templates': ['01_IB5ì˜ ì‹¤ë‚´ì˜¨ë„ëŠ” {roomtemp}â„ƒì…ë‹ˆë‹¤.']}]})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "run(\"ì˜¤ëŠ˜ ìš°ë¦¬ë°˜ í‰ê· ì˜¨ë„ ì•Œë ¤ì¤˜\")\n",
    "\n",
    "run(\"ì–´ì œ ì˜†ë°˜ ì˜¨ë„ í‰ê·  ì•Œë ¤ì¤˜\")\n",
    "run(\"í˜„ì¬ ìš°ë¦¬ë°˜ ì‹¤ë‚´ì˜¨ë„ ì•Œë ¤ì¤˜\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Query: ë¡¯ë°ìºìŠ¬ì˜ í˜„ì¬ ì˜¨ë„ ì•Œë ¤ì¤˜, Time: 5.028217315673828'\n",
      "{\"Formalized Input\": \"ë¡¯ë°ìºìŠ¬ì˜ í˜„ì¬ ì‹¤ë‚´ì˜¨ë„ë¥¼ ì•Œë ¤ì¤˜.\", \"Input Semantic Parsing\": {\"Temporal\": {\"í˜„ì¬\": \"2022-09-30 12:00:00\"}, \"Spatial\": {\"ë¡¯ë°ìºìŠ¬\": \"unknown\"}, \"Modality\": {\"ì‹¤ë‚´ì˜¨ë„\": \"roomtemp\"}}, \"Strategy\": {\"Objective\": \"unknown spatial entityë¥¼ userì—ê²Œ ë¬¼ì–´ë³´ê³ , ê·¸ì— ë§ëŠ” ë‹µë³€ ì œê³µ\", \"Expected Outputs\": [\"unknown spatial entityë¥¼ ë‹¤ì‹œ í•œë²ˆ í™•ì¸í•´ì£¼ì„¸ìš”.\"], \"Step\": [\"unknown spatial entityë¥¼ userì—ê²Œ ë¬¼ì–´ë³´ê¸°\"]}, \"Instruction Set\": [{\"type\": \"r\", \"templates\": [\"unknown spatial entityë¥¼ ë‹¤ì‹œ í•œë²ˆ í™•ì¸í•´ì£¼ì„¸ìš”.\"]}]}\n",
      "'Query: 10ë…„ì „ ìš°ë¦¬ë°˜ ì˜¨ë„ ì•Œë ¤ì¤˜, Time: 15.704979181289673'\n",
      "{\"Formalized Input\": \"10ë…„ì „ ìš°ë¦¬ë°˜ ì‹¤ë‚´ì˜¨ë„ë¥¼ ì•Œë ¤ì¤˜.\", \"Input Semantic Parsing\": {\"Temporal\": {\"10ë…„ì „\": \"2012-09-30 00:00:00 ~ 2012-09-30 23:59:59\"}, \"Spatial\": {\"ìš°ë¦¬ë°˜\": \"01_IB5\"}, \"Modality\": {\"ì‹¤ë‚´ì˜¨ë„\": \"roomtemp\"}}, \"Strategy\": {\"Objective\": \"10ë…„ì „ ìš°ë¦¬ë°˜ ì‹¤ë‚´ì˜¨ë„ì˜ ë°ì´í„°ë¥¼ ì¿¼ë¦¬ í›„ ë°˜í™˜\", \"Expected Outputs\": [\"10ë…„ì „ ìš°ë¦¬ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ ë°ì´í„°ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. 2012-09-30 00:00:00 ~ 2012-09-30 23:59:59 ì‚¬ì´ì— í‰ê·  24.5â„ƒ, ìµœì € 20â„ƒ, ìµœê³  30â„ƒì˜€ìŠµë‹ˆë‹¤.\"], \"Step\": [\"10ë…„ì „ ìš°ë¦¬ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ ë°ì´í„°ë¥¼ ì¿¼ë¦¬í•´ qr_roomtemp_10years_agoì— ì €ì¥\", \"qr_roomtemp_10years_agoì—ì„œ í‰ê· , ìµœì €, ìµœê³  ì˜¨ë„ ê³„ì‚°\", \"ê³„ì‚° ê²°ê³¼ ë°˜í™˜\"]}, \"Instruction Set\": [{\"type\": \"q\", \"run\": {\"args\": {\"table_name\": \"data_t\", \"columns\": [\"roomtemp\"], \"conditions\": [\"timestamp BETWEEN '2012-09-30 00:00:00' AND '2012-09-30 23:59:59'\"], \"subquery\": \"idu_id = (SELECT id FROM idu_t WHERE name = '01_IB5')\"}}, \"result\": {\"name\": \"qr_roomtemp_10years_ago\"}}, {\"type\": \"o\", \"python_script_to_process\": \"avg_temp = qr_roomtemp_10years_ago['roomtemp'].mean(); min_temp = qr_roomtemp_10years_ago['roomtemp'].min(); max_temp = qr_roomtemp_10years_ago['roomtemp'].max()\", \"return\": [\"avg_temp\", \"min_temp\", \"max_temp\"]}, {\"type\": \"r\", \"templates\": [\"10ë…„ì „ ìš°ë¦¬ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ ë°ì´í„°ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. {avg_temp}â„ƒì˜ í‰ê· , {min_temp}â„ƒì˜ ìµœì €, {max_temp}â„ƒì˜ ìµœê³  ì˜¨ë„ë¡œ ì¸¡ì •ë˜ì—ˆìŠµë‹ˆë‹¤.\"]}]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('{\"Formalized Input\": \"10ë…„ì „ ìš°ë¦¬ë°˜ ì‹¤ë‚´ì˜¨ë„ë¥¼ ì•Œë ¤ì¤˜.\", \"Input Semantic Parsing\": {\"Temporal\": {\"10ë…„ì „\": \"2012-09-30 00:00:00 ~ 2012-09-30 23:59:59\"}, \"Spatial\": {\"ìš°ë¦¬ë°˜\": \"01_IB5\"}, \"Modality\": {\"ì‹¤ë‚´ì˜¨ë„\": \"roomtemp\"}}, \"Strategy\": {\"Objective\": \"10ë…„ì „ ìš°ë¦¬ë°˜ ì‹¤ë‚´ì˜¨ë„ì˜ ë°ì´í„°ë¥¼ ì¿¼ë¦¬ í›„ ë°˜í™˜\", \"Expected Outputs\": [\"10ë…„ì „ ìš°ë¦¬ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ ë°ì´í„°ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. 2012-09-30 00:00:00 ~ 2012-09-30 23:59:59 ì‚¬ì´ì— í‰ê·  24.5â„ƒ, ìµœì € 20â„ƒ, ìµœê³  30â„ƒì˜€ìŠµë‹ˆë‹¤.\"], \"Step\": [\"10ë…„ì „ ìš°ë¦¬ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ ë°ì´í„°ë¥¼ ì¿¼ë¦¬í•´ qr_roomtemp_10years_agoì— ì €ì¥\", \"qr_roomtemp_10years_agoì—ì„œ í‰ê· , ìµœì €, ìµœê³  ì˜¨ë„ ê³„ì‚°\", \"ê³„ì‚° ê²°ê³¼ ë°˜í™˜\"]}, \"Instruction Set\": [{\"type\": \"q\", \"run\": {\"args\": {\"table_name\": \"data_t\", \"columns\": [\"roomtemp\"], \"conditions\": [\"timestamp BETWEEN \\'2012-09-30 00:00:00\\' AND \\'2012-09-30 23:59:59\\'\"], \"subquery\": \"idu_id = (SELECT id FROM idu_t WHERE name = \\'01_IB5\\')\"}}, \"result\": {\"name\": \"qr_roomtemp_10years_ago\"}}, {\"type\": \"o\", \"python_script_to_process\": \"avg_temp = qr_roomtemp_10years_ago[\\'roomtemp\\'].mean(); min_temp = qr_roomtemp_10years_ago[\\'roomtemp\\'].min(); max_temp = qr_roomtemp_10years_ago[\\'roomtemp\\'].max()\", \"return\": [\"avg_temp\", \"min_temp\", \"max_temp\"]}, {\"type\": \"r\", \"templates\": [\"10ë…„ì „ ìš°ë¦¬ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ ë°ì´í„°ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. {avg_temp}â„ƒì˜ í‰ê· , {min_temp}â„ƒì˜ ìµœì €, {max_temp}â„ƒì˜ ìµœê³  ì˜¨ë„ë¡œ ì¸¡ì •ë˜ì—ˆìŠµë‹ˆë‹¤.\"]}]}',\n",
       " {'Formalized Input': '10ë…„ì „ ìš°ë¦¬ë°˜ ì‹¤ë‚´ì˜¨ë„ë¥¼ ì•Œë ¤ì¤˜.',\n",
       "  'Input Semantic Parsing': {'Temporal': {'10ë…„ì „': '2012-09-30 00:00:00 ~ 2012-09-30 23:59:59'},\n",
       "   'Spatial': {'ìš°ë¦¬ë°˜': '01_IB5'},\n",
       "   'Modality': {'ì‹¤ë‚´ì˜¨ë„': 'roomtemp'}},\n",
       "  'Strategy': {'Objective': '10ë…„ì „ ìš°ë¦¬ë°˜ ì‹¤ë‚´ì˜¨ë„ì˜ ë°ì´í„°ë¥¼ ì¿¼ë¦¬ í›„ ë°˜í™˜',\n",
       "   'Expected Outputs': ['10ë…„ì „ ìš°ë¦¬ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ ë°ì´í„°ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. 2012-09-30 00:00:00 ~ 2012-09-30 23:59:59 ì‚¬ì´ì— í‰ê·  24.5â„ƒ, ìµœì € 20â„ƒ, ìµœê³  30â„ƒì˜€ìŠµë‹ˆë‹¤.'],\n",
       "   'Step': ['10ë…„ì „ ìš°ë¦¬ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ ë°ì´í„°ë¥¼ ì¿¼ë¦¬í•´ qr_roomtemp_10years_agoì— ì €ì¥',\n",
       "    'qr_roomtemp_10years_agoì—ì„œ í‰ê· , ìµœì €, ìµœê³  ì˜¨ë„ ê³„ì‚°',\n",
       "    'ê³„ì‚° ê²°ê³¼ ë°˜í™˜']},\n",
       "  'Instruction Set': [{'type': 'q',\n",
       "    'run': {'args': {'table_name': 'data_t',\n",
       "      'columns': ['roomtemp'],\n",
       "      'conditions': [\"timestamp BETWEEN '2012-09-30 00:00:00' AND '2012-09-30 23:59:59'\"],\n",
       "      'subquery': \"idu_id = (SELECT id FROM idu_t WHERE name = '01_IB5')\"}},\n",
       "    'result': {'name': 'qr_roomtemp_10years_ago'}},\n",
       "   {'type': 'o',\n",
       "    'python_script_to_process': \"avg_temp = qr_roomtemp_10years_ago['roomtemp'].mean(); min_temp = qr_roomtemp_10years_ago['roomtemp'].min(); max_temp = qr_roomtemp_10years_ago['roomtemp'].max()\",\n",
       "    'return': ['avg_temp', 'min_temp', 'max_temp']},\n",
       "   {'type': 'r',\n",
       "    'templates': ['10ë…„ì „ ìš°ë¦¬ë°˜ì˜ ì‹¤ë‚´ì˜¨ë„ ë°ì´í„°ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. {avg_temp}â„ƒì˜ í‰ê· , {min_temp}â„ƒì˜ ìµœì €, {max_temp}â„ƒì˜ ìµœê³  ì˜¨ë„ë¡œ ì¸¡ì •ë˜ì—ˆìŠµë‹ˆë‹¤.']}]})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(\"ë¡¯ë°ìºìŠ¬ì˜ í˜„ì¬ ì˜¨ë„ ì•Œë ¤ì¤˜\")\n",
    "run(\"10ë…„ì „ ìš°ë¦¬ë°˜ ì˜¨ë„ ì•Œë ¤ì¤˜\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Query: ì§€ê¸ˆ ì˜†ë°˜ ì—ì–´ì»¨ ìƒíƒœ ì•Œë ¤ì¤˜, Time: 9.772225141525269'\n",
      "{\"Formalized Input\": \"ì§€ê¸ˆ ì˜†ë°˜ ì—ì–´ì»¨ ì „ì›ì´ ì¼œì ¸ìˆì–´?\", \"Input Semantic Parsing\": {\"Temporal\": {\"ì§€ê¸ˆ\": \"2022-09-30 12:00:00\"}, \"Spatial\": {\"ì˜†ë°˜\": \"01_IB7\"}, \"Modality\": {\"ì—ì–´ì»¨ ì „ì›\": \"oper\"}}, \"Strategy\": {\"Objective\": \"ì§€ê¸ˆ ì˜†ë°˜ ì—ì–´ì»¨ ì „ì› ìƒíƒœë¥¼ ì¿¼ë¦¬ í›„ ë°˜í™˜\", \"Expected Outputs\": [\"ì˜†ë°˜ ì—ì–´ì»¨ ì „ì›ì´ ì¼œì ¸ìˆìŠµë‹ˆë‹¤.\"], \"Step\": [\"ì§€ê¸ˆ ì˜†ë°˜ ì—ì–´ì»¨ ì „ì› ìƒíƒœë¥¼ ì¿¼ë¦¬í•´ qr_aircon_operì— ì €ì¥\", \"qr_aircon_oper ë°˜í™˜\"]}, \"Instruction Set\": [{\"type\": \"q\", \"run\": {\"args\": {\"table_name\": \"data_t\", \"columns\": [\"oper\"], \"conditions\": [\"timestamp = '2022-09-30 12:00:00'\"], \"subquery\": \"idu_id = (SELECT id FROM idu_t WHERE name = '01_IB7')\"}}, \"result\": {\"name\": \"qr_aircon_oper\"}}, {\"type\": \"o\", \"python_script_to_process\": \"oper = qr_aircon_oper['oper'].values[0]\", \"return\": [\"oper\"]}, {\"type\": \"r\", \"templates\": [\"ì˜†ë°˜ ì—ì–´ì»¨ ì „ì›ì´ {oper}ì…ë‹ˆë‹¤.\"]}]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('{\"Formalized Input\": \"ì§€ê¸ˆ ì˜†ë°˜ ì—ì–´ì»¨ ì „ì›ì´ ì¼œì ¸ìˆì–´?\", \"Input Semantic Parsing\": {\"Temporal\": {\"ì§€ê¸ˆ\": \"2022-09-30 12:00:00\"}, \"Spatial\": {\"ì˜†ë°˜\": \"01_IB7\"}, \"Modality\": {\"ì—ì–´ì»¨ ì „ì›\": \"oper\"}}, \"Strategy\": {\"Objective\": \"ì§€ê¸ˆ ì˜†ë°˜ ì—ì–´ì»¨ ì „ì› ìƒíƒœë¥¼ ì¿¼ë¦¬ í›„ ë°˜í™˜\", \"Expected Outputs\": [\"ì˜†ë°˜ ì—ì–´ì»¨ ì „ì›ì´ ì¼œì ¸ìˆìŠµë‹ˆë‹¤.\"], \"Step\": [\"ì§€ê¸ˆ ì˜†ë°˜ ì—ì–´ì»¨ ì „ì› ìƒíƒœë¥¼ ì¿¼ë¦¬í•´ qr_aircon_operì— ì €ì¥\", \"qr_aircon_oper ë°˜í™˜\"]}, \"Instruction Set\": [{\"type\": \"q\", \"run\": {\"args\": {\"table_name\": \"data_t\", \"columns\": [\"oper\"], \"conditions\": [\"timestamp = \\'2022-09-30 12:00:00\\'\"], \"subquery\": \"idu_id = (SELECT id FROM idu_t WHERE name = \\'01_IB7\\')\"}}, \"result\": {\"name\": \"qr_aircon_oper\"}}, {\"type\": \"o\", \"python_script_to_process\": \"oper = qr_aircon_oper[\\'oper\\'].values[0]\", \"return\": [\"oper\"]}, {\"type\": \"r\", \"templates\": [\"ì˜†ë°˜ ì—ì–´ì»¨ ì „ì›ì´ {oper}ì…ë‹ˆë‹¤.\"]}]}',\n",
       " {'Formalized Input': 'ì§€ê¸ˆ ì˜†ë°˜ ì—ì–´ì»¨ ì „ì›ì´ ì¼œì ¸ìˆì–´?',\n",
       "  'Input Semantic Parsing': {'Temporal': {'ì§€ê¸ˆ': '2022-09-30 12:00:00'},\n",
       "   'Spatial': {'ì˜†ë°˜': '01_IB7'},\n",
       "   'Modality': {'ì—ì–´ì»¨ ì „ì›': 'oper'}},\n",
       "  'Strategy': {'Objective': 'ì§€ê¸ˆ ì˜†ë°˜ ì—ì–´ì»¨ ì „ì› ìƒíƒœë¥¼ ì¿¼ë¦¬ í›„ ë°˜í™˜',\n",
       "   'Expected Outputs': ['ì˜†ë°˜ ì—ì–´ì»¨ ì „ì›ì´ ì¼œì ¸ìˆìŠµë‹ˆë‹¤.'],\n",
       "   'Step': ['ì§€ê¸ˆ ì˜†ë°˜ ì—ì–´ì»¨ ì „ì› ìƒíƒœë¥¼ ì¿¼ë¦¬í•´ qr_aircon_operì— ì €ì¥', 'qr_aircon_oper ë°˜í™˜']},\n",
       "  'Instruction Set': [{'type': 'q',\n",
       "    'run': {'args': {'table_name': 'data_t',\n",
       "      'columns': ['oper'],\n",
       "      'conditions': [\"timestamp = '2022-09-30 12:00:00'\"],\n",
       "      'subquery': \"idu_id = (SELECT id FROM idu_t WHERE name = '01_IB7')\"}},\n",
       "    'result': {'name': 'qr_aircon_oper'}},\n",
       "   {'type': 'o',\n",
       "    'python_script_to_process': \"oper = qr_aircon_oper['oper'].values[0]\",\n",
       "    'return': ['oper']},\n",
       "   {'type': 'r', 'templates': ['ì˜†ë°˜ ì—ì–´ì»¨ ì „ì›ì´ {oper}ì…ë‹ˆë‹¤.']}]})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(\"ì§€ê¸ˆ ì˜†ë°˜ ì—ì–´ì»¨ ìƒíƒœ ì•Œë ¤ì¤˜\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
